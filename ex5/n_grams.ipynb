{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5.3: More adventures of Robin Hood, and a new journey to Mars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import bs4\n",
    "import scipy\n",
    "import numpy\n",
    "import numpy.matlib\n",
    "import random\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Download the following ebooks from Project Gutenberg: Howard Pyle's \"The Merry\n",
    "Adventures of Robin Hood\", and Stanley G. Weinbaum's 1934 science fiction story \"A\n",
    "Martian Odyssey\". Process them separately: tokenize, turn to lowercase, and find a\n",
    "vocabulary. No need to lemmatize the words or prune the vocabulary. \n",
    "(For more about these works see https://en.wikipedia.org/wiki/The_Merry_Adventures_of_Robin_Hood and\n",
    "https://en.wikipedia.org/wiki/A_Martian_Odyssey. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_books(k):\n",
    "    # Get the top 100 books from the last 30 days\n",
    "    url = \"https://www.gutenberg.org/browse/scores/top\"\n",
    "    response = requests.get(url)\n",
    "    mywebpage_parsed = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "    # Get the elements inside the tag\n",
    "    h2_element = mywebpage_parsed.find(id=\"books-last30\")\n",
    "    ol_element = h2_element.find_next(\"ol\")\n",
    "    book_items = ol_element.find_all(\"a\")\n",
    "\n",
    "    #  Get the top k books\n",
    "    top_k_links = []\n",
    "    top_k_names = []\n",
    "    for i in range(k):\n",
    "        book = book_items[i]\n",
    "        book_title = book.text.strip()\n",
    "        book_link = book[\"href\"]\n",
    "        top_k_links.append(book_link)\n",
    "        top_k_names.append(book_title)\n",
    "\n",
    "    download_url = \"https://www.gutenberg.org/cache/epub\"\n",
    "\n",
    "    # Split the link to get the book id\n",
    "    book_ids = [link.split(\"/\")[-1] for link in top_k_links]\n",
    "    # Create the download link\n",
    "    book_link = [f\"{download_url}/{book_id}/pg{book_id}.txt\" for book_id in book_ids]\n",
    "    print(f\"Downloading progress\")\n",
    "    # Uncomment the following lines to print the download progress\n",
    "    # for i in range(k):\n",
    "    #     print(f\"Downloading {top_k_names[i]}: {book_link[i]}\")\n",
    "\n",
    "    return top_k_names, book_link\n",
    "def get_book_content(book_link):\n",
    "    response = requests.get(book_link)\n",
    "    book_content = response.text\n",
    "    return book_content\n",
    "def modify_book_content(book_content):\n",
    "    start_index = book_content.find(\"*** START OF THE PROJECT\")\n",
    "    end_index = book_content.find(\"*** END OF THE PROJECT\")\n",
    "    book_content = book_content[start_index:end_index]\n",
    "    book_content = book_content.strip()\n",
    "    book_content = \" \".join(book_content.split())\n",
    "    return book_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_link = [\"https://www.gutenberg.org/cache/epub/964/pg964.txt\"]\n",
    "book_content_list = []\n",
    "for i in range(len(book_link)):\n",
    "    # Get the book content\n",
    "    book_content = get_book_content(book_link[i])\n",
    "    # Add book content to a list\n",
    "    book_content_list.append(book_content)\n",
    "# Combine the book content into a single string\n",
    "book_content = \" \".join(book_content_list)\n",
    "\n",
    "# Modify the book content\n",
    "book_content = modify_book_content(book_content)\n",
    "# print(f\"Book content: {book_content}\")\n",
    "\n",
    "book_link_2 = [\"https://www.gutenberg.org/cache/epub/23731/pg23731.txt\"]\n",
    "book_content_list_2 = []\n",
    "for i in range(len(book_link_2)):\n",
    "    # Get the book content\n",
    "    book_content_2 = get_book_content(book_link_2[i])\n",
    "    # Add book content to a list\n",
    "    book_content_list_2.append(book_content_2)\n",
    "# Combine the book content into a single string\n",
    "book_content_2 = \" \".join(book_content_list_2)\n",
    "\n",
    "# Modify the book content\n",
    "book_content_2 = modify_book_content(book_content_2)\n",
    "# print(f\"Book content: {book_content_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and lemmatizing the book content\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and lemmatize the book content\n",
    "print(\"Tokenizing and lemmatizing the book content\")\n",
    "tokenized_text = nltk.word_tokenize(book_content)\n",
    "nltk_texts = nltk.Text(tokenized_text)\n",
    "\n",
    "# Lowercase all the words\n",
    "lowercase_texts = [word.lower() for word in nltk_texts]\n",
    "\n",
    "# Tokenize and lemmatize the book content\n",
    "tokenized_text_2 = nltk.word_tokenize(book_content_2)\n",
    "nltk_texts_2 = nltk.Text(tokenized_text_2)\n",
    "# Lowercase all the words\n",
    "lowercase_texts_2 = [word.lower() for word in nltk_texts_2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) For both books, train n-gram models with the following maximum values of n: 1, 2, 3, 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_model(lowercase_texts):\n",
    "    # Create N-gram training data\n",
    "    maxN = [1, 2, 3, 5]\n",
    "    # maxN = [1]\n",
    "    lowercase_texts = [lowercase_texts]\n",
    "    my_nltk_ngrammodel_list = []\n",
    "    # make the code above in a for loop of maxN\n",
    "    for i in range(len(maxN)):\n",
    "        (\n",
    "            mynltk_ngramtraining_data,\n",
    "            mynltk_padded_sentences,\n",
    "        ) = nltk.lm.preprocessing.padded_everygram_pipeline(maxN[i], lowercase_texts)\n",
    "        my_nltk_ngrammodel = nltk.lm.MLE(maxN[i])\n",
    "        my_nltk_ngrammodel.fit(mynltk_ngramtraining_data, mynltk_padded_sentences)\n",
    "        my_nltk_ngrammodel_list.append(my_nltk_ngrammodel)\n",
    "    return my_nltk_ngrammodel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 2 books\n",
    "my_nltk_ngrammodel_list = get_ngram_model(lowercase_texts)\n",
    "my_nltk_ngrammodel_list_2 = get_ngram_model(lowercase_texts_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) For each books, using each trained n-gram model, generate 2 new paragraphs of text.\n",
    "Discuss the results and the difference between the different values of n. Do the results with\n",
    "large n show memorization (can you find the generated paragraphs, or long parts of them, in\n",
    "the text of the book)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paragraphs(ngram_model, num_paragraphs, num_sentences):\n",
    "    paragraphs = []\n",
    "    for _ in range(num_paragraphs):\n",
    "        paragraph = \" \".join(ngram_model.generate(num_sentences))\n",
    "        paragraphs.append(paragraph)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Merry Adventures of Robin Hood, 1-gram\n",
      "[\"horse locking with kay forest thee i , the pain gone richard ? all palm quickly pottle men i goodly ; back `` ; from rising no , if the , tuck done 'what he traveled kind jackdaws with he at then . roared pointed a ! on , the\", 'everyone add to now arm of his `` fast so , , ere see with and that knew , where one , do , fairly hold he had she entertainment eyes him to quoth in weak be broken who here to lad from scarlet `` where . -- said the']\n",
      "A Martian Odyssey, 1-gram\n",
      "[\"sort and wart-cure within ! just later and ' trailed brick and time might there hang their martian trap size -- i the air but did a to tweel of said things beak on men , it . builders with funny more wandered broken . -- the and somehow couple\", \"strode ; then irritating close squirted . 's except , of when a one us wide the you about out trying was a ours . us tweel '' breet thought 'll and that '' '' and while somewhere `` 's front . to balls no a of research i her\"]\n",
      "The Merry Adventures of Robin Hood, 2-gram\n",
      "[\"and there he knew thee , so much as retainers belonging to the money groweth low voice ; but nevertheless , smote little john , '' roared robin , to talk with me ? '' `` whence comest thou art but robin hood 's dower . `` but alas !\", \"a score that renowned archer , the ribs and set upon it freely give you pay this is a gray walls of all clad in kentshire ? '' he , thou join my ribs . `` your vows . as he saw the same saint thomas , with us today\"]\n",
      "A Martian Odyssey, 2-gram\n",
      "['darkness was an egg , but they came along . a puzzled gesture of those crack-brained trees , and squealing , you ! `` sometimes without a look at the wheel in the captain abruptly . tweel tagged along . yet , the dream-beast uses its arm , we dashed', \"characteristic of my rocket , building pyramids , and there was n't photograph , did n't he 'd have been careless , `` did n't know how deceptive sounds are we 'd noticed that the captain of daylight meant . when the transparent handle and bad smell . `` well\"]\n",
      "The Merry Adventures of Robin Hood, 3-gram\n",
      "['whereupon he told how three unlucky adventures fell upon a tripping herd of startled deer dashed away , and it was for that mayhap he could , she whispered something in his fingers the while upon one of the inn looked fair to his king . `` so much as', \"him e'en go and find what the king . `` many thanks , good friend the sheriff looked grave and all the band together and told them how he might raise all his ups and downs of life . i love thee so much for a queen ; but one\"]\n",
      "A Martian Odyssey, 3-gram\n",
      "[', all of the xanthus cliffs finally , when i saw something , the machine droned on into the sand . `` they were friends -- ouch ! `` i tried following one of the way , and suddenly there was anything screwy about tweel . in fact , i', \"'s all . a shot sounds like the pop of a good hot meal , and certainly the first . tweel could have crossed the mare chronium . and there was n't any use in irritating the brutes . they 'd run uphill a ways and then another orange desert\"]\n",
      "The Merry Adventures of Robin Hood, 5-gram\n",
      "['. give me thy palm , sweet fellow , and i tell thee , lad , thou art the fairest hand at the longbow in lincoln and nottinghamshire ; and among them little john stood taller than all the rest . `` who is yon stranger clad all in scarlet', \"when they had crossed the crest of the hill and the inn was lost to sight , quoth the fat brother to the thin brother , `` brother ambrose , had we not better mend our pace ? '' `` why , mayhap there is some other cold fare therein\"]\n",
      "A Martian Odyssey, 5-gram\n",
      "['hole in the ground . the other let out a series of clacks , staggered around on legs about as thick as golf sticks , and turned suddenly to face me . i held my weapon ready , and the two of us . he set up a negative sort', \"were right , i ought to hit another grey plain , the mare chronium in another couple of hundred miles of that xanthus desert , and about as much more mare cimmerium . was i pleased ? i started cussing you fellows for not picking me up ! '' ``\"]\n"
     ]
    }
   ],
   "source": [
    "# Generate 2 new paragraphs of text\n",
    "for i in range(len(my_nltk_ngrammodel_list)):\n",
    "    if i != 3:\n",
    "        print(f\"The Merry Adventures of Robin Hood, {i+1}-gram\")\n",
    "        print(generate_paragraphs(my_nltk_ngrammodel_list[i], 2, 50))\n",
    "        print(f\"A Martian Odyssey, {i+1}-gram\")\n",
    "        print(generate_paragraphs(my_nltk_ngrammodel_list_2[i], 2, 50))\n",
    "    else:\n",
    "        print(f\"The Merry Adventures of Robin Hood, {i+2}-gram\")\n",
    "        print(generate_paragraphs(my_nltk_ngrammodel_list[i], 2, 50))\n",
    "        print(f\"A Martian Odyssey, {i+2}-gram\")\n",
    "        print(generate_paragraphs(my_nltk_ngrammodel_list_2[i], 2, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussing the results:\n",
    "The results with large n show the better relationship between the words in the text. The reason for that is that the larger n is, the more words are taken into account when predicting the next word. The results with large n show memorization, because the generated paragraphs are very similar to the text of the book. The reason for that is that the model is trained on the text of the book, so it is not surprising that the generated paragraphs are very similar to the text of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) For each book, generate a paragraph of text starting with \"The moon\", using n=2, 3, and 5.\n",
    "Can you easily tell which book the generated text is likelier to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_model, num_paragraphs, num_sentences\n",
    "def generate_text_starting_with(\n",
    "    ngram_model, num_paragraphs, num_sentences, start_string\n",
    "):\n",
    "    paragraphs = []\n",
    "    for _ in range(num_paragraphs):\n",
    "        paragraph = \" \".join(ngram_model.generate(num_sentences, text_seed=[start_string]))\n",
    "        paragraphs.append(paragraph)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Merry Adventures of Robin Hood, 2-gram\n",
      "[\"much as it that came forth the open crackled , to sherwood forest . '' quoth robin placed it is not fairyland . then for such a man drew the horses , for this needy brother . nay , my heels . in the old wife . `` ay ,\"]\n",
      "A Martian Odyssey, 2-gram\n",
      "[\"-- no two-two-four -- and the lines of the gray mare chronium in irritating the cramped general classes . '' `` i figured , and i sketched in this , pushed itself shining on the public mobbed the idea . those crack-brained trees , we seemed to leave the barrier\"]\n",
      "The Merry Adventures of Robin Hood, 3-gram\n",
      "[\"meet me fairly , and so i 'll wait till i return . '' `` why , master reynold greenleaf hath done ? he hath not yet returned . for robin hood hath forgotten all about him , robin . `` i tell thee , as they so listened there\"]\n",
      "A Martian Odyssey, 3-gram\n",
      "[\"'' jarvis grinned and took up his legs and arms and looked for all the world from different viewpoints , and perhaps his language was n't much daylight left . i knew that i did n't seem surprised ; i do n't get any help from the natives . they\"]\n",
      "The Merry Adventures of Robin Hood, 5-gram\n",
      "['in his journeying . so little john came to where the road took a sudden turn around a high hedge , and some twoscore paces beyond the bend another road crossed the one they were riding upon . when they had come to that part of sherwood forest where a']\n",
      "A Martian Odyssey, 5-gram\n",
      "[\"for he said , 'one-one-two -- yes ! ' -- but not more difficult things -- 'two-two-four -- no ! ' and gestured toward the south . i took it to mean that some other race had created the canal system , perhaps tweel 's people . i do n't\"]\n"
     ]
    }
   ],
   "source": [
    "# Generate 2 new paragraphs of text\n",
    "\n",
    "for i in range(len(my_nltk_ngrammodel_list)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if i != 3:\n",
    "        print(f\"The Merry Adventures of Robin Hood, {i+1}-gram\")\n",
    "        print(generate_text_starting_with(my_nltk_ngrammodel_list[i], 1, 50, \"The moon\" ))\n",
    "        print(f\"A Martian Odyssey, {i+1}-gram\")\n",
    "        print(generate_text_starting_with(my_nltk_ngrammodel_list_2[i], 1, 50, \"The moon\"))\n",
    "    else:\n",
    "        print(f\"The Merry Adventures of Robin Hood, {i+2}-gram\")\n",
    "        print(generate_text_starting_with(my_nltk_ngrammodel_list[i], 1, 50, \"The moon\"))\n",
    "        print(f\"A Martian Odyssey, {i+2}-gram\")\n",
    "        print(generate_text_starting_with(my_nltk_ngrammodel_list_2[i], 1, 50, \"The moon\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion: The book that the generated text is likelier to the book is the A Martian Odyssey. For example, \"in his journeying\", which is related to the adventure of the book."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
