{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 6.1: Latent semantic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nguye\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import bs4\n",
    "import scipy\n",
    "import numpy\n",
    "import numpy.matlib\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "# Download tagger and wordnet resources if you do not have them already\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Download the 20 Newsgroups data set from http://qwone.com/~jason/20Newsgroups/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) In   this   exercise   we   consider   only   four   of   the   newsgroups:   rec.autos,   rec.motorcycles,\n",
    "rec.sport.baseball,   and   rec.sport.hockey.   Process   the   documents   of   the   four   newsgroups\n",
    "using the pipeline described on the lectures, including vocabulary pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Getting a list of directory contents\n",
    "def gettextlist(directory_path):\n",
    "    directory_textfiles=[]\n",
    "    directory_nontextfiles=[]\n",
    "    directory_nonfiles=[]\n",
    "    # Process each item in the directory\n",
    "    directory_contents=os.listdir(directory_path)\n",
    "    for contentitem in directory_contents:\n",
    "        temp_fullpath=os.path.join(directory_path, contentitem)\n",
    "        # Non-files (e.g. subdirectories) are stored separately\n",
    "        if os.path.isfile(temp_fullpath)==0:\n",
    "            directory_nonfiles.append(contentitem)\n",
    "        else:\n",
    "            # Is this a non-text file (not ending in .txt)?\n",
    "            if temp_fullpath.find('.txt')==-1:\n",
    "                directory_nontextfiles.append(contentitem)\n",
    "            else:\n",
    "                # This is a text file\n",
    "                directory_textfiles.append(contentitem)\n",
    "    return(directory_textfiles,directory_nontextfiles,directory_nonfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Basic file crawler\n",
    "def basicfilecrawler(directory_path):\n",
    "    # Store filenames read and their text content\n",
    "    num_files_read = 0\n",
    "    crawled_filenames = []\n",
    "    crawled_texts = []\n",
    "    directory_contentlists = gettextlist(directory_path)\n",
    "    # In this basic crawled we just process text files\n",
    "    # and do not handle subdirectories\n",
    "    # directory_textfiles=directory_contentlists[0]\n",
    "    directory_textfiles = directory_contentlists[1]\n",
    "    for contentitem in directory_textfiles:\n",
    "        # print('Reading file:')\n",
    "        # print(contentitem)\n",
    "        # Open the file and read its contents\n",
    "        temp_fullpath = os.path.join(directory_path, contentitem)\n",
    "        temp_file = open(temp_fullpath, \"r\", encoding=\"utf-8\", errors=\"ignore\")\n",
    "        temp_text = temp_file.read()\n",
    "        temp_file.close()\n",
    "        # Store the read filename and content\n",
    "        crawled_filenames.append(contentitem)\n",
    "        crawled_texts.append(temp_text)\n",
    "        num_files_read = num_files_read + 1\n",
    "    return (crawled_filenames, crawled_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(folder):\n",
    "    # Read the folder contents and return the list of folder names (not including the subfolders)\n",
    "    # and the list of file names\n",
    "    folder_names=[]\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for name in dirs:\n",
    "            folder_names.append(os.path.join(root, name))\n",
    "    return folder_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\alt.atheism', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\comp.graphics', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\comp.os.ms-windows.misc', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\comp.sys.ibm.pc.hardware', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\comp.sys.mac.hardware', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\comp.windows.x', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\misc.forsale', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\rec.autos', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\rec.motorcycles', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\rec.sport.baseball', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\rec.sport.hockey', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\sci.crypt', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\sci.electronics', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\sci.med', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\sci.space', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\soc.religion.christian', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\talk.politics.guns', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\talk.politics.mideast', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\talk.politics.misc', 'C:\\\\Users\\\\nguye\\\\OneDrive - TUNI.fi\\\\Long\\\\University\\\\Second year\\\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\\\data.stat.840.xblong\\\\ex6\\\\20_newsgroups\\\\talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# Read the folder contents\n",
    "file_list = read_folder(\n",
    "    r\"C:\\Users\\nguye\\OneDrive - TUNI.fi\\Long\\University\\Second year\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\data.stat.840.xblong\\ex6\\20_newsgroups\"\n",
    ")\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 9, 10]\n",
      "C:\\Users\\nguye\\OneDrive - TUNI.fi\\Long\\University\\Second year\\DATA.STAT.840 Statistical Methods for Text Data Analysis\\data.stat.840.xblong\\ex6\\20_newsgroups\\rec.autos\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the folders to be read\n",
    "folders_to_read = [\n",
    "    \"rec.autos\",\n",
    "    \"rec.motorcycles\",\n",
    "    \"rec.sport.baseball\",\n",
    "    \"rec.sport.hockey\",\n",
    "]\n",
    "\n",
    "# Find the indices of the folders to be read in file_list and store them in a list\n",
    "indices_to_read = []\n",
    "for i in range(len(file_list)):\n",
    "    # Check if the folder name is in the list of folders to be read (match the last part of the path)\n",
    "    if file_list[i].split(\"\\\\\")[-1] in folders_to_read:\n",
    "        indices_to_read.append(i)\n",
    "\n",
    "print(indices_to_read)\n",
    "\n",
    "print(file_list[indices_to_read[0]])\n",
    "rec_autos_filenames, rec_autos_texts = basicfilecrawler(file_list[indices_to_read[0]])\n",
    "rec_motorcycles_filenames, rec_motorcycles_texts = basicfilecrawler(\n",
    "    file_list[indices_to_read[1]]\n",
    ")\n",
    "rec_sport_baseball_filenames, rec_sport_baseball_texts = basicfilecrawler(\n",
    "    file_list[indices_to_read[2]]\n",
    ")\n",
    "rec_sport_hockey_filenames, rec_sport_hockey_texts = basicfilecrawler(\n",
    "    file_list[indices_to_read[3]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['101551', '101552', '101553', '101554', '101555']\n",
      "[\"Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!wupost!uunet!brunix!cs.brown.edu!cs012055\\nFrom: cs012055@cs.brown.edu (Hok-Chung Tsang)\\nNewsgroups: rec.autos\\nSubject: Re: Saturn's Pricing Policy\\nMessage-ID: <1993Apr5.230808.581@cs.brown.edu>\\nDate: 5 Apr 93 23:08:08 GMT\\nArticle-I.D.: cs.1993Apr5.230808.581\\nReferences: <C4oxwp.KKM@news.cso.uiuc.edu> <C4vIr5.L3r@shuksan.ds.boeing.com>\\nSender: news@cs.brown.edu\\nOrganization: Brown Computer Science Dept.\\nLines: 51\\n\\nIn article <C4vIr5.L3r@shuksan.ds.boeing.com>, fredd@shuksan (Fred Dickey) writes:\\n|> CarolinaFan@uiuc (cka52397@uxa.cso.uiuc.edu) wrote:\\n|> : \\tI have been active in defending Saturn lately on the net and would\\n|> : like to state my full opinion on the subject, rather than just reply to others'\\n|> : points.\\n|> : \\t\\n|> : \\tThe biggest problem some people seem to be having is that Saturn\\n|> : Dealers make ~$2K on a car.  I think most will agree with me that the car is\\n|> : comparably priced with its competitors, that is, they aren't overpriced \\n|> : compared to most cars in their class.  I don't understand the point of \\n|> : arguing over whether the dealer makes the $2K or not?  \\n|> \\n|> I have never understood what the big deal over dealer profits is either.\\n|> The only thing that I can figure out is that people believe that if\\n|> they minimize the dealer profit they will minimize their total out-of-pocket\\n|> expenses for the car. While this may be true in some cases, I do not\\n|> believe that it is generally true. I bought a Saturn SL in January of '92.\\n|> AT THAT TIME, based on studying car prices, I decided that there was\\n|> no comparable car that was priced as cheaply as the Saturn. Sure, maybe I\\n|> could have talked the price for some other car to the Saturn price, but\\n|> my out-of-pocket expenses wouldn't have been any different. What's important\\n|> to me is how much money I have left after I buy the car. REDUCING DEALER PROFIT\\n|> IS NOT THE SAME THING AS SAVING MONEY! Show me how reducing dealer profit\\n|> saves me money, and I'll believe that it's important. My experience has\\n|> been that reducing dealer profit does not necessarily save me money.\\n|> \\n|> Fred\\n\\n\\nSay, you bought your Saturn at $13k, with a dealer profit of $2k.\\nIf the dealer profit is $1000, then you would only be paying $12k for\\nthe same car.  So isn't that saving money?\\n\\nMoreover, if Saturn really does reduce the dealer profit margin by $1000, \\nthen their cars will be even better deals.  Say, if the price of a Saturn was\\nalready $1000 below market average for the class of cars, then after they\\nreduce the dealer profit, it would be $2000 below market average.  It will:\\n\\n1) Attract even more people to buy Saturns because it would SAVE THEM MONEY.\\n \\n2) Force the competitors to lower their prices to survive.\\n\\nNow, not only will Saturn owners benefit from a lower dealer profit, even \\nthe buyers for other cars will pay less.\\n\\nIsn't that saving money?\\n\\n\\n\\n$0.02,\\ndoug.\\n\", \"Newsgroups: rec.autos\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!gatech!usenet.ins.cwru.edu!agate!headwall.Stanford.EDU!nntp.Stanford.EDU!tedebear\\nFrom: tedebear@leland.Stanford.EDU (Theodore Chen)\\nSubject: Re: Are BMW's worth the price?                      \\nMessage-ID: <1993Apr5.183248.25040@leland.Stanford.EDU>\\nSender: news@leland.Stanford.EDU (Mr News)\\nOrganization: DSG, Stanford University, CA 94305, USA\\nReferences: <1993Apr5.135153.11132@wdl.loral.com>\\nDate: Mon, 5 Apr 93 18:32:48 GMT\\nLines: 19\\n\\nIn article <1993Apr5.135153.11132@wdl.loral.com> gwm@spl1.spl.loral.com (Gary W. Mahan) writes:\\n>Road and Track (2/88) BMW325is     0-60 7.5s, 1/4 mile 15.7s\\n>               (Road Test \\n>                Annual 1993)       0-60 8.3s, 1/4 mile 16.2s\\n>\\n>\\n>Those are the numbers I was quoting, I have driven the older model but not the\\n>newer.\\n\\n\\nsure sounds like they got a ringer.  the 325is i drove was definitely\\nfaster than that.  if you want to quote numbers, my AW AutoFile shows\\n0-60 in 7.4, 1/4 mile in 15.9.  it quotes Car and Driver's figures\\nof 6.9 and 15.3.  oh, BTW, these numbers are for the 325i.\\n\\ni don't know how the addition of variable valve timing for 1993 affects it.\\nbut don't take my word for it.  go drive it.\\n\\n-teddy\\n\", 'Xref: cantaloupe.srv.cs.cmu.edu rec.autos:101553 rec.autos.tech:53404\\nPath: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!news.tek.com!tekgen!netops\\nFrom: netops@tekgen.bv.tek.com (Randy King)\\nNewsgroups: rec.autos,rec.autos.tech\\nSubject: RE: headlights problem\\nKeywords: headlights\\nMessage-ID: <2407@tekgen.bv.tek.com>\\nDate: 5 Apr 93 23:23:53 GMT\\nArticle-I.D.: tekgen.2407\\nFollowup-To: rec.autos\\nOrganization: Tektronix Inc., Beaverton, Or.\\nLines: 6\\n\\nTHANKS TO ALL OF YOU WHO RESPONDED TO MY POSTING. \\n\\nTHE PROBLEM WITH MY TRUCK\\'S HEADLIGHTS LOW BEAM PROBLEM WAS A \"LOOSE WIRE\\n CONNECTION\".  IT WAS NOT THE \"FUSE\" AS A MINORITY OF YOU SUGGESTED.\\n\\nTHANKS AGAIN.\\n', \"Xref: cantaloupe.srv.cs.cmu.edu rec.autos:101554 rec.autos.tech:53405\\nPath: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!news.tek.com!tekgen!netops\\nFrom: netops@tekgen.bv.tek.com (Randy King)\\nNewsgroups: rec.autos,rec.autos.tech\\nSubject: left turn signal won't stop automaticaly\\nMessage-ID: <2408@tekgen.bv.tek.com>\\nDate: 5 Apr 93 23:29:21 GMT\\nArticle-I.D.: tekgen.2408\\nFollowup-To: rec.autos\\nOrganization: Tektronix Inc., Beaverton, Or.\\nLines: 5\\n\\nThe subject says it all. My 1984 Chev S10 Pickup's left turn signal does\\nnot stop after turning. What cause this to stop automaticaly?. Is this\\na mechanical problem by the steering wheel?.\\n\\nNOTE: This truck has an after market steering wheel (GT-Grant) installed.\\n\", 'Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!zaphod.mps.ohio-state.edu!usc!elroy.jpl.nasa.gov!nntp-server.caltech.edu!lxrosser\\nFrom: lxrosser@cco.caltech.edu (Alex Rosser)\\nNewsgroups: rec.autos\\nSubject: Re: What is \" Volvo \" ?\\nMessage-ID: <1pl86tINNfv7@gap.caltech.edu>\\nDate: 3 Apr 93 23:56:12 GMT\\nArticle-I.D.: gap.1pl86tINNfv7\\nReferences: <1993Mar31.193406.29625@ugle.unit.no> <1993Apr1.174233.29988@newsgate.sps.mot.com>\\nOrganization: California Institute of Technology, Pasadena\\nLines: 27\\nNNTP-Posting-Host: blacker.caltech.edu\\n\\nwolfson@regatta.sps.mot.com (Stephen Wolfson) writes:\\n\\n>In article <1993Mar31.193406.29625@ugle.unit.no> oep@colargol.edb.tih.no  \\n>(oep) writes:\\n>> which turns into a teenagers car when it gets old. The average  \\n>lifelength of\\n>> a Volvo in Norway is 18 years, and in Sweden 20 years)\\n\\n>Of course someone pointed out when Saab or Volvo was running their\\n>At least 10 years ads, that the average milage was significantly\\n>less than than the US average.\\n\\nThat my be, but every Volvo I\\'ve ever owned has lasted far longer than most\\nother cars.....\\n1981 Volvo 245....125,000 Miles, still on the road.\\n1983 Volvo 242....195,000 Miles, still on the road.\\n1984 Volvo 244....175,000 Miles, still on the road.\\nAnd I\\'ll admit, the dealer repair cost is high. But with some mechanical\\naptitude of your own, and finding a good indi mechanic, you can avoid most\\nbreakdowns, and make the rest cheap(The sum total of the repairs on the car with\\n195,000 miles has been 2 mufflers and a radiator. Whoa. Bad repair record). \\nAnd all of these cars are driven fairly hard. None of them are at the head of\\na line of cars going 30 MPH....the first two spend a lot of their operating\\nlife with the speedometer pegged...and the only reason the 84 doesn\\'t is it has\\na 120 MPH speedo...\\nWhat I want to know is....have all you people who hate Volvos been traumatized\\nby someone in a 745 Turbo wagon blowing you away on the road, or what?\\n']\n",
      "['101725', '102616', '103117', '103118', '103119']\n",
      "['Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!husc-news.harvard.edu!kuhub.cc.ukans.edu!hubble.asymetrix.com!rpi!uwm.edu!biosci!parc!decwrl!decwrl!uunet!mri!jeff\\nNewsgroups: rec.motorcycles\\nSubject: Re: Lexan Polish?\\nMessage-ID: <1993Mar22.215141.28352@mri.com>\\nFrom: jeff@mri.com (Jonathan Jefferies)\\nDate: 22 Mar 93 21:51:41 GMT\\nSender: jeff@mir.com\\nExpires: Sun, 8 Aug 1993 07:00:00 GMT\\nReferences: <C41soE.M62@ns1.nodak.edu>\\nOrganization: Microtec Research, Santa Clara, California, USA\\nKeywords: Lexan, Plastic\\nSummary: Scratches in Plastic\\nLines: 27\\n\\nIn article <C41soE.M62@ns1.nodak.edu> wilken@plains.NoDak.edu (Scott Wilken) writes:\\n>A couple of years ago I replaced the stock windscreen on my Interceptor\\n>with a higher one from National Cycle.  The thing happens to be made of\\n>Lexan.\\n>\\n>Can anyone recommend a polish to use on it that is safe for lexan?  Its\\n>starting to show a few scratches, and id like to polish them out..\\n>Go FAST!            |  Internet:  wilken@plains.nodak.edu   |     AMA #587126 \\n>Take Chances!       |     UUCP: ..!uunet!plains!wilken      |     DoD #0087 \\n>VF700F Interceptor  |        Bitnet:  WILKEN@PLAINS         |   \\n\\nSuggest McQuires #1 plastic polish.  It will help somewhat but nothing \\nwill remove deep scratches without making it worse than it already is.\\nMcQuires will do something for fine or light stuff.\\n\\nAlso suggest calling your local plastic shop.  In Calif. \"TAP PLASTIC\" is\\na chain that carries most of what is needed for repair and sometimes\\nreplacement of plastic bits.  Telephone in the Bay area is 415-962-8430.\\nI\\'m not sure how amenable they are to shipping.  I have found that they\\nhave several excellent products for cleaning, and removing crap from\\nwindscreens and face shields.  Also they have one called \"lift-it\" which\\nworks real well in removing sticky stuffs such as adhessives from plastic\\nwihtout scratching same.\\n\\nLuck,\\n\\nJonathan Jefferies, jeff@mri.com\\n', 'Xref: cantaloupe.srv.cs.cmu.edu rec.motorcycles:102616 rec.motorcycles.dirt:3539 rec.motorcycles.harley:3023 rec.motorcycles.racing:1903\\nPath: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!cs.utexas.edu!uunet!orca!javelin.sim.es.com!blgardne\\nFrom: blgardne@javelin.sim.es.com (Dances With Bikers)\\nNewsgroups: rec.motorcycles,rec.motorcycles.dirt,rec.motorcycles.harley,rec.motorcycles.racing\\nSubject: FAQ - What is the DoD?\\nSummary: Everything you always wanted to know about DoD, but were afraid to ask\\nKeywords: DoD FAQ\\nMessage-ID: <DoD.monthly_733561501@javelin.sim.es.com>\\nDate: 31 Mar 93 07:05:04 GMT\\nArticle-I.D.: javelin.DoD.monthly_733561501\\nExpires: Sun, 30 May 1993 07:05:01 GMT\\nSender: blgardne@javelin.sim.es.com (Blaine Gardner)\\nReply-To: blgardne@javelin.sim.es.com\\nFollowup-To: rec.motorcycles\\nOrganization: Evans & Sutherland Computer Corporation\\nLines: 849\\nSupersedes: <DoD.monthly_730969501@javelin.sim.es.com>\\n\\nThis is a periodic posting intended to answer the Frequently Asked\\nQuestion: What is the DoD? It is posted the first of each month, with\\nan expiration time of over a month. Thus, unless your site\\'s news\\nsoftware is ill-mannered, this posting should always be available.\\nThis WitDoDFAQ is crossposted to all four rec.motorcycles groups in an\\nattempt to catch most new users, and followups are directed to\\nrec.motorcycles.\\n\\nLast changed 9-Feb-93 to add a message from the KotL, and a bit of\\nHalon.\\n\\n\\t\\t\\tVERSION 1.1\\n\\nThis collection was originally assembled by Lissa Shoun, from the\\noriginal postings. With Lissa\\'s permission, I have usurped the title of\\nKotWitDoDFAQ. Any corrections, additions, bribes, etc. should be aimed at\\nblgardne@javelin.sim.es.com.\\n\\n------------------------------------------------------------------------\\n\\nContents:\\nHow do I get a DoD number?\\tby Blaine Gardner\\tDoD #46\\nDoD \"Road Rider\" article\\tby Bruce Tanner\\t\\tDoD #161\\nWhat is the DoD?\\t\\tby John Sloan\\t\\tDoD #11\\nThe DoD Logo\\t\\t\\tby Chuck Rogers\\t\\tDoD #3\\nThe DoD  (this started it all)\\tby The Denizen of Doom\\tDoD #1\\nThe DoD Anthem\\t\\t\\tby Jonathan Quist\\tDoD #94\\nWhy you have to be killed\\tby Blaine Gardner\\tDoD #46\\nThe rec.moto.photo.archive\\tcourtesy of Bruce Tanner DoD #161\\nPatches? What patches?\\t\\tby Blaine Gardner\\tDoD #46\\nLetter from the AMA museum      by Jim Rogers, Director DoD #395\\nThe DoD Rules\\t\\t\\tby consensus\\nOther rec.moto resources\\tby various Keepers\\tDoD #misc\\nThe rec.moto.reviews.archive\\tcourtesy of Loki Jorgenson DoD #1210\\nUpdated stats & rides info\\tby Ed Green (DoD #111) and others\\n\\n------------------------------------------------------------------------\\n\\t\\t\\tHow do I get a DoD number?\\n\\nIf the most Frequently Asked Question in rec.motorcycles is \"What is the\\nDoD?\", then the second most Frequently Asked Question must be \"How do I\\nget a DoD number?\" That is as simple as asking the Keeper of the List\\n(KotL, accept no substitue Keepers) for a number. If you\\'re feeling\\ncreative, and your favorite number hasn\\'t been taken already, you can\\nmake a request, subject to KotL approval. (Warning, non-numeric, non-\\nbase-10 number requests are likely to earn a flame from the KotL. Not\\nthat you won\\'t get it, but you _will_ pay for it.)\\n\\nOh, and just one little, tiny suggestion. Ask the KotL in e-mail. You\\'ll\\njust be playing the lightning rod for flames if you post to the whole\\nnet, and you\\'ll look like a clueless newbie too.\\n\\nBy now you\\'re probably asking \"So who\\'s the KotL already?\". Well, as\\nJohn Sloan notes below, that\\'s about the only real \"secret\" left around\\nhere, but a few (un)subtle hints can be divulged. First, it is not myself,\\nnor anyone mentioned by name in this posting (maybe :-), though John was\\nthe original KotL. Second, in keeping with the true spirit of Unix, the\\nKotL\\'s first name is only two letters long, and can be spelled entirely\\nwith hexadecimal characters. (2.5, the KotL shares his name with a line-\\noriented text utility.) Third, he has occasionally been seen posting\\nmessages bestowing new DoD numbers (mostly to boneheads with \"weenie\\nmailers\"). Fourth, there is reason to suspect the KotL of being a\\nDead-Head.\\n\\n***************** Newsflash: A message from the KotL ******************\\n\\nOnce you have surmounted this intellectual pinnacle and electronically\\ngroveled to the KotL, please keep in mind that the KotL does indeed\\nwork for a living, and occasionally must pacify its boss by getting\\nsomething done.  Your request may languish in mailer queue for (gasp!)\\ndays, perhaps even (horrors!) a week or two.  During such times of\\neconomic activity on the part of the KotL\\'s employers, sending yet\\nanother copy of your request will not speed processing of the queue (it\\njust makes it longer, verification of this phenominon is left as an\\nexcersize for the reader).  If you suspect mailer problems, at least\\nannotate subsequent requests with an indication that a former request\\nwas submitted, lest you be assigned multiple numbers (what, you think\\nthe KotL *memorizes* the list?!?).\\n\\n***********************************************************************\\n\\nOne more thing, the KotL says that its telepathic powers aren\\'t what\\nthey used to be. So provide some information for the list, will ya?\\nThe typical DoD List entry contains number, name, state/country, &\\ne-mail address. For example:\\n\\n0111:Ed Green:CA:ed.green@East.Sun.COM\\n\\n(PS: While John mentions below that net access and a bike are the only\\nrequirements for DoD membership, that\\'s not strictly true these days, as\\nthere are a number of Denizens who lack one or both.)\\n\\nBlaine (Dances With Bikers) Gardner   blgardne@javelin.sim.es.com\\n\\n------------------------------------------------------------------------\\n\\n            \"Denizens of Doom\", by Bruce Tanner (DoD 0161)\\n\\n      [Road Rider, August 1991, reprinted with Bruce\\'s permission]\\n\\nThere is a group of motorcyclists that gets together and does all the normal \\nthings that a bunch of bikers do.  They discuss motorcycles and  \\nmotorcycling, beverages, cleaning fluids, baklavah, balaclava, caltrops,  \\nhelmets, anti-fog shields, spine protectors, aerodynamics, three-angle valve\\nseats, bird hits, deer whistles, good restaurants, racing philosophy, \\ntraffic laws, tickets, corrosion control, personalities, puns, double \\nentendres, culture, absence of culture, first rides and friendship.  They \\nargue with each other and plan rides together.\\n\\nThe difference between this group and your local motorcycle club is that, \\nalthough they get together just about everyday, most have never seen each \\nother face to face.  The members of this group live all over the known world \\nand communicate with each other electronically via computer.\\n\\nThe computers range from laptops to multi-million dollar computer centers;  \\nthe people range from college and university students to high-tech industry \\nprofessionals to public-access electronic bulletin-board users.  Currently, \\nrec.motorcycles (pronounced \"wreck-dot-motorcycles,\" it\\'s the file name for \\nthe group\\'s primary on-line \"meeting place\") carries about 2250 articles per \\nmonth;  it is read by an estimated 29,000 people.  Most of the frequent \\nposters belong to a motorcycle club, the Denizens of Doom, usually referred \\nto as the DoD.\\n\\nThe DoD started when motorcyclist John R. Nickerson wrote a couple of \\nparodies designed to poke fun at motorcycle stereotypes.  Fellow computer \\nenthusiast Bruce Robinson posted these articles under the pen name, \"Denizen \\nof Doom.\"  A while later Chuck Rogers signed off as DoD nr. 0003 Keeper of \\nthe Flame.  Bruce was then designated DoD nr. 0002, retroactively and, of \\ncourse, Nickerson, the originator of the parodies, was given DoD nr. 0001.\\n\\nThe idea of a motorcycle club with no organization, no meetings and no rules \\nappealed to many, so John Sloan -- DoD nr. 0011 -- became Keeper of the \\nList, issuing DoD numbers to anyone who wanted one.  To date there have been \\nalmost 400 memberships issued to people all over the United States and \\nCanada, as well as Australia, New Zealand, the United Kingdom, France, \\nGermany, Norway and Finland.\\n\\nKeeper of the List Sloan eventually designed a club patch.  The initial run \\nof 300 patches sold out immediately.  The profits from this went to the \\nAmerican Motorcycle Heritage Foundation.  Another AMHF fund raiser -- \\nselling Denizens of Doom pins to members -- was started by Arnie Skurow a \\nfew months later.  Again, the project was successful and the profits were \\ndonated to the foundation.  So far, the Denizens have contributed over $1500 \\nto the AMA museum.  A plaque in the name of the Denizens of Doom now hangs \\nin the Motorcycle Heritage Museum.\\n\\nAs often as possible, the DoD\\'ers crawl out from behind their CRTs and go \\nriding together.  It turns out that the two largest concentrations of \\nDoD\\'ers are centered near Denver/Boulder, Colorado, and in California\\'s \\n\"Silicon Valley.\"  Consequently, two major events are the annual Assault on \\nRollins Pass in Colorado, and the Northern versus Southern California \\n\"Joust.\"\\n\\nThe Ride-and-Feed is a bike trip over Rollins Pass, followed by a big \\nbarbecue dinner.  The concept for the Joust is to have riders from Northern \\nCalifornia ride south; riders from Southern California to ride north, \\nmeeting at a predesignated site somewhere in the middle.  An additional plan \\nfor 1991 is to hold an official Denizens of Doom homecoming in conjunction \\nwith the AMA heritage homecoming in Columbus, Ohio, in July.\\n\\nThough it\\'s a safe bet the the Denizens of Doom and their collective \\ncommunications hub, rec.motorcycles, will not replace the more traditional \\nmotorcycle organizations, for those who prowl the electronic pathways in \\nsearch of two-wheeled camaraderie, it\\'s a great way for kindred spirits to \\nget together.  Long may they flame.\\n\\n\\n\"Live to Flame -- Flame to Live\"\\t[centerbar]\\n\\nThis official motto of the Denizens of Doom refers to the ease with which \\nyou can gratuitously insult someone electronically, when you would not do \\nanything like that face to face.  These insults are known as \"flames\";  \\nissuing them is called \"flaming.\"  Flames often start when a member \\ndisagrees with something another member has posted over the network.  A \\ntypical, sophisticated, intelligent form of calm, reasoned rebuttal would be \\nsomething like:  \"What an incredibly stupid statement, you Spandex-clad \\nposeur!\"  This will guarantee that five other people will reply in defense \\nof the original poster, describing just what they think of you, your riding \\nability and your cat.\\n\\n------------------------------------------------------------------------\\n\\n          _The Denizens of Doom: The Saga Unfolds_\\n\\n                  by John Sloan  DoD #0011\\n\\nPeriodically the question \"What is DoD?\" is raised. This is one of\\nthose questions in the same class as \"Why is the sky blue?\", \"If there\\nis a God, why is there so much suffering in the world?\" and \"Why do\\nwomen inevitably tell you that you\\'re such a nice guy just before they\\ndump you?\", the kinds of questions steeped in mysticism, tradition,\\nand philosophy, questions that have inspired research and discussion\\nby philosophers in locker rooms, motorcycle service bays, and in the\\nhalls of academe for generations. \\n\\nA long, long time ago (in computer time, where anything over a few\\nminutes is an eternity and the halting problem really is a problem) on\\na computer far, far away on the net (topologically speaking; two\\nmachines in the same room in Atlanta might route mail to one another\\nvia a system in Chicago), a chap who wished to remain anonymous (but\\nwho was eventually assigned the DoD membership #1) wrote a satire of\\nthe various personalities and flame wars of rec.motorcycles, and\\nsigned it \"The Denizen of Doom\". Not wishing to identify himself, he\\nasked that stalwart individual who would in the fullness of time\\nbecome DoD #2 to post it for him. DoD #2, not really giving a whit\\nabout what other people thought and generally being a right thinking\\nindividual, did so.  Flaming and other amusements followed. \\n\\nHe who would become the holder of DoD membership #3 thought this was\\nthe funniest thing he\\'d seen in a while (being the sort that is pretty\\neasily amused), so he claimed membership in the Denizens of Doom\\nMotorcycle Club, and started signing his postings with his membership\\nnumber. \\n\\nPerhaps readers of rec.motorcycles were struck with the vision of a\\nmotorcycle club with no dues, no rules, no restrictions as to brand or\\nmake or model or national origin of motorcycle, a club organized\\nelectronically.  It may well be that readers were yearning to become a\\npart of something that would provide them with a greater identity, a\\ngestalt personality, something in which the whole was greater than the\\nsum of its parts.  It could also be that we\\'re all computer nerds who\\nwear black socks and sneakers and pocket protectors, who just happen\\nto also love taking risks on machines with awesome power to weight\\nratios, social outcasts who saw a clique that would finally be open\\nminded enough to accept us as members. \\n\\nIn a clear case of self fulfilling prophesy, The Denizens of Doom\\nMotorcycle Club was born. A club in which the majority of members have\\nnever met one another face to face (and perhaps like it that way), yet\\nfeel that they know one another pretty well (or well enough given some\\nof the electronic personalities in the newsgroup). A club organized\\nand run (in the loosest sense of the word) by volunteers through the\\nnetwork via electronic news and mail, with a membership/mailing list\\n(often used to organize group rides amongst members who live in the\\nsame region), a motto, a logo, a series of photo albums circulating\\naround the country (organized by DoD #9), club patches (organized by\\n#11), and even an MTV-style music video (produced by #47 and\\ndistributed on VHS by #18)! \\n\\nWhere will it end? Who knows? Will the DoD start sanctioning races,\\nplacing limits on the memory and clock rate of the on-board engine\\nmanagement computers? Will the DoD organize poker runs where each\\nparticipant collects a hand of hardware and software reference cards?\\nWill the DoD have a rally in which the attendees demand a terminal\\nroom and at least a 386-sized UNIX system? Only time will tell. \\n\\nThe DoD has no dues, no rules, and no requirements other than net\\naccess and a love for motorcycles. To become a member, one need only\\nask (although we will admit that who you must ask is one of the few\\nreally good club secrets). New members will receive via email a\\nmembership number and the latest copy of the membership list, which\\nincludes name, state, and email address. \\n\\nThe Denizens of Doom Motorcycle Club will live forever (or at least\\nuntil next year when we may decided to change the name). \\n\\n                  Live to Flame - Flame to Live\\n\\n------------------------------------------------------------------------\\n\\n     The DoD daemon as seen on the patches, pins, etc. by\\n\\n\\tChuck Rogers,  car377@druhi.att.com,  DoD #0003\\n \\n\\n                :-(           DoD            )-: \\n               :-(  x    __         __    x   )-:      \\n              :-(  x    / /         \\\\ \\\\    x   )-:     \\n             :-(  x    / / -\\\\-----/- \\\\ \\\\    x   )-:    \\n            :-(  L     | \\\\/  \\\\   /  \\\\/ |     F   )-:   \\n            :-(  I     | /    \\\\ /    \\\\ |     L   )-:   \\n            :-(  V     \\\\/ __   /   __ \\\\/     A   )-:   \\n            :-(  E     / /  \\\\     /  \\\\ \\\\     M   )-:   \\n            :-(        | |   \\\\   /   | |     E   )-:   \\n            :-(  T     | | . | _ | . | |         )-:   \\n            :-(  O     | \\\\___// \\\\\\\\___/ |     T   )-:   \\n            :-(         \\\\     \\\\_/     /      O   )-:   \\n            :-(  F       \\\\___     ___/           )-:   \\n            :-(  L        \\\\ \\\\     / /        L   )-:   \\n            :-(  A         \\\\ vvvvv /         I   )-:   \\n            :-(  M         | (   ) |         V   )-:   \\n            :-(  E         | ^^^^^ |         E   )-:   \\n             :-(  x        \\\\_______/        x   )-:    \\n              :-(  x                       x   )-:     \\n               :-(  x   rec.motorcycles   x   )-:\\n                :-(          USENET          )-:\\n\\n\\n------------------------------------------------------------------------\\n\\n                      The DoD\\n\\n              by the Denizen of Doom    DoD #1\\n \\nWelcome one and all to the flamingest, most wonderfullest newsgroup of\\nall time: wreck.mudder-disciples or is it reak.mudder-disciples? The\\nNames have been changes to protect the Guilty (riders) and Innocent\\n(the bikes) alike. If you think you recognize a contorted version of\\nyour name, you don\\'t. It\\'s just your guilt complex working against\\nyou. Read \\'em and weep. \\n\\nWe tune in on a conversation between some of our heros. Terrible\\nBarbarian is extolling the virtues of his Hopalonga Puff-a-cane to\\nReverend Muck Mudgers and Stompin Fueling-Injection: \\n\\nTerrible: This Hopalonga is the greatest... Beats BMWs dead!! \\n\\nMuck: I don\\'t mean to preach, Terrible, but lighten up on the BMW\\n     crowd eh?  I mean like I like riding my Yuka-yuka Fudgeo-Jammer\\n     11 but what the heck.  \\n\\nStompin: No way, the BMW is it, complete, that\\'s all man.\\n\\nTerrible: Nahhhh, you\\'re sounding like Heritick Ratatnack! Hey, at\\n     least he is selling his BMW and uses a Hopalonga Intercorruptor!\\n     Not as good as a Puff-a-cane, should have been called a\\n     Woosh-a-stream.\\n\\nStompin: You mean Wee-Stream.\\n\\nTerrible: Waddya going to do? Call in reinforcements???\\n\\nStompin: Yehh man. Here comes Arlow Scarecrow and High Tech. Let\\'s see\\n     what they say, eh? \\n\\nMuck: Now men, let\\'s try to be civil about this.\\n\\nHigh Tech: Hi, I\\'m a 9 and the BMW is the greatest.\\n\\nArlow: Other than my B.T. I love my BMW!\\n\\nTerrible: B.T.???\\n\\nArlow: Burley Thumpison, the greatest all American ride you can own.\\n\\nMuck: Ahhh, look, you\\'re making Terrible gag.\\n\\nTerrible: What does BMW stand for anyway??? \\n\\nMuck, Arlow, High: Beats Me, Wilhelm.\\n\\nTerrible: Actually, my name is Terrible. Hmmm, I don\\'t know either.\\n\\nMuck: Say, here comes Chunky Bear.\\n\\nChunky: Hey, Hey, Hey! Smarter than your average bear!\\n\\nTerrible: Hey, didn\\'t you drop your BMW???\\n\\nChunky: All right eh, a little BooBoo, but I left him behind. I mean \\n     even Villy Ogle flamed me for that! \\n\\nMuck: It\\'s okay, we all makes mistakes.\\n\\nOut of the blue the West coasters arrive, led by Tread Orange with\\nDill Snorkssy, Heritick Ratatnack, Buck Garnish, Snob Rasseller and\\nthe perenial favorite: Hooter Boobin Brush! \\n\\nHeritick: Heya Terrible, how\\'s yer front to back bias?\\n\\nTerrible: Not bad, sold yer BMW?\\n\\nHeritick: Nahhh.\\n\\nHooter: Hoot, Hoot.\\n\\nBuck: Nice tree Hooter, how\\'d ya get up there?\\n\\nHooter: Carbujectors from Hell!!!\\n\\nMuck: What\\'s a carbujector?\\n\\nHooter: Well, it ain\\'t made of alumican!!! Made by Tilloslert!!\\n\\nMuck: Ahh, come on down, we aren\\'t going to flame ya, honest!!\\n\\nDill: Well, where do we race?\\n\\nSnob: You know, Chunky, we know about about your drop and well, don\\'t\\n     ride! \\n\\nMuck: No! No! Quiet!\\n\\nTread: BMW\\'s are the greatest in my supreme level headed opinion.\\n     They even have luggage made by Sourkraut!\\n\\nHigh: My 9 too!\\n\\nTerrible, Heritick, Dill, Buck: Nahhhhh!!!\\n\\nStompin, Tread, High, Chunky, Snob: Yesss Yessssss!!!\\n\\nBefore this issue could be resolved the Hopalonga crew called up more\\ncohorts from the local area including Polyanna Stirrup and the\\ninfamous Booster Robiksen on his Cavortin! \\n\\nPolyanna: Well, men, the real bikers use stirrups on their bikes like\\n     I use on my Hopalonga Evening-Bird Special. Helpful for getting\\n     it up on the ole ventral stand!  \\n\\nTerrible: Hopalonga\\'s are great like Polyanna says and Yuka-Yuka\\'s and\\n     Sumarikis and Kersnapis are good too! \\n\\nBooster: I hate Cavortin.\\n\\nAll: WE KNOW, WE KNOW.\\n\\nBooster: I love Cavortin.\\n\\nAll: WE KNOW WE KNOW.\\n\\nMuck: Well, what about Mucho Guzlers and Lepurras?\\n\\nSnob, Tread: Nawwwwww.\\n\\nMuck: What about a Tridump?\\n\\nTerrible: Isn\\'t that a chewing gum?\\n\\nMuck: Auggggg, Waddda about a Pluck-a-kity?\\n\\nHeritick: Heyya Muck, you tryin\\' to call up the demon rider himself?\\n\\nMuck: No, no. There is more to Mudder-Disciples than arguing about make.\\n\\nTwo more riders zoom in, in the form of Pill Turret and Phalanx Lifter.\\nPill: Out with dorsal stands and ventral stands forever.\\n\\nPhalanx: Hey, I don\\'t know about that.\\n\\nAnd Now even more west coasters pour in.\\nRoad O\\'Noblin: Hopalonga\\'s are the greatest!\\n\\nMaulled Beerstein: May you sit on a bikejector!\\n\\nSuddenly more people arrived from the great dark nurth:\\nKite Lanolin: Hey, BMW\\'s are great, men.\\n\\nRobo-Nickie: I prefer motorcycle to robot transformers, personally.\\n\\nMore riders from the west coast come into the discussion:\\nAviator Sourgas: Get a Burley-Thumpison with a belted-rigged frame.\\n\\nGuess Gasket: Go with a BMW or Burley-Thumpison.\\n\\nWith a roar and a screech the latest mudder-disciple thundered in. It\\nwas none other that Clean Bikata on her Hopalonga CaBammerXorn. \\nClean: Like look, Hopalonga are it but only CaBammerXorns. \\n\\nMuck: Why??\\n\\nClean: Well, like it\\'s gotta be a 6-banger or nothin.\\n\\nMuck: But I only have a 4-banger.\\n\\nClean: No GOOD!\\n\\nChunky: Sob, some of us only have 2-bangers!\\n\\nClean: Inferior!\\n\\nStompin: Hey, look, here\\'s proof BMW\\'s are better. The Bimmer-Boys\\nburst into song: (singing) Beemer Babe, Beemer Babe give me a\\nthrill... \\n\\nRoad, Terrible, Polyanna, Maulled, Dill etc.: Wadddoes BMW stand for? \\n\\nHeritick, Stompin, Snob, Chunky, Tread, Kite, High, Arlow: BEAT\\'S ME,\\n     WILHEM! \\n\\nRoad, Terrible, Polyanna, Maulled, Dill etc.: Oh, don\\'t you mean BMW? \\n\\nAnd so the ensuing argument goes until the skies clouded over and the\\nthunder roared and the Greatest Mudder-Disciple (G.M.D.) of them all\\nboomed out.\\nG.M.D.: Enough of your bickering! You are doomed to riding\\n     Bigot & Suction powered mini-trikes for your childish actions. \\n\\nAll: no, No, NO!!! Puhlease.\\n\\nDoes this mean that all of the wreck.mudder-disciples will be riding\\nmini-trikes?  Are our arguing heros doomed?  Tune in next week for the\\nnext gut wretching episode of \"The Yearning and Riderless\" with its\\never increasing cast of characters.  Where all technical problems will\\nbe flamed over until well done.  Next week\\'s episode will answer the\\nquestion of: \"To Helmet or Not to Helmet\" will be aired, this is heady\\nmaterial and viewer discretion is advised. \\n\\n------------------------------------------------------------------------\\n\\n          Script for the Denizens of Doom Anthem Video\\n\\n                by Jonathan E. Quist   DoD #94\\n\\n\\n[Scene:  A sterile engineering office.  A lone figure, whom we\\'ll call\\nChuck, stands by a printer output bin, wearing a white CDC lab coat,\\nwith 5 mechanical pencils in a pocket protector.] \\n\\n(editor\\'s note: For some reason a great deal of amusement was had at\\nthe First Annual DoD Uni-Coastal Ironhorse Ride & Joust by denizens\\nreferring to each other as \"Chuck\". I guess you had to be there. I\\nwasn\\'t.) \\n\\nChuck:  I didn\\'t want to be a Software Systems Analyst,\\n cow-towing to the whims of a machine, and saying yessir, nosir,\\n may-I-have-another-sir.  My mother made me do it.  I wanted\\n to live a man\\'s life,\\n[Music slowly builds in background]\\n riding Nortons and Triumphs through the highest mountain passes\\n and the deepest valleys,\\n living the life of a Motorcyclist;\\n doing donuts and evading the police;\\n terrorizing old ladies and raping small children;\\n eating small dogs for tea (and large dogs for dinner).  In short,\\n\\n\\tI Want to be      A Denizen!\\n\\n[Chuck rips off his lab coat, revealing black leather jacket (with\\nfringe), boots, and cap.  Scene simultaneously changes to the top of\\nan obviously assaulted Rollins Pass.  A small throng of Hell\\'s Angels\\nsit on their Harleys in the near background, gunning their engines,\\nshowering lookers-on with nails as they turn donuts, and leaking oil\\non the tarmac.  Chuck is standing in front of a heavily chromed Fat\\nBoy.] \\n\\nChuck [Sings to the tune of \"The Lumberjack Song\"]:\\n\\nI\\'m a Denizen and I\\'m okay,\\nI flame all night and I ride all day.\\n\\n[Hell\\'s Angels Echo Chorus, surprisingly heavy on tenors]:\\nHe\\'s a Denizen and he\\'s okay,\\nHe flames all night and he rides all day.\\n\\nI ride my bike;\\nI eat my lunch;\\nI go to the lavat\\'ry.\\nOn Wednesdays I ride Skyline,\\nRunning children down with glee.\\n\\n[Chorus]:\\nHe rides his bike;\\nHe eats his lunch;\\nHe goes to the lavat\\'ry.\\nOn Wednesdays he rides Skyline,\\nRunning children down with glee.\\n\\n[Chorus refrain]:\\n\\'Cause He\\'s a Denizen...\\n\\nI ride real fast,\\nMy name is Chuck,\\nIt somehow seems to fit.\\nI over-rate the worst bad f*ck,\\nBut like a real good sh*t.\\n\\nOh, I\\'m a Denizen and I\\'m okay!\\nI flame all night and I ride all day.\\n\\n[Chorus refrain]:\\nOh, He\\'s a Denizen...\\n\\nI wear high heels\\nAnd bright pink shorts,\\n full leathers and a bra.\\nI wish I rode a Harley,\\n just like my dear mama.\\n\\n[Chorus refrain]\\n\\n------------------------------------------------------------------------\\n\\n                    Why you have to be killed.\\n\\nWell, the first thing you have to understand (just in case you managed\\nto read this far, and still not figure it out) is that the DoD started\\nas a joke. And in the words of one Denizen, it intends to remain one.\\n\\nSometime in the far distant past, a hapless newbie asked: \"What does DoD\\nstand for? It\\'s not the Department of Defense is it?\" Naturally, a\\nDenizen who had watched the movie \"Top Gun\" a few times too many rose\\nto the occasion and replied:\\n\\n\"That\\'s classified, we could tell you, but then we\\'d have to kill you.\"\\n\\nAnd the rest is history.\\n\\nA variation on the \"security\" theme is to supply disinformation about\\nwhat DoD stands for. Notable contributions (and contributers, where\\nknown) include:\\n\\nDaughters of Democracy (DoD 23)\\t\\tDoers of Donuts\\nDancers of Despair (DoD 9)\\t\\tDebasers of Daughters\\nDickweeds of Denver\\t\\t\\tDriveway of Death\\nDebauchers of Donuts\\t\\t\\tDumpers of Dirtbikes\\n\\nNote that this is not a comprehensive list, as variations appear to be\\nlimited only by the contents of one\\'s imagination or dictionary file.\\n\\n------------------------------------------------------------------------\\n\\n                     The rec.moto.photo archive\\n\\nFirst a bit of history, this all started with Ilana Stern and Chuck\\nRogers organizing a rec.motorcycles photo album. Many copies were made,\\nand several sets were sent on tours around the world, only to vanish in\\nunknown locations. Then Bruce Tanner decided that it would be appropriate\\nfor an electronic medium to have an electronic photo album. Bruce has not\\nonly provided the disk space and ftp & e-mail access, but he has taken\\nthe time to scan most of the photos that are available from the archive.\\n\\nNot only can you see what all these folks look like, you can also gawk\\nat their motorcycles. A few non-photo files are available from the\\nserver too, they include the DoD membership list, the DoD Yellow Pages,\\nthe general rec.motorcycles FAQ, and this FAQ posting.\\n\\nHere are a couple of excerpts from from messages Bruce posted about how\\nto use the archive.\\n\\n**********************************************************\\n\\nVia ftp:\\n\\ncerritos.edu [130.150.200.21]\\n\\nVia e-mail:\\n\\nThe address is server@cerritos.edu.  The commands are given in the body of the\\nmessage.  The current commands are DIR and SEND, given one per line.  The\\narguments to the commands are VMS style file specifications.  For\\nrec.moto.photo the file spec is [DOD]file.  For example, you can send:\\n\\ndir [dod]\\nsend [dod]bruce_tanner.gif\\nsend [dod]dodframe.ps\\n\\nand you\\'ll get back 5 mail messages; a directory listing, 3 uuencoded parts\\nof bruce_tanner.gif, and the dodframe.ps file in ASCII.\\n\\nOh, wildcards (*) are allowed, but a maximum of 20 mail messages (rounded up to\\nthe next whole file) are send.  A \\'send [dod]*.gif\\' would send 150 files of\\n50K each; not a good idea.\\n-- \\nBruce Tanner        (213) 860-2451 x 596    Tanner@Cerritos.EDU\\nCerritos College    Norwalk, CA             cerritos!tanner\\n\\n**********************************************************\\n\\nA couple of comments: Bruce has put quite a bit of effort into this, so\\nwhy not drop him a note if you find the rec.moto.photo archive useful?\\nSecond, since Bruce has provided the server as a favor, it would be kind\\nof you to access it after normal working hours (California time). \\n\\n------------------------------------------------------------------------\\n\\n                      Patches? What patches?\\n\\nYou may have heard mention of various DoD trinkets such as patches &\\npins. And your reaction was probably: \"I want!\", or \"That\\'s sick!\", or\\nperhaps \"That\\'s sick! I want!\"\\n\\nWell, there\\'s some good news and some bad news. The good news is that\\nthere\\'s been an amazing variety of DoD-labeled widgets created. The bad\\nnews is that there isn\\'t anywhere you can buy any of them. This isn\\'t\\nbecause of any \"exclusivity\" attempt, but simply because there is no\\n\"DoD store\" that keeps a stock. All of the creations have been done by\\nindividual Denizens out of their own pockets. The typical procedure is\\nsomeone says \"I\\'m thinking of having a DoD frammitz made, they\\'ll cost\\n$xx.xx, with $xx.xx going to the AMA museum. Anyone want one?\" Then\\norders are taken, and a batch of frammitzes large enough to cover the\\npre-paid orders is produced (and quickly consumed). So if you want a\\nDoD doodad, act quickly the next time somebody decides to do one. Or\\nproduce one yourself if you see a void that needs filling, after all\\nthis is anarchy in action.\\n\\nHere\\'s a possibly incomplete list of known DoD merchandise (and\\nperpetrators). Patches (DoD#11), pins (DoD#99), stickers (DoD#99),\\nmotorcycle license plate frames (DoD#216), t-shirts (DoD#99), polo shirts\\n(DoD#122), Zippo lighters (DoD#99) [LtF FtL], belt buckles (DoD#99), and\\npatches (DoD#99) [a second batch was done (and rapidly consumed) by\\npopular demand].\\n\\nAll \"profits\" have been donated to the American Motorcyclist Association\\nMotorcycle Heritage Museum. As of June 1992, over $5500 dollars has been\\ncontributed to the museum fund by the DoD. If you visit the museum,\\nyou\\'ll see a large plaque on the Founders\\' Wall in the name of \"Denizens\\nof Doom, USENET, The World\", complete with a DoD pin.\\n\\n------------------------------------------------------------------------\\n\\nHere\\'s a letter from the AMA to the DoD regarding our contributions.\\n\\n~Newsgroups: rec.motorcycles\\n~From: Arnie Skurow <arnie@magnus.acs.ohio-state.edu>\\n~Subject: A letter from the Motorcycle Heritage Museum\\n~Date: Mon, 13 Apr 1992 11:04:58 GMT\\n\\nI received the following letter from Jim Rogers, director of the Museum,\\nthe other day.\\n\\n\"Dear Arnie and all members of the Denizens of Doom:\\n\\nCongratulations and expressions of gratitude are in order for you and the\\nDenizens of Doom!  With your recent donation, the total amount donated is\\nnow $5,500.  On behalf of the AMHF, please extend my heartfeld gratitude\\nto all the membership of the Denizens.  The club\\'s new plaque is presently\\nbeing prepared.  Of course, everyone is invited to come to the museum to \\nsee the plaque that will be installed in our Founders Foyer.  By the way,\\nI will personally mount a Denizens club pin on the plaque.  Again, thank \\nyou for all your support, which means so much to the foundation, the\\nmuseum, and the fulfillment of its goals.\\n\\n                                Sincerely,\\n\\n\\n                                Jim Rogers, D.O.D. #0395\\n                                Director\\n\\nP.S.  Please post on your computer bulletin board.\"\\n\\nAs you all know, even though the letter was addressed to me personally,\\nit was meant for all of you who purchased DoD goodies that made this\\namount possible.\\n\\nArnie\\n\\n------------------------------------------------------------------------\\n\\nThe Rules, Regulations, & Bylaws of the Denizens of Doom Motorcycle Club\\n\\nFrom time to time there is some mention, discussion, or flame about the\\nrules of the DoD. In order to fan the flames, here is the complete text\\nof the rules governing the DoD.\\n\\n\\t\\t\\tRule #1. There are no rules.\\n\\t\\t\\tRule #0. Go ride.\\n\\n------------------------------------------------------------------------\\n\\n\\t\\tOther rec.motorcycles information resources.\\n\\nThere are several general rec.motorcycles resources that may or may not\\nhave anything to do with the DoD. Most are posted on a regular basis,\\nbut they can also be obtained from the cerritos ftp/e-mail server (see\\nthe info on the photo archive above).\\n\\nA general rec.motorcycles FAQ is maintained by Dave Williams.\\nCerritos filenames are FAQn.TXT, where n is currently 1-5.\\n\\nThe DoD Yellow Pages, a listing of motorcycle industry vendor phone\\nnumbers & addresses, is maintained by bob pakser.\\nCerritos filename is YELLOW_PAGES_Vnn, where n is the rev. number.\\n\\nThe List of the DoD membership is maintained by The Keeper of the List.\\nCerritos filename is DOD.LIST.\\n\\nThis WitDoD FAQ (surprise, surprise!) is maintained by yours truly.\\nCerritos filename is DOD_FAQ.TXT.\\n\\nAdditions, corrections, etc. for any of the above should be aimed at\\nthe keepers of the respective texts.\\n\\n------------------------------------------------------------------------\\n\\n(Loki Jorgenson loki@Physics.McGill.CA) has provided an archive site\\nfor motorcycle and accessory reviews, here\\'s an excerpt from his\\nperiodic announcement.\\n\\n**********************************************************\\n\\n\\tThe Rec.Motorcycles.Reviews Archives (and World Famous Llama\\n  Emporium) contains a Veritable Plethora (tm) of bike (and accessories)\\n  reviews, written by rec.moto readers based on their own experiences.\\n  These invaluable gems of opinion (highly valued for their potential to\\n  reduce noise on the list) can be accessed via anonymous FTP, Email\\n  server or by personal request:\\n\\n  Anonymous FTP:\\t\\tftp.physics.mcgill.ca (132.206.9.13)\\n\\t\\t\\t\\t\\tunder ~ftp/pub/DoD\\n  Email archive server:\\t\\trm-reviews@ftp.physics.mcgill.ca\\n  Review submissions/questions:\\trm-reviews@physics.mcgill.ca\\n\\n  NOTE: There is a difference in the addresses for review submission\\n      and using the Email archive server (ie. an \"ftp.\").\\n\\n  To get started with the Email server, send an Email message with a line\\n  containing only \"send help\".  \\n\\n  NOTE: If your return address appears like\\n\\tdomain!subdomain!host!username\\n      in your mail header, include a line like (or something similar)\\n\\tpath username@host.subdomain.domain \\n\\n\\tIf you are interested in submitting a review of a bike that you\\n  already own(ed), PLEASE DO!  There is a template of the format that the\\n  reviews are kept in (more or less) available at the archive site .\\n  For those who have Internet access but are unsure of how anonymous\\n  FTP works, an example script is available on request.\\n\\n**********************************************************\\n\\nReviews of any motorcycle related accessory or widget are welcome too.\\n\\n------------------------------------------------------------------------\\n\\n            Updated stats & rec.motorcycles rides info\\n\\nSome of the info cited above in various places tends to be a moving\\ntarget. Rather than trying to catch every occurence, I\\'m just sticking\\nthe latest info down here.\\n\\nEstimated rec.motorcycles readership: 35K  [news.groups]\\n \\nApproximate DoD Membership: 975  [KotL]\\n\\nDoD contributions to the American Motorcyclist Association Motorcycle\\nHeritage Museum. Over $5500  [Arnie]\\n \\n                        Organized (?) Rides:\\n\\nSummer 1992 saw more organized rides, with the Joust in its third\\nyear, and the Ride & Feed going strong, but without the Rollins Pass\\ntrip due to the collapse of a tunnel.  The East Coast Denizens got\\ntogether for the Right Coast Ride (RCR), with bikers from as far north\\nas NH, and as far south as FL meeting in the Blueridge Mountains of\\nNorth Carolina.  The Pacific Northwest crew organized  the first Great\\nPacific Northwest Dryside Gather (GPNDG), another successful excuse for\\nriding motorcycles, and seeing the faces behind the names we all have\\ncome to know so well.  [Thanks to Ed Green for the above addition.]\\n\\nAlso worth mentioning are: The first rec.moto.dirt ride, held in the\\nMoab/Canyonlands area of southern Utah. Riders from 5 states showed up,\\nriding everything from monster BMWs to itty-bitty XRs to almost-legal\\n2-strokes.  And though it\\'s not an \"official\" (as if anything could be\\nofficial with this crowd) rec.moto event, the vintage motorcycle races\\nin Steamboat Springs, Colorado always provides a good excuse for netters\\nto gather.  There\\'s also been the occasional Labor Day gather in Utah.\\nEuropean Denizens have staged some gathers too.  (Your ad here,\\nreasonable rates!)\\n------------------------------------------------------------------------\\n-- \\nBlaine Gardner @ Evans & Sutherland   580 Arapeen Drive, SLC, Utah 84108\\n       blgardne@javelin.sim.es.com     BIX: blaine_g@bix.com      FJ1200\\nHalf of my vehicles and all of my computers are Kickstarted.      DoD#46\\n-- \\nBlaine Gardner @ Evans & Sutherland   580 Arapeen Drive, SLC, Utah 84108\\n       blgardne@javelin.sim.es.com     BIX: blaine_g@bix.com      FJ1200\\nHalf of my vehicles and all of my computers are Kickstarted.      DoD#46\\n', 'Newsgroups: rec.motorcycles\\nPath: cantaloupe.srv.cs.cmu.edu!rochester!udel!darwin.sura.net!wupost!uunet!murphy!jpradley!magpie!manes\\nFrom: manes@magpie.linknet.com (Steve Manes)\\nSubject: Re: Oops! Oh no!\\nOrganization: Manes and Associates, NYC\\nDate: Thu, 1 Apr 1993 17:43:29 GMT\\nMessage-ID: <C4tFwI.DLp@magpie.linknet.com>\\nX-Newsreader: TIN [version 1.1 PL9]\\nReferences: <1pd49g$a8m@vtserf.cc.vt.edu>\\nLines: 53\\n\\nWm. L. Ranck (ranck@joesbar.cc.vt.edu) wrote:\\n:    I hate to admit this, and I\\'m still mentally kicking myself for it.\\n: I rode the brand new K75RT home last Friday night.  100 miles in rain\\n: and darkness.  No problems.  Got it home and put it on the center stand.\\n:    The next day I pushed it off the center stand in preparation for going\\n: over to a friend\\'s house to pose.  You guessed it.  It got away from me\\n: and landed on its right side.  \\n:    Scratched the lower fairing, cracked the right mirror, and cracked the\\n: upper fairing.  \\n:    *DAMN* am I stupid!  It\\'s going to cost me ~$200 to get the local\\n: body shop to fix it.  And that is after I take the fairing off for them.\\n: Still, that\\'s probably cheaper than the mirror alone if I bought a \\n: replacement from BMW.\\n\\nYou got off cheap.  My sister\\'s ex-boyfriend was such an incessant pain\\nin the ass about wanting to ride my bikes (no way, Jose) that I\\nfinally took him to Lindner\\'s BMW in New Canaan, CT last fall where\\nI had seen a nice, used K100RS in perfect condition.  After telling\\neveryone in the shop his Norton war stories from fifteen years ago,\\nsigning the liability waiver, and getting his pre-flight, off he went...\\n\\nWell, not quite.  I walked out of a pizza shop up the street,\\nfeeling good about myself (made my sister\\'s boyfriend happy and got\\nthe persistent wanker off my ass for good), heard the horrendous\\nracket of an engine tortured to its red line and then a crash.  I\\nsaw people running towards the obvious source of the disturbance...\\nJeff laying under the BMW with the rear wheel spinning wildly and\\nsomeone groping for the kill switch.  I stared in disbelief with\\na slice hanging out of my mouth as Matty, the shop manager, slid\\nup beside me and asked, \"Friend of yours, Steve?\".  \"Shit, Matty,\\nit could have been worse.  That could been my FLHS!\"\\n\\nJeff hadn\\'t made it 10 inches.  Witnesses said he lifted his feet\\nbefore letting out the clutch and gravity got the best of him.\\nJeff claimed that the clutch didn\\'t engage.  Matty was quick.\\nWhile Jeff was still stuttering in embarrassed shock he managed\\nto snatch Jeff\\'s credit card for a quick imprint and signature.  Twenty\\nminutes later, when Jeff\\'s color had paled to a flush, Matty\\npresented him with an estimate of $580 for a busted right mirror\\nand a hairline crack in the fairing.  That was for fixing the crack\\nand masking the damaged area, not a new fairing.  Or he could buy the\\nbike.\\n\\nI\\'m not sure what happened later as my sister split up with Jeff shortly\\nafterwards (to hook up with another piece of work) except that Matty\\ntold me he ran the charge through in December and that it went\\nuncontested.\\n\\n\\n-- \\nStephen Manes\\t\\t\\t\\t\\t   manes@magpie.linknet.com\\nManes and Associates\\t\\t\\t\\t   New York, NY, USA  =o&>o\\n\\n', 'Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!network.ucsd.edu!news.service.uci.edu!ucivax!megatek!randy\\nFrom: randy@megatek.com (Randy Davis)\\nNewsgroups: rec.motorcycles\\nSubject: Re: A Miracle in California\\nMessage-ID: <1993Apr5.223941.11539@megatek.com>\\nDate: 5 Apr 93 22:39:41 GMT\\nArticle-I.D.: megatek.1993Apr5.223941.11539\\nReferences: <95.602CV3dTx01@JUTS.ccc.amdahl.com> <1ppvof$92a@seven-up.East.Sun.COM>\\nSender: randy@megatek.com (Randy Davis)\\nReply-To: randy@megatek.com\\nOrganization: Megatek Corporation, San Diego, California\\nLines: 15\\n\\nIn article <1ppvof$92a@seven-up.East.Sun.COM> egreen@East.Sun.COM writes:\\n|Bikers wave to bikers the world over.  Whether or not Harley riders\\n|wave to other bikers is one of our favorite flame wars...\\n\\n  I am happy to say that some Harley riders in our area are better than most\\nthat are flamed about here: I (riding a lowly sport bike, no less) and my\\ngirlfriend were the recipient of no less than twenty waves from a group of\\nat least twenty-five Harley riders.  I was leading a group of about four\\nsport bikes at the time (FJ1200/CBR900RR/VFR750).  I initiated *some* of the\\nwaves, but not all.  It was a perfect day, and friendly riders despite some\\nbrand differences made it all the better...\\n\\nRandy Davis                            Email: randy@megatek.com\\nZX-11 #00072 Pilot                            {uunet!ucsd}!megatek!randy\\nDoD #0013\\n', 'Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!gatech!news-feed-1.peachnet.edu!umn.edu!msus1.msus.edu!stafford.winona.msus.edu!user\\nNewsgroups: rec.motorcycles\\nSubject: Re: more DoD paraphernalia\\nMessage-ID: <Stafford-050493122618@stafford.winona.msus.edu>\\nFrom: Stafford@Vax2.Winona.MSUS.Edu (John Stafford)\\nDate: 5 Apr 93 13:30:02 -0600\\nFollowup-To: rec.motorcycles\\nReferences: <1993Apr5.145301.6763@rd.hydro.on.ca> <1pppnrINNitg@cronkite.Central.Sun.COM>\\nDistribution: world\\nOrganization: Winona State University\\nNntp-Posting-Host: stafford.winona.msus.edu\\nLines: 11\\n\\nIn article <1pppnrINNitg@cronkite.Central.Sun.COM>,\\ndoc@webrider.central.sun.com (Steve Bunis) wrote:\\n> \\n> How about a decal of thicker vinyl? \\n\\n  How about a Geeky temporary tatoo?  I mean, why should the \\n  RUBs be exempt from a little razzing.\\n\\n====================================================\\nJohn Stafford   Minnesota State University @ Winona\\n                    All standard disclaimers apply.\\n']\n",
      "['100521', '101666', '102151', '102584', '102585']\n",
      "['Path: cantaloupe.srv.cs.cmu.edu!rochester!udel!bogus.sura.net!jhunix.hcf.jhu.edu!jhunix.hcf.jhu.edu!not-for-mail\\nFrom: admiral@jhunix.hcf.jhu.edu (Steve C Liu)\\nNewsgroups: rec.sport.baseball\\nSubject: spring records\\nDate: 17 Mar 1993 15:30:03 -0500\\nOrganization: Homewood Academic Computing, Johns Hopkins University, Baltimore, Md, USA\\nLines: 26\\nSender: admiral@jhunix.hcf.jhu.edu\\nDistribution: world\\nExpires: 5/9/93\\nMessage-ID: <1o81obINN9f7@jhunix.hcf.jhu.edu>\\nNNTP-Posting-Host: jhunix.hcf.jhu.edu\\nSummary: Earl Weaver Commandments\\n\\n\\tThe Orioles\\' pitching staff again is having a fine exhibition season.\\nFour shutouts, low team ERA, (Well, I haven\\'t gotten any baseball news since\\nMarch 14 but anyways) Could they contend, yes. Could they win it all?  Maybe.\\n\\nBut for all those fans of teams with bad spring records, remember Earl\\nWeaver\\'s first law of baseball (From his book on managing)\\n\\nNo one gives a damn in July if you lost a game in March. :)\\n\\nBTW, anyone have any idea on the contenders for the O\\'s fifth starter?\\nIt\\'s pretty much set that Sutcliffe, Mussina, McDonald and Rhodes are the\\nfirst four in the rotation.\\n\\nHere at Johns Hopkins University where the mascot is the Blue Jay :(,\\ntheir baseball team logo was the Toronto club\\'s logo. Now it\\'s a \\nanatomically correct blue jay. God, can\\'t they think of an original idea?\\nIt\\'s even in the same pose as the baltimore oriole on the O\\'s hats.\\nHow many people realize that the bird is really called a baltimore oriole?\\n__________________________________________________________________________\\n|Admiral Steve C. Liu        Internet Address: admiral@jhunix.hcf.jhu.edu|\\n|\"Committee for the Liberation and Intergration of Terrifying Organisms  |\\n|and their Rehabilitation Into Society\" from Red Dwarf - \"Polymorph\"     |\\n|****The Bangles are the greatest female rock band that ever existed!****|\\n|   This sig has been brought to you by... Frungy! The Sport of Kings!   |\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n \\n', 'Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!husc-news.harvard.edu!hsdndev!wupost!tulane!ukma!smith\\nNewsgroups: rec.sport.baseball\\nSubject: Re: Eck vs Rickey (was Re: Rickey\\'s whining again)\\nMessage-ID: <C4oF8s.ECv@ms.uky.edu>\\nFrom: smith@ms.uky.edu (Brian Smith)\\nDate: 30 Mar 93 00:41:15 GMT\\nExpires: Sat, 1 May 1993 04:00:00 GMT\\nReferences: <1993Mar11.061739.21570@mnemosyne.cs.du.edu> <C4EsxE.Ly2@megatest.com> <6998@blue.cis.pitt.edu>\\nDistribution: usa\\nOrganization: University Of Kentucky, Dept. of Math Sciences\\nLines: 169\\n\\nIn article <6998@blue.cis.pitt.edu> genetic+@pitt.edu (David M. Tate) writes:\\n>I\\'ve read all of the followups to this, but I thought I\\'d go back to the\\n>original article to make specific comments about the method:\\n>\\n>\\n>jao@megatest.com (John Oswalt) said:\\n>>\\n>>He has obtained the play by play records, in computer readable\\n>>form, for every major league baseball game for the past several years.\\n>>He devised an algorithm which I call \"sum-over-situations\", and wrote\\n>>a computer program to calculate every major league players contribution\\n>>using it.  It works like this:\\n>>\\n>>Look at every \"situation\" in every game in a baseball season.  A\\n>>situation is determined by inning, score, where the baserunners are,\\n>>and how many outs there are.  For each situation, count how many\\n>>times the team eventually won the game that the situation occured in,\\n>>and divide by the number of times the situation came up, to come up with\\n>>a \"value\" for that situation.\\n>\\n>This was first done by George Lindsey in the late \\'50s/early \\'60s, and\\n>reported in \\n>\\n>\\tArticle:\\tAn Investigation of Strategies in Baseball\\n>\\tAuthor:\\t\\tGeorge R. Lindsey\\n>\\tJournal:\\tOperations Research\\n>\\tIssue:\\t\\tVolume 11 #4, July-August 1963, pp. 477-501\\n>\\n>Later, Pete Palmer did the same thing using simulated seasons to generate\\n>a larger set of data to avoid the kind of small-sample anomalies that other\\n>people have worried about.  He reported this in _The_Hidden_Game_of_Baseball_\\n>(with John Thorn).  Gary Skoog modified the method a bit and did some work\\n>on what he called a \"Value Added\" measure based on these situational values.\\n>His were based directly on marginal runs, though, not on win probabilities.\\n>These results, as applied to the 198? season, were reported in one of the\\n>Bill James Baseball Abstract books (1987?  Help me out here, somebody...)\\n>\\n>>For example, a situation might be inning 3, score 2-0, runner on second\\n>>and no outs.  There were 4212 regular season major league games last\\n>>year.  (With the Rockies and Marlins, there will be more this year.)\\n>>Say this situation came up in 100 of those, and the team ahead won\\n>>75 of them.  Then the value of this situation is 0.75.\\n>\\n>[Description of method: look at change in win probability based on the at bat\\n> plus any baserunning, and credit/debit the player by that amount each time\\n> he gets a plate appearance.]\\n>\\n>>Now, for each player, sum up all his at-bat and base-running values\\n>>for the season to obtain an overall value for that player.  Obviously\\n>>the sum of all players\\' values for each game, and for the season as a\\n>>whole, will be 0.\\n>\\n>That\\'s only because you always credit +x to the batter and -x to the pitcher;\\n>there\\'s no validation involved.\\n>\\n>OK, there\\'s a very big problem here that nobody has yet commented on: you\\'re\\n>adding *probabilities*, and probabilities don\\'t add.  Runs you can add; the\\n>total team runs breaks down into how many runs Joe contributed plus how many\\n>runs Fred contributed, etc.  But probabilities don\\'t work that way.  If Bob\\n>increases his team\\'s chance of winning by 1% in each of 400 PAs, that does\\n>not mean that Bob increased his team\\'s chance of winning by 400%.  In fact,\\n>it doesn\\'t mean *anything*, because the units are screwy.\\n\\nI agree and disagree.  John is saying that the batters efforts will result\\nin 4 more wins then losses.  While you are probably correct that 400%\\ndoes not mean 4 more wins then losses, it means something.  I would\\nrather have a player who increased my teams chances of winning by 1% in\\neach of 400 PAs then I would a player who increased my chances of winning\\nby .5% in each of 400 PAs.  Thus, there appears to me to be an obvious\\npositive association between John\\'s statistic and winning games.  Thus,\\nbefore you disregard this stat, it appears to me that further study must\\ngo into what sort of relationship there is.\\n\\n>Consider an example:  Bob hits a 2-out solo HR in the bottom of the first;\\n>about .12 on your scale.  He does the same thing again in the fourth, with\\n>the score tied, for another .14.  And again, in the seventh, with the score\\n>tied, for another .22.  And, finally, in the ninth to win the game by a score\\n>of 7-6, for a value of 0.5.  Bob hit 4 solo HR in 4 plate appearances, and\\n>was credited by your method with .12 + .14 + .22 + .5 = .98.  But what does\\n>that mean?  Was Bob 98% responsible for the win?  Certainly not; the defense\\n>is *always* 50% responsible (if you include pitching in that), and Bob wasn\\'t\\n>pitching.  In fact, Bob was only 4/7 of the offense (which is a lot, but not\\n>even close to 100%).  Furthermore, what about the other 3 team runs?  Say\\n>they all came on solo HR by Fred; then Fred was hitting HR to tie up the game,\\n>which are just as valuable as HR to take the lead (see Lindsey), and Fred will\\n>himself have accrued a good .4 rating or so.  So Fred and Bob combined have\\n>amassed 138% of a win IN ONE GAME.  There\\'s clearly a problem here.\\n\\nThe only problem here is an insistance that these number mean exactly\\nhow many wins the team has.  First, we are using averages over many\\nseasons and applying them to one game.  Second, remember some players\\nperformance take away from the chance of you winning.  That is a\\nplayer who gets an out gets a \"negative probability\" in most cases.\\nThus, I\\'m not sure in any given game when you add up all the numbers\\nfor a team who won that they will add up to 1 in that game.  Sometimes,\\nthey will add up to more then one sometime, less than one.  Also,\\nthe pitchers\\' bad performances (giving up 6 runs) may have given\\nthem a large negative percentage for that game.  Also, any batter that\\npulled an 0-4 night would give large negatives.  \\n\\n\\n\\n>>Greg thinking about the right things, but his intuition is off the\\n>>mark.  Closers are enormously important.  The total number of runs\\n>>value is outweighed by when they come, or are prevented from comming.\\n>>The doubling which Greg allows is not enough.\\n>\\n>In another article, I proposed a test of this.  We can predict a team\\'s \\n>won/lost record quite accurately by looking at how many runs *total* they\\n>score and allow, without regard to when those runs score in the game.  If\\n>late runs are really more important than early runs, then looking only at\\n>late runs should lead to a *better* predictor, right?\\n\\nNo, but really only because you have a smaller sample size.  I would\\nthink however, that the number of runs you score in the first inning\\nwould be just as good as a prediction as how many runs you score \\nin the last inning.  And, realize something else a closer usually\\ncomes in in a close situation, not a blow out.  It is hard to argue\\nthat any runs that a closer gives up in a game have equal importance\\nto those given up in the first inning.  Look, a closer giving up runs\\noften means a team will lose many games.  On, the other hand a starter\\nwho gives up runs often still leaves his team a chance to win.  The\\noffence has many more outs to do something about.  But, I am not\\nsaying all late inning situations are equally important either.  If\\nI am down 8 runs in the ninth, it really does not matter how many\\nruns my pitcher gives up in the ninth.       \\n\\n>Here\\'s another thought experiment: apply this method to basketball.  What\\n>you find is that points scored in the first *half* of the game have almost\\n>exactly no value, because no lead is safe with an entire half yet to play.\\n>Furthermore, the sub in off the bench who sinks the winning free throws with\\n>no time on the clock gets a +1.0 for the game, while the star forward who \\n>scored 27 points in the first half before spraining his ankle gets a zero.\\n>\\n>Does this make sense?\\n\\n\\nNo, but why would you assume that the teams probability of winning would\\nbe 0 before the possesion in which the free throws were made.  Look,\\nif you are down 1 point with 5 seconds left, there is a fairly high\\nprobability that you will win the game if you are in possesion of the\\nball.  And, do not forget that somebody elses missed shots, turnovers,\\nfouls, bad defense, etc. caused a \"negative chance\" that the team\\nwould win.\\n \\nFrom reading all of the discussion on this statistic, I feel that those\\nwho critisize it to a certain extent are doing so out of an agenda.\\nAt first look this statistic valadates clutchness.  But, it really\\ndoes not.  Cluthness revolves around the idea that certain players\\nin crucial situation elevate their performance and others performance\\ngoes down.  I\\'ve never seen convincing proof that this really happens.\\nSo, if you assume there is no clutchness, then that means that except\\nfor a lot of noice, this statistic has a positive association to\\nplayer performance.  There is a way to get rid of the noice if you\\ndo not believe in clutchness.  Certainly, we could find out what\\nthe average value of a home run is for example.  We may find for\\ninstance, that a home run increases your chance of winning by 15%\\non average while a strikeout decreases your chance of winning by 5%.\\nI bet if this were done we would find that this statistic was just\\nas good as other statistics we have for predicting wins and losses.\\n\\nHow do we evaluate relief pitchers?  Say John and Sam have the\\nexact same pitching statistics (runs, earned runs, K\\'s, BB\\'s,\\netc.)  Both had exceptional numbers.  John, however only pitched\\nin closer situations, while Sam was a Mop up man.  Who was more\\nvaluble to their team?  Probably John.  Who was the better \\npitcher?  They were probably about the same.\\n\\n                                                        Brian Smith\\n', 'Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!emory!sol.ctr.columbia.edu!zaphod.mps.ohio-state.edu!darwin.sura.net!jhunix.hcf.jhu.edu!jhunix.hcf.jhu.edu!not-for-mail\\nFrom: admiral@jhunix.hcf.jhu.edu (Steve C Liu)\\nNewsgroups: rec.sport.baseball\\nSubject: Re: NO JOKE: ROCKIES HAVE ATTENDANCE RECORD!!!!\\nDate: 1 Apr 1993 14:38:03 -0500\\nOrganization: Homewood Academic Computing, Johns Hopkins University, Baltimore, Md, USA\\nLines: 23\\nSender: admiral@jhunix.hcf.jhu.edu\\nDistribution: usa\\nExpires: 5/9/93\\nMessage-ID: <1pfgarINNq7s@jhunix.hcf.jhu.edu>\\nReferences: <wilbanks.733682487@spot.Colorado.EDU>\\nNNTP-Posting-Host: jhunix.hcf.jhu.edu\\nSummary: OPCY is just too small...\\n\\nHell, the Orioles\\' Opening Day game could easily be the largest in history\\nif we had a stadium with 80,000 seats. But unfortunely the Yards (a\\ndefinitely excellent ballpark) only holds like 45,000 with 275 SRO spots.\\nTicket sales for the entire year is moving fast. Bleacher seats are almost\\ngone for every game this year. It\\'s a extremely likelyhood that the O\\'s\\ncould sell out every game this year (especially if we lead the division for\\nmost of the year like \\'89). \\n\\tOn another front, the sale of the Orioles to anyone is likely to be\\nforced upon Eli Jacobs who is major debt apparently. Maybe we can get an\\nowner willing to spend on a proven rightfielder free agent in the winter.\\n\\tFernando has made the O\\'s as the fifth starter. The O\\'s pitching\\nstaff looks pretty good. Sutcliffe, Mussina, McDonald, Rhodes, and Fernando.\\n\\tBaltimore is my pick for the victors in a very competitive AL East.\\n__________________________________________________________________________\\n|Admiral Steve C. Liu        Internet Address: admiral@jhunix.hcf.jhu.edu|\\n|\"Committee for the Liberation and Intergration of Terrifying Organisms  |\\n|and their Rehabilitation Into Society\" from Red Dwarf - \"Polymorph\"     |\\n|****The Bangles are the greatest female rock band that ever existed!****|\\n|   This sig has been brought to you by... Frungy! The Sport of Kings!   |\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n Second to last day of the season - Gregg (The True Wild Thing) Olson\\nuncorks a wild pitch allowing the Blue Jays to tie. Blue Jays win in the\\n11th and ends the Baby Birds\\' miracle season of \\'89.\\n', 'Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!linac!uchinews!kimbark!thf2\\nFrom: thf2@kimbark.uchicago.edu (Ted Frank)\\nNewsgroups: rec.sport.baseball\\nSubject: Players Overpaid?\\nMessage-ID: <1993Apr5.231343.17894@midway.uchicago.edu>\\nDate: 5 Apr 93 23:13:43 GMT\\nArticle-I.D.: midway.1993Apr5.231343.17894\\nSender: news@uchinews.uchicago.edu (News System)\\nReply-To: thf2@midway.uchicago.edu\\nOrganization: University of Chicago\\nLines: 42\\n\\nThere\\'s a lot of whining about how much players are overpaid.  I thought\\nI\\'d put together an underpaid team that could win a pennant.  I splurged\\nand let four of the players earn as much as half a million dollars; the\\nhighest-paid player is Frank Thomas, at $900K.  I cut some players, like\\nKenny Lofton, Chris Hoiles, Keith Mitchell, Tim Wakefield, and a bunch\\nof pitchers, all of whom could have arguably made the team better at a\\ncost of $1 million for the lot of them.  The total team salary is \\n$7,781,500, averaging slightly over $300K a player.  If that\\'s too steep,\\nyou can dump Thomas and Bagwell, replacing them with Paul Sorrento and\\na minimum wager to save a bit over a million dollars, and still have one\\nof the best teams in the majors.\\n\\np, Juan Guzman, 500\\np, Mussina,\\t400\\np, Castillo,    250\\np, Eldred,      175\\np, Rhodes,\\t155\\np, Militello,   118\\nrp, Rojas,\\t300\\nrp, Beck,\\t250\\nrp, Melendez,   235\\nrp, Hernandez,\\t185\\nrp, Nied,\\t150\\nc, Rodriguez,\\t275\\nc, Piazza,      126\\n1b, Thomas,\\t900\\n1b, Bagwell,    655\\n2b, Knoblauch,\\t500\\n2b, Barberie,\\t190\\n3b, Gomez,\\t312.5\\n3b, Palmer,\\t250\\nss, Listach,\\t350\\nss, Pena,\\t170\\nlf, Gonzalez,\\t525\\ncf, Lankford,\\t290\\nrf, R.Sanders,\\t275\\nof, Plantier,\\t245\\n-- \\nted frank                 | \"However Teel should have mentioned that though \\nthf2@kimbark.uchicago.edu |  his advice is legally sound, if you follow it \\nthe u of c law school     |  you will probably wind up in jail.\"\\nstandard disclaimers      |                    -- James Donald, in misc.legal\\n', \"Newsgroups: rec.sport.baseball\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!zaphod.mps.ohio-state.edu!caen!batcomputer!cornell!tedward\\nFrom: tedward@cs.cornell.edu (Edward [Ted] Fischer)\\nSubject: Re: Rickey Henderson\\nMessage-ID: <1993Apr5.182833.25212@cs.cornell.edu>\\nOrganization: Cornell Univ. CS Dept, Ithaca NY 14853\\nReferences: <1993Apr5.173500.26383@ra.msstate.edu>\\nDistribution: usa\\nDate: Mon, 5 Apr 1993 18:28:33 GMT\\nLines: 12\\n\\nIn article <1993Apr5.173500.26383@ra.msstate.edu> js1@Isis.MsState.Edu (Jiann-ming Su) writes:\\n>I say buy out Henderson's contract and let him go bag groceries.  Next \\n>season, you'll be able to sign him for nothing.  That goes for any bitching\\n>ball player.\\n\\nI doubt Henderson would clear waivers.  And if he did, he would\\ninstantly be signed for the major league minimum, with Oakland picking\\nup the remaining $3 million tab.\\n\\nSome GMs value on-field performance too...\\n\\n-Valentine\\n\"]\n",
      "['52550', '52551', '52552', '52553', '52554']\n",
      "['Newsgroups: rec.sport.hockey\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!spool.mu.edu!torn!newshub.ccs.yorku.ca!ists!stpl.ists.ca!dchhabra\\nFrom: dchhabra@stpl.ists.ca (Deepak Chhabra)\\nSubject: Superstars and attendance (was Teemu Selanne, was +/- leaders)\\nMessage-ID: <1993Apr5.182124.17415@ists.ists.ca>\\nSender: news@ists.ists.ca (News Subsystem)\\nNntp-Posting-Host: stpl.ists.ca\\nOrganization: Solar Terresterial Physics Laboratory, ISTS\\nDistribution: na\\nDate: Mon, 5 Apr 93 18:21:24 GMT\\nLines: 115\\n\\n\\nDean J. Falcione (posting from jrmst+8@pitt.edu) writes:\\n[I wrote:]\\n\\n>>When the Pens got Mario, granted there was big publicity, etc, etc,\\n>>and interest was immediately generated.  Gretzky did the same thing for LA. \\n>>However, imnsho, neither team would have seen a marked improvement in\\n>>attendance if the team record did not improve.  In the year before Lemieux\\n>>came, Pittsburgh finished with 38 points.  Following his arrival, the Pens\\n>>finished with 53, 76, 72, 81, 87, 72, 88, and 87 points, with a couple of\\n                          ^^\\n>>Stanley Cups thrown in.\\n      \\n>It was at this point the Pens attendance was near capacity (34 out of 40 \\n>sellouts) yet they hadn\\'t made the playoffs since 1982.  How do you explain\\n>a 6th place team breaking attendance records when they haven\\'t been to the\\n>playoffs in 7 years?  Mario Lemieux is the explanation, IMHO.  \\n\\n>You could make a case that the *expectation* of an improving team that\\n>would make the playoffs is the reason. \\n\\nFunny you should mention it...this is exactly the case I was going to make.\\n\\n>But I think the reason is Lemieux\\n>had a 168 point season and was the first non-Gretzky to win the Hart and\\n>Ross since 1980.  People turned out to watch him play. \\n\\nI will grant that a star like Mario will draw fans, even if the team sucks. \\nBut this is short term only; I still do not think the attendance increase \\nwill last, unless the team is a winning/competitive/improving/butt-kicking\\none.  Pittsburgh was still getting better, so people continued to support\\nthem.  If they suddenly dropped to, say, 50 points, you\\'d have knee surgery\\nfor some of the people jumping off the bandwagon.  \\n\\n>Also, the following year (88-89) the Pens had 89 points not 87. \\n\\nOk.  My numbers came from the NHL Guide and Record Book. \\n\\n>They made the transaction to try and build a winner around Mario, that is \\n>true.  But the improvement in attendance came before they started doing\\n>this (Coffey late in 1987) and before they even had a playoff bound team.\\n>A doubling of attendance occured in 1984-85 from the previous year.  An\\n>increase from 38 points to 53 points is not going to do that.  The arrival\\n>of Mario Lemieux is what did it. \\n\\nYou can give the credit to Mario since he deserves it.  But my point is that\\nit wasn\\'t Mario himself, but it was the *expectation* of things to come (i.e.\\na winning team) that he created by being the next great hockey superstar. And\\nbefore anybody jumps in and says I\\'m nit-picking and mincing words, go back\\nand read from where this thread started...\\n\\nIt might help to think about what would go through a fan\\'s mind who suddenly\\nfound an interest in Mario and the Pens.  Was it \"gee, Mario Lemieux is\\namazing, I\\'ll go watch him play\", or was it \"gee, now we\\'ve got a *kick*\\n*ass* guy on *our* side, I\\'ll go watch him play\".  I think it was the latter.\\n\\n> Similar thing happened in L.A.   Before\\n>Gretzky\\'s arrival, about 12000 per game.  After, constant sellouts.  They\\n>are STILL selling out every game despite showing little or no improvement\\n>since Gretzky\\'s first year there.  How do you explain it?  People are going\\n>to see Gretzky.  they certainly aren\\'t going to see a winner, they haven\\'t\\n>GOT a winner.  They\\'ve had MUCH better teams in their past history than\\n>they currently have, yet they didn\\'t draw as well then.\\n\\nI don\\'t think this is accurate.  The *tickets* sell, but people don\\'t go to\\nthe games.  I think this thread has already been discussed...season ticket\\nholders in LA don\\'t always use their tickets.  So in effect, after the Kings\\ninitial success following Gretzky\\'s arrival (68 to 91 points, same source)\\nand corresponding attendance jump, there has been an effective drop in\\nattendance even though ticket sales may not have changed much.  \\n\\nWhether or not the Kings are a \\'winner\\' is debatable.  I claim that since\\nGretzky\\'s arrival they have at the very least been competitive...I also claim\\nthat McNall has made a stupid move in trying to reassemble the Oiler\\ndynasty...but that\\'s another story and included only because I don\\'t like\\nMcNall:-).  Anyway,  McNall did do some heavy marketing around Gretzky, and\\nthat undoubtedly was also responsible for the attendance and merchandising\\nsales, etc.  But as I said, when the Kings have been in there little\\ntailspins over the past couple of years there have been empty seats at the\\nForum even if the tickets were sold.\\n\\n>I think in the case of a Lemieux or Gretzky, the player can transcend\\n>winning as the major drawing power.  \\n\\nFor the short term, IMO.  Although I think that it\\'s inevitable that the team\\nwill improve with a player such as Lemieux or Gretzky, simply because they\\nmake people around them better.\\n\\n>But winning sure as hell helps.  ;-)\\n\\nWell, at least we are in full agreement here!\\n\\n>This does not make Roger\\'s point any more valid, but the Jets aren\\'t\\n\\nSo are you saying Roger has ever had a valid point? <couldn\\'t resist...>\\n\\n>getting a HUGE jump in productivity, yet they ARE getting a huge\\n>jump in attendance.  This is due to the emergence of Teemu Selanne.\\n>They have the 17th best record in hockey, it sure as hell isn\\'t because\\n>they are winning.\\n\\nYes, but they are doing no worse than last year.  I think the same type of\\nreasoning I applied to a new Pittsburgh fan applies to all the extra people\\nshowing up at Winnipeg games.  It\\'s difficult to predict, but do you think\\nthat if the Jets miss the playoffs next season that in the year after they\\nwill maintain their attendance levels?  I seriously doubt it, because in that\\ncase the expectation of an improving team would be gone, with or without\\nSelanne.\\n\\nI did provide the example of Rocket Ismail and the Toronto Argonauts of the \\nCFL...did you leave it out because you don\\'t know much about the CFL?  If \\nthat\\'s the case then fair enough, but if it isn\\'t the case then I\\'m curious\\nto hear your explanation.\\n\\n\\n', 'Newsgroups: rec.sport.hockey\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!usc!cs.utexas.edu!utnut!torn!newshub.ccs.yorku.ca!ists!stpl.ists.ca!dchhabra\\nFrom: dchhabra@stpl.ists.ca (Deepak Chhabra)\\nSubject: Re: NHL team leaders in +/-\\nMessage-ID: <1993Apr5.185633.17843@ists.ists.ca>\\nSender: news@ists.ists.ca (News Subsystem)\\nNntp-Posting-Host: stpl.ists.ca\\nOrganization: Solar Terresterial Physics Laboratory, ISTS\\nReferences: <1993Mar29.010820.113@ramsey.cs.laurentian.ca> <C4nt1B.9LM@ccu.umanitoba.ca> <1993Mar29.190650.28940@ramsey.cs.laurentian.ca>\\nDate: Mon, 5 Apr 93 18:56:33 GMT\\nLines: 42\\n\\nIn article <1993Mar29.190650.28940@ramsey.cs.laurentian.ca> maynard@ramsey.cs.laurentian.ca (Roger Maynard) writes:\\n\\n>The Jets use the \"breakaway pass\" scheme to create a scoring sensation\\n>in order to generate interest.  If teams score as many or more goals\\n>against Winnipeg when Selanne is on the ice as Winnipeg scores when\\n>he is on the ice then I can\\'t see how his contribution can be described\\n>as impressive.  \\n\\nImplicitly you are assuming that goals scored against Winnipeg with Selanne\\non the ice can be blamed on him...Roger, he is a FORWARD.  Winnipeg has a\\nlousy defensive record anyway.  Let\\'s put it another way.  John Cullen\\'s +/-\\nis terrible.  What\\'s your excuse for him?  That his powerplay points don\\'t\\ncount?  Neither do Selanne\\'s... \\n\\n>The object of the game is not to feed Selanne - it is \\n>to win.  And feeding Selanne does not contribute in any meaningful way\\n>to winning.\\n\\nKnowledgeable hockey observers the world over would agree that\\nfeeding Selanne so he can score does contribute in a meaningful way to\\nwinning. \\n\\n>Pat Burns wouldn\\'t have a goal suck like this on his team.\\n\\nYou\\'re worried about Teemu when you have Glenn Anderson on your team?\\n\\n>We DON\\'T KNOW what Selanne does best.  We do know what Jet\\'s management\\n>wants.  And again, the object of the exercise is not to allow Selanne to\\n>do what he does best, it is to win hockey games.\\n\\nWhat he does best is score...so I refer you to my comment above.\\n\\n>As it is now, Selanne\\n>is a grandstanding goal suck.  Did you see the way he parades around\\n>with his arms outstretched after scoring a goal?  You would think the\\n>Messiah had returned...\\n\\nNope, didn\\'t see it.  I was too busy watching Foligno jump up and down after\\n_his_ goal....\\n\\n\\n\\n', \"Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!zaphod.mps.ohio-state.edu!usc!aludra.usc.edu!not-for-mail\\nFrom: jbarrett@aludra.usc.edu (Jonathan Barrett)\\nNewsgroups: rec.sport.hockey\\nSubject: Re: This year's biggest and worst (opinion)...\\nKeywords: NHL, awards\\nMessage-ID: <1pqgq3INN2vn@aludra.usc.edu>\\nDate: 5 Apr 93 09:53:39 GMT\\nArticle-I.D.: aludra.1pqgq3INN2vn\\nReferences: <C4zCII.Ftn@watserv1.uwaterloo.ca>\\nSender: nntp@aludra.usc.edu\\nOrganization: University of Southern California, Los Angeles, CA\\nLines: 15\\nNNTP-Posting-Host: aludra.usc.edu\\n\\nI can only comment on the Kings, but the most obvious candidate for pleasant\\nsurprise is Alex Zhitnik. He came highly touted as a defensive defenseman, but\\nhe's clearly much more than that. Great skater and hard shot (though wish he\\nwere more accurate). In fact, he pretty much allowed the Kings to trade away\\nthat huge defensive liability Paul Coffey. Kelly Hrudey is only the biggest\\ndisappointment if you thought he was any good to begin with. But, at best, he's\\nonly a mediocre goaltender. A better choice would be Tomas Sandstrom, though\\nnot through any fault of his own, but because some thugs in Toronto decided \\nto threaten his career in order to avoid conceding a goal. Other than that, the\\naward goes to Robert Lang, an uninspiring Czech. Robitaille could easily be\\nMVP, but I'd prefer to give it to Rob Blake who is quietly becoming one of the\\nleague's premier defensemen, and if the Kings manage to hold onto him and the \\nrest of our young defense, it could one day mean that we'll let in fewer\\ngoals than Hartford. Honorable mentions to Majestic Marty and Warren Rychel.\\nJon\\n\", \"Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!network.ucsd.edu!news.service.uci.edu!nntpsrv\\nFrom: assist@orion.oac.uci.edu (ASSIST Coordination Site)\\nNewsgroups: rec.sport.hockey\\nSubject: Re: This year's biggest and worst (opinion)...\\nKeywords: NHL, awards\\nMessage-ID: <2BC0C6DF.18865@news.service.uci.edu>\\nDate: 5 Apr 93 23:55:11 GMT\\nArticle-I.D.: news.2BC0C6DF.18865\\nReferences: <C4zCII.Ftn@watserv1.uwaterloo.ca>\\nDistribution: world\\nOrganization: University of California, Irvine\\nLines: 20\\nNntp-Posting-Host: orion.oac.uci.edu\\n\\nIn article <C4zCII.Ftn@watserv1.uwaterloo.ca> smale@healthy.uwaterloo.ca (Bryan Smale) writes:\\n>                         MVP           Biggest       Biggest\\n>                                       Suprise       Disappointment\\n\\n>Los Angeles Kings       Robitaille     Donnelly      Hrudey\\n\\n\\nI would have chosen Alex Zhitnik for biggest suprise.  They\\ndid expect that he would become a great defenseman, but I don't\\nthink anyone knew that he was going to be this impressive in his \\nrookie year.  His speed, skating ability, and puck control is\\nexceptional -- he is the one to watch on the Kings.\\n\\n\\nKris\\nkris@fs2.assist.uci.edu\\n\\nGO KINGS!\\n\\n--\\n\", 'Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!cs.utexas.edu!uunet!noc.near.net!bigboote.WPI.EDU!ching\\nFrom: ching@coyote.WPI.EDU (Jay Heminger)\\nNewsgroups: rec.sport.hockey\\nSubject: Re: NCAA finals...Winner????\\nMessage-ID: <1pqgt9$r46@bigboote.WPI.EDU>\\nDate: 5 Apr 93 23:55:21 GMT\\nArticle-I.D.: bigboote.1pqgt9$r46\\nReferences: <1993Apr4.165655.16932@miavx1.acs.muohio.edu>\\nDistribution: world\\nOrganization: Worcester Polytechnic Institute\\nLines: 9\\nNNTP-Posting-Host: coyote.wpi.edu\\nOriginator: ching@coyote.WPI.EDU\\n\\n\\nMaine beat LSSU 5-4.\\n\\n\\n-- \\n------------------------THE LOGISTICIAN REIGNS SUPREME!!!----------------------\\n|\\t\\t\\t\\t\\t\\t\\t\\t\\t      |\\n|   GO BLUE!!!   GO TIGERS!!!   GO PISTONS!!!   GO LIONS!!!   GO RED WINGS!!! |\\n-------------------------------ching@wpi.wpi.edu-------------------------------\\n']\n"
     ]
    }
   ],
   "source": [
    "print(rec_autos_filenames[0:5])\n",
    "print(rec_autos_texts[0:5])\n",
    "print(rec_motorcycles_filenames[0:5])\n",
    "print(rec_motorcycles_texts[0:5])\n",
    "print(rec_sport_baseball_filenames[0:5])\n",
    "print(rec_sport_baseball_texts[0:5])\n",
    "print(rec_sport_hockey_filenames[0:5])\n",
    "print(rec_sport_hockey_texts[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycrawled_texts = (\n",
    "    rec_autos_texts\n",
    "    + rec_motorcycles_texts\n",
    "    + rec_sport_baseball_texts\n",
    "    + rec_sport_hockey_texts\n",
    ")\n",
    "mycrawled_filenames = (\n",
    "    rec_autos_filenames\n",
    "    + rec_motorcycles_filenames\n",
    "    + rec_sport_baseball_filenames\n",
    "    + rec_sport_hockey_filenames\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!wupost!uunet!brunix!cs.brown.edu!cs012055\\nFrom: cs012055@cs.brown.edu (Hok-Chung Tsang)\\nNewsgroups: rec.autos\\nSubject: Re: Saturn's Pricing Policy\\nMessage-ID: <1993Apr5.230808.581@cs.brown.edu>\\nDate: 5 Apr 93 23:08:08 GMT\\nArticle-I.D.: cs.1993Apr5.230808.581\\nReferences: <C4oxwp.KKM@news.cso.uiuc.edu> <C4vIr5.L3r@shuksan.ds.boeing.com>\\nSender: news@cs.brown.edu\\nOrganization: Brown Computer Science Dept.\\nLines: 51\\n\\nIn article <C4vIr5.L3r@shuksan.ds.boeing.com>, fredd@shuksan (Fred Dickey) writes:\\n|> CarolinaFan@uiuc (cka52397@uxa.cso.uiuc.edu) wrote:\\n|> : \\tI have been active in defending Saturn lately on the net and would\\n|> : like to state my full opinion on the subject, rather than just reply to others'\\n|> : points.\\n|> : \\t\\n|> : \\tThe biggest problem some people seem to be having is that Saturn\\n|> : Dealers make ~$2K on a car.  I think most will agree with me that the car is\\n|> : comparably priced with its competitors, that is, they aren't overpriced \\n|> : compared to most cars in their class.  I don't understand the point of \\n|> : arguing over whether the dealer makes the $2K or not?  \\n|> \\n|> I have never understood what the big deal over dealer profits is either.\\n|> The only thing that I can figure out is that people believe that if\\n|> they minimize the dealer profit they will minimize their total out-of-pocket\\n|> expenses for the car. While this may be true in some cases, I do not\\n|> believe that it is generally true. I bought a Saturn SL in January of '92.\\n|> AT THAT TIME, based on studying car prices, I decided that there was\\n|> no comparable car that was priced as cheaply as the Saturn. Sure, maybe I\\n|> could have talked the price for some other car to the Saturn price, but\\n|> my out-of-pocket expenses wouldn't have been any different. What's important\\n|> to me is how much money I have left after I buy the car. REDUCING DEALER PROFIT\\n|> IS NOT THE SAME THING AS SAVING MONEY! Show me how reducing dealer profit\\n|> saves me money, and I'll believe that it's important. My experience has\\n|> been that reducing dealer profit does not necessarily save me money.\\n|> \\n|> Fred\\n\\n\\nSay, you bought your Saturn at $13k, with a dealer profit of $2k.\\nIf the dealer profit is $1000, then you would only be paying $12k for\\nthe same car.  So isn't that saving money?\\n\\nMoreover, if Saturn really does reduce the dealer profit margin by $1000, \\nthen their cars will be even better deals.  Say, if the price of a Saturn was\\nalready $1000 below market average for the class of cars, then after they\\nreduce the dealer profit, it would be $2000 below market average.  It will:\\n\\n1) Attract even more people to buy Saturns because it would SAVE THEM MONEY.\\n \\n2) Force the competitors to lower their prices to survive.\\n\\nNow, not only will Saturn owners benefit from a lower dealer profit, even \\nthe buyers for other cars will pay less.\\n\\nIsn't that saving money?\\n\\n\\n\\n$0.02,\\ndoug.\\n\",\n",
       " \"Newsgroups: rec.autos\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!gatech!usenet.ins.cwru.edu!agate!headwall.Stanford.EDU!nntp.Stanford.EDU!tedebear\\nFrom: tedebear@leland.Stanford.EDU (Theodore Chen)\\nSubject: Re: Are BMW's worth the price?                      \\nMessage-ID: <1993Apr5.183248.25040@leland.Stanford.EDU>\\nSender: news@leland.Stanford.EDU (Mr News)\\nOrganization: DSG, Stanford University, CA 94305, USA\\nReferences: <1993Apr5.135153.11132@wdl.loral.com>\\nDate: Mon, 5 Apr 93 18:32:48 GMT\\nLines: 19\\n\\nIn article <1993Apr5.135153.11132@wdl.loral.com> gwm@spl1.spl.loral.com (Gary W. Mahan) writes:\\n>Road and Track (2/88) BMW325is     0-60 7.5s, 1/4 mile 15.7s\\n>               (Road Test \\n>                Annual 1993)       0-60 8.3s, 1/4 mile 16.2s\\n>\\n>\\n>Those are the numbers I was quoting, I have driven the older model but not the\\n>newer.\\n\\n\\nsure sounds like they got a ringer.  the 325is i drove was definitely\\nfaster than that.  if you want to quote numbers, my AW AutoFile shows\\n0-60 in 7.4, 1/4 mile in 15.9.  it quotes Car and Driver's figures\\nof 6.9 and 15.3.  oh, BTW, these numbers are for the 325i.\\n\\ni don't know how the addition of variable valve timing for 1993 affects it.\\nbut don't take my word for it.  go drive it.\\n\\n-teddy\\n\",\n",
       " 'Xref: cantaloupe.srv.cs.cmu.edu rec.autos:101553 rec.autos.tech:53404\\nPath: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!news.tek.com!tekgen!netops\\nFrom: netops@tekgen.bv.tek.com (Randy King)\\nNewsgroups: rec.autos,rec.autos.tech\\nSubject: RE: headlights problem\\nKeywords: headlights\\nMessage-ID: <2407@tekgen.bv.tek.com>\\nDate: 5 Apr 93 23:23:53 GMT\\nArticle-I.D.: tekgen.2407\\nFollowup-To: rec.autos\\nOrganization: Tektronix Inc., Beaverton, Or.\\nLines: 6\\n\\nTHANKS TO ALL OF YOU WHO RESPONDED TO MY POSTING. \\n\\nTHE PROBLEM WITH MY TRUCK\\'S HEADLIGHTS LOW BEAM PROBLEM WAS A \"LOOSE WIRE\\n CONNECTION\".  IT WAS NOT THE \"FUSE\" AS A MINORITY OF YOU SUGGESTED.\\n\\nTHANKS AGAIN.\\n',\n",
       " \"Xref: cantaloupe.srv.cs.cmu.edu rec.autos:101554 rec.autos.tech:53405\\nPath: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!news.tek.com!tekgen!netops\\nFrom: netops@tekgen.bv.tek.com (Randy King)\\nNewsgroups: rec.autos,rec.autos.tech\\nSubject: left turn signal won't stop automaticaly\\nMessage-ID: <2408@tekgen.bv.tek.com>\\nDate: 5 Apr 93 23:29:21 GMT\\nArticle-I.D.: tekgen.2408\\nFollowup-To: rec.autos\\nOrganization: Tektronix Inc., Beaverton, Or.\\nLines: 5\\n\\nThe subject says it all. My 1984 Chev S10 Pickup's left turn signal does\\nnot stop after turning. What cause this to stop automaticaly?. Is this\\na mechanical problem by the steering wheel?.\\n\\nNOTE: This truck has an after market steering wheel (GT-Grant) installed.\\n\",\n",
       " 'Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!zaphod.mps.ohio-state.edu!usc!elroy.jpl.nasa.gov!nntp-server.caltech.edu!lxrosser\\nFrom: lxrosser@cco.caltech.edu (Alex Rosser)\\nNewsgroups: rec.autos\\nSubject: Re: What is \" Volvo \" ?\\nMessage-ID: <1pl86tINNfv7@gap.caltech.edu>\\nDate: 3 Apr 93 23:56:12 GMT\\nArticle-I.D.: gap.1pl86tINNfv7\\nReferences: <1993Mar31.193406.29625@ugle.unit.no> <1993Apr1.174233.29988@newsgate.sps.mot.com>\\nOrganization: California Institute of Technology, Pasadena\\nLines: 27\\nNNTP-Posting-Host: blacker.caltech.edu\\n\\nwolfson@regatta.sps.mot.com (Stephen Wolfson) writes:\\n\\n>In article <1993Mar31.193406.29625@ugle.unit.no> oep@colargol.edb.tih.no  \\n>(oep) writes:\\n>> which turns into a teenagers car when it gets old. The average  \\n>lifelength of\\n>> a Volvo in Norway is 18 years, and in Sweden 20 years)\\n\\n>Of course someone pointed out when Saab or Volvo was running their\\n>At least 10 years ads, that the average milage was significantly\\n>less than than the US average.\\n\\nThat my be, but every Volvo I\\'ve ever owned has lasted far longer than most\\nother cars.....\\n1981 Volvo 245....125,000 Miles, still on the road.\\n1983 Volvo 242....195,000 Miles, still on the road.\\n1984 Volvo 244....175,000 Miles, still on the road.\\nAnd I\\'ll admit, the dealer repair cost is high. But with some mechanical\\naptitude of your own, and finding a good indi mechanic, you can avoid most\\nbreakdowns, and make the rest cheap(The sum total of the repairs on the car with\\n195,000 miles has been 2 mufflers and a radiator. Whoa. Bad repair record). \\nAnd all of these cars are driven fairly hard. None of them are at the head of\\na line of cars going 30 MPH....the first two spend a lot of their operating\\nlife with the speedometer pegged...and the only reason the 84 doesn\\'t is it has\\na 120 MPH speedo...\\nWhat I want to know is....have all you people who hate Volvos been traumatized\\nby someone in a 745 Turbo wagon blowing you away on the road, or what?\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycrawled_texts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude header lines from each message\n",
    "excludedlinemarkers = [\n",
    "    \"Xref:\",\n",
    "    \"Path:\",\n",
    "    \"From:\",\n",
    "    \"Newsgroups:\",\n",
    "    \"Subject:\",\n",
    "    \"Summary:\",\n",
    "    \"Keywords:\",\n",
    "    \"Message-ID:\",\n",
    "    \"Date:\",\n",
    "    \"Expires:\",\n",
    "    \"Followup-To:\",\n",
    "    \"Distribution:\",\n",
    "    \"Organization:\",\n",
    "    \"Approved:\",\n",
    "    \"Supersedes:\",\n",
    "    \"Lines:\",\n",
    "    \"NNTP-Posting-Host:\",\n",
    "    \"References:\",\n",
    "    \"Sender:\",\n",
    "    \"In-Reply-To:\",\n",
    "    \"Article-I.D.:\",\n",
    "    \"Reply-To:\",\n",
    "    \"Nntp-Posting-Host:\",\n",
    "]\n",
    "for k in range(len(mycrawled_texts)):\n",
    "    templines = mycrawled_texts[k].splitlines()\n",
    "    remaininglines = []\n",
    "    for l in range(len(templines)):\n",
    "        line_should_be_excluded = 0\n",
    "        for m in range(len(excludedlinemarkers)):\n",
    "            if len(templines[l]) >= len(excludedlinemarkers[m]):\n",
    "                if (\n",
    "                    excludedlinemarkers[m]\n",
    "                    == templines[l][0 : len(excludedlinemarkers[m])]\n",
    "                ):\n",
    "                    line_should_be_excluded = 1\n",
    "                    break\n",
    "        if line_should_be_excluded == 0:\n",
    "            remaininglines.append(templines[l])\n",
    "    mycrawled_texts[k] = \"\\n\".join(remaininglines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"\\nIn article <C4vIr5.L3r@shuksan.ds.boeing.com>, fredd@shuksan (Fred Dickey) writes:\\n|> CarolinaFan@uiuc (cka52397@uxa.cso.uiuc.edu) wrote:\\n|> : \\tI have been active in defending Saturn lately on the net and would\\n|> : like to state my full opinion on the subject, rather than just reply to others'\\n|> : points.\\n|> : \\t\\n|> : \\tThe biggest problem some people seem to be having is that Saturn\\n|> : Dealers make ~$2K on a car.  I think most will agree with me that the car is\\n|> : comparably priced with its competitors, that is, they aren't overpriced \\n|> : compared to most cars in their class.  I don't understand the point of \\n|> : arguing over whether the dealer makes the $2K or not?  \\n|> \\n|> I have never understood what the big deal over dealer profits is either.\\n|> The only thing that I can figure out is that people believe that if\\n|> they minimize the dealer profit they will minimize their total out-of-pocket\\n|> expenses for the car. While this may be true in some cases, I do not\\n|> believe that it is generally true. I bought a Saturn SL in January of '92.\\n|> AT THAT TIME, based on studying car prices, I decided that there was\\n|> no comparable car that was priced as cheaply as the Saturn. Sure, maybe I\\n|> could have talked the price for some other car to the Saturn price, but\\n|> my out-of-pocket expenses wouldn't have been any different. What's important\\n|> to me is how much money I have left after I buy the car. REDUCING DEALER PROFIT\\n|> IS NOT THE SAME THING AS SAVING MONEY! Show me how reducing dealer profit\\n|> saves me money, and I'll believe that it's important. My experience has\\n|> been that reducing dealer profit does not necessarily save me money.\\n|> \\n|> Fred\\n\\n\\nSay, you bought your Saturn at $13k, with a dealer profit of $2k.\\nIf the dealer profit is $1000, then you would only be paying $12k for\\nthe same car.  So isn't that saving money?\\n\\nMoreover, if Saturn really does reduce the dealer profit margin by $1000, \\nthen their cars will be even better deals.  Say, if the price of a Saturn was\\nalready $1000 below market average for the class of cars, then after they\\nreduce the dealer profit, it would be $2000 below market average.  It will:\\n\\n1) Attract even more people to buy Saturns because it would SAVE THEM MONEY.\\n \\n2) Force the competitors to lower their prices to survive.\\n\\nNow, not only will Saturn owners benefit from a lower dealer profit, even \\nthe buyers for other cars will pay less.\\n\\nIsn't that saving money?\\n\\n\\n\\n$0.02,\\ndoug.\", \"\\nIn article <1993Apr5.135153.11132@wdl.loral.com> gwm@spl1.spl.loral.com (Gary W. Mahan) writes:\\n>Road and Track (2/88) BMW325is     0-60 7.5s, 1/4 mile 15.7s\\n>               (Road Test \\n>                Annual 1993)       0-60 8.3s, 1/4 mile 16.2s\\n>\\n>\\n>Those are the numbers I was quoting, I have driven the older model but not the\\n>newer.\\n\\n\\nsure sounds like they got a ringer.  the 325is i drove was definitely\\nfaster than that.  if you want to quote numbers, my AW AutoFile shows\\n0-60 in 7.4, 1/4 mile in 15.9.  it quotes Car and Driver's figures\\nof 6.9 and 15.3.  oh, BTW, these numbers are for the 325i.\\n\\ni don't know how the addition of variable valve timing for 1993 affects it.\\nbut don't take my word for it.  go drive it.\\n\\n-teddy\", '\\nTHANKS TO ALL OF YOU WHO RESPONDED TO MY POSTING. \\n\\nTHE PROBLEM WITH MY TRUCK\\'S HEADLIGHTS LOW BEAM PROBLEM WAS A \"LOOSE WIRE\\n CONNECTION\".  IT WAS NOT THE \"FUSE\" AS A MINORITY OF YOU SUGGESTED.\\n\\nTHANKS AGAIN.', \"\\nThe subject says it all. My 1984 Chev S10 Pickup's left turn signal does\\nnot stop after turning. What cause this to stop automaticaly?. Is this\\na mechanical problem by the steering wheel?.\\n\\nNOTE: This truck has an after market steering wheel (GT-Grant) installed.\", \"\\nwolfson@regatta.sps.mot.com (Stephen Wolfson) writes:\\n\\n>In article <1993Mar31.193406.29625@ugle.unit.no> oep@colargol.edb.tih.no  \\n>(oep) writes:\\n>> which turns into a teenagers car when it gets old. The average  \\n>lifelength of\\n>> a Volvo in Norway is 18 years, and in Sweden 20 years)\\n\\n>Of course someone pointed out when Saab or Volvo was running their\\n>At least 10 years ads, that the average milage was significantly\\n>less than than the US average.\\n\\nThat my be, but every Volvo I've ever owned has lasted far longer than most\\nother cars.....\\n1981 Volvo 245....125,000 Miles, still on the road.\\n1983 Volvo 242....195,000 Miles, still on the road.\\n1984 Volvo 244....175,000 Miles, still on the road.\\nAnd I'll admit, the dealer repair cost is high. But with some mechanical\\naptitude of your own, and finding a good indi mechanic, you can avoid most\\nbreakdowns, and make the rest cheap(The sum total of the repairs on the car with\\n195,000 miles has been 2 mufflers and a radiator. Whoa. Bad repair record). \\nAnd all of these cars are driven fairly hard. None of them are at the head of\\na line of cars going 30 MPH....the first two spend a lot of their operating\\nlife with the speedometer pegged...and the only reason the 84 doesn't is it has\\na 120 MPH speedo...\\nWhat I want to know is....have all you people who hate Volvos been traumatized\\nby someone in a 745 Turbo wagon blowing you away on the road, or what?\"]\n"
     ]
    }
   ],
   "source": [
    "print(mycrawled_texts[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Tokenize loaded texts and change them to NLTK format\n",
    "mycrawled_nltktexts = []\n",
    "for k in range(len(mycrawled_texts)):\n",
    "    temp_tokenizedtext = nltk.word_tokenize(mycrawled_texts[k])\n",
    "    temp_nltktext = nltk.Text(temp_tokenizedtext)\n",
    "    mycrawled_nltktexts.append(temp_nltktext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Text: In article < C4vIr5.L3r @ shuksan.ds.boeing.com > ,...>,\n",
       " <Text: In article < 1993Apr5.135153.11132 @ wdl.loral.com > gwm...>,\n",
       " <Text: THANKS TO ALL OF YOU WHO RESPONDED TO...>,\n",
       " <Text: The subject says it all . My 1984...>,\n",
       " <Text: wolfson @ regatta.sps.mot.com ( Stephen Wolfson ) writes...>,\n",
       " <Text: : TIN [ version 1.1 PL8.8>,\n",
       " <Text: I 'm looking for a replacement radio/tape player...>,\n",
       " <Text: I am thinking about getting an Infiniti G20...>,\n",
       " <Text: In article < 1993Apr5.175719.7892 @ telxon.mis.telxon.com > joes...>,\n",
       " <Text: In article < 1993Apr5.212645.15988 @ nntpd.lkg.dec.com > kenyon...>,\n",
       " <Text: In article < 3mwF2B1w165w @ njcc.wisdom.bubble.org > ,...>,\n",
       " <Text: Do n't have a list of what 's...>,\n",
       " <Text: In article < 1993Apr3.005245.10615 @ michael.apple.com > ems...>,\n",
       " <Text: In article < 1pq29p $ 29p @ seven-up.East.Sun.COM...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 In article <...>,\n",
       " <Text: This past winter I drove from NYC to...>,\n",
       " <Text: Sayeth `` Joseph D. Mazza '' < mazz+...>,\n",
       " <Text: Sayeth sjwyrick @ lbl.gov ( Steve Wyrick )...>,\n",
       " <Text: In article IGw @ world.std.com , edwards @...>,\n",
       " <Text: In article < C50pBH.244 @ noose.ecn.purdue.edu > rjwade...>,\n",
       " <Text: My sister has an MGB . She has...>,\n",
       " <Text: In article < 1993Apr1.191826.28921 @ iscnvx.lmsc.lockheed.com > sharen...>,\n",
       " <Text: I was wondering if someone could point me...>,\n",
       " <Text: Has anybody noticed that Toyota has an uncanny...>,\n",
       " <Text: Cup holders ( driving is an importantant enough...>,\n",
       " <Text: One of the local dealers has a used...>,\n",
       " <Text: It 's great that all these other cars...>,\n",
       " <Text: We 're considering getting a Ford Explorer XLT...>,\n",
       " <Text: According to a LoJack representative I saw recently...>,\n",
       " <Text: Bottom line : I did it and it...>,\n",
       " <Text: > sure sounds like they got a ringer...>,\n",
       " <Text: In article < 1ppg8b $ fvq @ armory.centerline.com...>,\n",
       " <Text: Left hand steering wheel placement was not standard...>,\n",
       " <Text: DeSoto 's first year of manufacture was 1928...>,\n",
       " <Text: > In article < 78834 @ cup.portal.com >...>,\n",
       " <Text: In article < 1993Apr2.135926.1 @ skcla.monsanto.com > ,...>,\n",
       " <Text: > Well , you young fellers wo n't...>,\n",
       " <Text: Anyone have figures or pointers to references about...>,\n",
       " <Text: hello testing...>,\n",
       " <Text: My friend brought a subaru SVX recently ....>,\n",
       " <Text: Could someone out there please tell me how...>,\n",
       " <Text: ak296 @ yfn.ysu.edu ( John R. Daker )...>,\n",
       " <Text: I test drove a Mazda 626 LX this...>,\n",
       " <Text: In article < 1993Apr5.234729.100387 @ ns1.cc.lehigh.edu > daz1...>,\n",
       " <Text: In article < 1993Apr5.181056.29411 @ mks.com > mike...>,\n",
       " <Text: kojo @ valet.phx.mcd.mot.com ( Kojo Yeboah ) writes...>,\n",
       " <Text: In article < 1993Apr5.213032.26844 @ pmafire.inel.gov > russ...>,\n",
       " <Text: > Photo radar and mailed tickets make no...>,\n",
       " <Text: Your best bet is the Dodge Intrepid with...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41.UAC PENINSULA CRUISERS THIRD...>,\n",
       " <Text: In article < C4rvKM.367 @ plato.ds.boeing.com > simnet...>,\n",
       " <Text: How do you take off the driver side...>,\n",
       " <Text: In article < 1pima2INN180 @ gap.caltech.edu > ,...>,\n",
       " <Text: In article < 1993Apr2.030031.15691 @ cactus.org > ,...>,\n",
       " <Text: In-reply-to : Brad Thone 's message of Fri...>,\n",
       " <Text: 1991 Geo Storm - Red / Grey interior...>,\n",
       " <Text: In article < 1993Apr5.203719 @ usho0b.hou281.chevron.com > hhtra...>,\n",
       " <Text: I bought a car with a defunct engine...>,\n",
       " <Text: < 1ppqkm $ 93n @ usenet.INS.CWRU.Edu > >...>,\n",
       " <Text: I 've had my Subaru Liberty 4WD station...>,\n",
       " <Text: Originator : qazi @ csd4.csd.uwm.edu From article <...>,\n",
       " <Text: rmt6r @ faraday.clas.Virginia.EDU ( Roy Matthew Thigpen )...>,\n",
       " <Text: cs012055 @ cs.brown.edu ( Hok-Chung Tsang ) writes...>,\n",
       " <Text: I 'm thinking of buying a new Dodge...>,\n",
       " <Text: In-reply-to : ssave @ ole.cdac.com 's message of...>,\n",
       " <Text: In article < mgolden.733994052 @ cwis > mgolden...>,\n",
       " <Text: 85 honda civic dx hatchback -- -- --...>,\n",
       " <Text: In article < YfkBJQS00Uh_E9TFo_ @ andrew.cmu.edu > ``...>,\n",
       " <Text: In article < 1993Apr5.211457.12789 @ ole.cdac.com > ssave...>,\n",
       " <Text: In article < 1993Apr1.230642.5207 @ cbfsb.cb.att.com > ykhsu...>,\n",
       " <Text: * * * * * * * *...>,\n",
       " <Text: In article < 1993Apr5.234729.100387 @ ns1.cc.lehigh.edu > daz1...>,\n",
       " <Text: X-Received : by usenet.pa.dec.com ; id AA12484 ;...>,\n",
       " <Text: In article < 4fjDcfu00iV2I9Kap_ @ andrew.cmu.edu > ``...>,\n",
       " <Text: in europe you can buy a 525iX ,...>,\n",
       " <Text: In article < 1993Apr6.060553.22453 @ cactus.org > boyle...>,\n",
       " <Text: > And all of these cars are driven...>,\n",
       " <Text: Originator : jdmooney @ koinsv02 In article <...>,\n",
       " <Text: In article < 1pnigoINN5in @ senator-bedfellow.MIT.EDU > chsu...>,\n",
       " <Text: In article < C4wJGq.A40 @ constellation.ecn.uoknor.edu > callison...>,\n",
       " <Text: In rec.autos , CPKJP @ vm.cc.latech.edu ( Kevin...>,\n",
       " <Text: [ nntpd-8755>,\n",
       " <Text: dunnjj @ ucsu.Colorado.EDU ( DUNN JONATHAN JAMES )...>,\n",
       " <Text: boyle @ bbsls23.bnr ( Ian Boyle ) writes...>,\n",
       " <Text: In article 2211 @ viewlogic.com , brad @...>,\n",
       " <Text: : TIN [ version 1.1.4 PL6>,\n",
       " <Text: < C51Hn0.2JI @ world.std.com > > In article...>,\n",
       " <Text: In article < 1993Apr6.035020.16730 @ cactus.org > boyle...>,\n",
       " <Text: CHINTS @ ISCS.NUS.SG writes : > Here are...>,\n",
       " <Text: In article < 91321 @ hydra.gatech.EDU > jkg...>,\n",
       " <Text: In article < 1993Apr2.174850.6289 @ cbnewsl.cb.att.com > prm...>,\n",
       " <Text: REQUEST FOR DISCUSSION This is a request for...>,\n",
       " <Text: In article < 1993Apr2.194838.13476 @ news.cs.brandeis.edu > andyh...>,\n",
       " <Text: In article < 1993Apr5.211457.12789 @ ole.cdac.com > ssave...>,\n",
       " <Text: bets @ chester.ksu.ksu.edu ( Beth Schwindt ) writes...>,\n",
       " <Text: Does anyone know the performance ratings for a...>,\n",
       " <Text: Mercedes-Benz announced yesterday its plans to begin building...>,\n",
       " <Text: In article < 93096.101507RSM2 @ psuvm.psu.edu > <...>,\n",
       " <Text: In article < jgladu-060493121851 @ 128.249.27.63 > jgladu...>,\n",
       " <Text: My friend , David Gordon wants to sell...>,\n",
       " <Text: In article < 1993Apr6.131018.12873 @ acd4.acd.com > ,...>,\n",
       " <Text: Quoting Jeffrey J. Nucciarone 's ( nucci @...>,\n",
       " <Text: > My '66 Ford has vent windows operated...>,\n",
       " <Text: Not exactly dumb , but who remebers the...>,\n",
       " <Text: ssave @ ole.cdac.com ( The Devil Reincarnate )...>,\n",
       " <Text: In article < 1993Apr6.185328.24947 @ news.cs.brandeis.edu > andyh...>,\n",
       " <Text: In article < C4x6yq.5L4 @ news.claremont.edu > ochaine...>,\n",
       " <Text: [ nntpd-19510>,\n",
       " <Text: >,\n",
       " <Text: In article < 1pq8tkINNbek @ chester.ksu.ksu.edu > bets...>,\n",
       " <Text: I know it 's a long shot ,...>,\n",
       " <Text: In article < 1993Apr6.194738.20021 @ magnus.acs.ohio-state.edu > jnielsen...>,\n",
       " <Text: In article < C50p1M.21o @ noose.ecn.purdue.edu > ,...>,\n",
       " <Text: I do n't want to sell this car...>,\n",
       " <Text: In article < 1993Apr6.195710.24227 @ cs.tulane.edu > finnegan...>,\n",
       " <Text: A friend of mine is cnsidering buying a...>,\n",
       " <Text: > I am in search of a dependable...>,\n",
       " <Text: > > Quad 4 reliable , yeah ,...>,\n",
       " <Text: In article < 33759 @ oasys.dt.navy.mil > tobias...>,\n",
       " <Text: In article < 1993Apr6.131018.12873 @ acd4.acd.com > jwg...>,\n",
       " <Text: In article < C518F0.9I7 @ undergrad.math.uwaterloo.ca > ,...>,\n",
       " <Text: zowie @ daedalus.stanford.edu ( Craig `` Powderkeg ''...>,\n",
       " <Text: In article < 1pima2INN180 @ gap.caltech.edu > ,...>,\n",
       " <Text: ...>,\n",
       " <Text: In article < 1993Apr5.230808.581 @ cs.brown.edu > cs012055...>,\n",
       " <Text: In article < C50p1M.21o @ noose.ecn.purdue.edu > rjwade...>,\n",
       " <Text: In a previous article , dh3q+ @ andrew.cmu.edu...>,\n",
       " <Text: jmh @ hopper.Virginia.EDU ( Jeffrey Hoffmeister ) writes...>,\n",
       " <Text: davidd @ lonestar.utsa.edu ( David . De Leon...>,\n",
       " <Text: seningen @ maserati.ross.com ( Mike Seningen ) >...>,\n",
       " <Text: In article < 1993Apr14.133007.11055 @ Princeton.EDU > chinatti...>,\n",
       " <Text: A point of interest - in `` hacking...>,\n",
       " <Text: hhtra @ usho72.hou281.chevron.com ( T.M.Haddock ) writes :...>,\n",
       " <Text: In article < zdem0a.734809554 @ hgo7 > ,...>,\n",
       " <Text: In article < 1993Apr14.171718.18852 @ lmpsbbs.comm.mot.com > sheinfel...>,\n",
       " <Text: In article < 1qcaueINNmt8 @ axon.cs.unc.edu > Andrew...>,\n",
       " <Text: > I agree that if traffic is all...>,\n",
       " <Text: A while back I asked for help in...>,\n",
       " <Text: I had exactly the same problem with a...>,\n",
       " <Text: I have a 1982 Regal and I am...>,\n",
       " <Text: In article < x ! fvt=b @ dixie.com...>,\n",
       " <Text: I consulted with someone working on an electronic...>,\n",
       " <Text: In a previous article , smorris @ sumax.seattleu.edu...>,\n",
       " <Text: Howdy , I 'm a little new to...>,\n",
       " <Text: < reilly-140493131545 @ rreilly.fnal.gov > Rob Reilly :...>,\n",
       " <Text: In a previous article , edf003 @ marshall.wvnet.edu...>,\n",
       " <Text: In a previous article , sdexter @ shl.com...>,\n",
       " <Text: In a previous article , edf003 @ marshall.wvnet.edu...>,\n",
       " <Text: In article < 1993Mar30.203846.85644 @ ns1.cc.lehigh.edu > jh03...>,\n",
       " <Text: I have a 86 chevy sprint with a/c...>,\n",
       " <Text: In article < 1993Apr15.011805.28485 @ ns1.cc.lehigh.edu > ,...>,\n",
       " <Text: In article < 1993Apr15.135514.29579 @ cbnewsj.cb.att.com > rdb1...>,\n",
       " <Text: In article < C5HqJ0.57 @ unix.amherst.edu > bhtulin...>,\n",
       " <Text: In article < C5FqFy.Fpq @ usenet.ucs.indiana.edu > ,...>,\n",
       " <Text: In rec.autos , dennis @ hpcvra.cv.hp.com ( Dennis...>,\n",
       " <Text: In article < 1qhs7dINNj2b @ hp-col.col.hp.com > tvervaek...>,\n",
       " <Text: In rec.autos , boyle @ cactus.org ( Craig...>,\n",
       " <Text: In article < 1993Apr15.160922.8797 @ magnus.acs.ohio-state.edu > ,...>,\n",
       " <Text: In article < 1993Apr15.160922.8797 @ magnus.acs.ohio-state.edu > sorlin...>,\n",
       " <Text: For sale - Mazda 323 1986 Mazda 323...>,\n",
       " <Text: In article < 1993Apr14.143750.120204 @ marshall.wvnet.edu > edf003...>,\n",
       " <Text: In a previous article , bmoss @ grinch.sim.es.com...>,\n",
       " <Text: : rec-autos/part1 [ most recent changes , 15 March 1993 : addition of alt.autos.karting -- rpw>,\n",
       " <Text: Archive-name : rec-autos/part5 [ this article is one...>,\n",
       " <Text: In-reply-to : ejv2j @ Virginia.EDU 's message of...>,\n",
       " <Text: I saw an interesting product in NY Auto...>,\n",
       " <Text: W > > will NOT do work on...>,\n",
       " <Text: Archive-Name : rec-autos/part2 Automotive Mailing Lists ( Electronic...>,\n",
       " <Text: Archive-name : rec-autos/part3 The Automotive Articles Archive Server...>,\n",
       " <Text: Archive-name : rec-autos/part4 [ this article is one...>,\n",
       " <Text: : rec-autos/part6 [ New article as of 4 February 1993 -- rpw>,\n",
       " <Text: In article < 1327 @ qa1.WichitaKS.NCR.COM > jhart...>,\n",
       " <Text: Originator : madman @ suave.austin.ibm.com This is a...>,\n",
       " <Text: ejv2j @ Virginia.EDU ( `` Erik Velapoldi ''...>,\n",
       " <Text: In article < 1993Apr15.170720.8538 @ colorado.edu > drew...>,\n",
       " <Text: Their number is 1-800-541-4716 they are based in...>,\n",
       " <Text: parr @ acs.ucalgary.ca ( Charles Parr ) writes...>,\n",
       " <Text: Originator : ernie @ ferris > In article...>,\n",
       " <Text: Originator : ernie @ ferris > In article...>,\n",
       " <Text: I have been looking at buying a 1989...>,\n",
       " <Text: ak954 @ yfn.ysu.edu ( Albion H. Bowers )...>,\n",
       " <Text: X-Disclaimer : This message was written by a...>,\n",
       " <Text: hhm @ cbnewsd.cb.att.com ( herschel.h.mayo ) writes :...>,\n",
       " <Text: Is anyone reading this message involved with the...>,\n",
       " <Text: In article < 1qk7t5 $ dg @ armory.centerline.com...>,\n",
       " <Text: parr @ acs.ucalgary.ca ( Charles Parr ) writes...>,\n",
       " <Text: A little bit off of the subject but...>,\n",
       " <Text: I bought an Intrepid about two months ago...>,\n",
       " <Text: Ah , yes , the big chunks down...>,\n",
       " <Text: I have just taken delivery on a new...>,\n",
       " <Text: IS there a simple way tooput these sunroofs...>,\n",
       " <Text: I do n't know if some lemons are...>,\n",
       " <Text: Is clear coat really worth it ? Yes...>,\n",
       " <Text: rmt6r @ faraday.clas.Virginia.EDU ( Roy Matthew Thigpen )...>,\n",
       " <Text: I have $ 30,000 as my budget ....>,\n",
       " <Text: schludermann @ sscvx1.ssc.gov writes : > I 'm...>,\n",
       " <Text: I have a 1986 Acura Integra 5 speed...>,\n",
       " <Text: In article < 1993Apr17.014638.56998 @ ns1.cc.lehigh.edu > ,...>,\n",
       " <Text: In article < 3090 @ shaman.wv.tek.com > ,...>,\n",
       " <Text: In article < 3090 @ shaman.wv.tek.com > ,...>,\n",
       " <Text: In article < 1993Apr14.190652.19777 @ slcs.slb.com > ,...>,\n",
       " <Text: Good luck ....>,\n",
       " <Text: Please satisfy my curiosity . I 'm interested...>,\n",
       " <Text: In response to a post about SUV 's...>,\n",
       " <Text: I 'm plannig to trade my Sentra SE-R...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 In article <...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 In article <...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 In article <...>,\n",
       " <Text: In article < C5o4nH.3su @ news.cso.uiuc.edu > mchaffee...>,\n",
       " <Text: Although not in direct response to the referenced...>,\n",
       " <Text: Could we plase cease this discussion . I...>,\n",
       " <Text: X-Newsreader : NNR/VM S_1.3.2 I recently posted an...>,\n",
       " <Text: Hello , I am looking to slightly increase...>,\n",
       " <Text: qazi @ csd4.csd.uwm.edu writes : > -- From...>,\n",
       " <Text: Warren Brown , the Washington Post 's auto...>,\n",
       " <Text: Disclaimer : This posting represents the poster 's...>,\n",
       " <Text: Two-volume soft-cover repair manuals for all models of...>,\n",
       " <Text: Does anyone know of a dead first generation...>,\n",
       " <Text: The biggest hurdle for automatics ( IMHO )...>,\n",
       " <Text: Chances are that this has been discussed to...>,\n",
       " <Text: The Chevrolet brothers were respected racers & test...>,\n",
       " <Text: In article < 0w2Z2B1w164w @ cellar.org > blu...>,\n",
       " <Text: In article < C5HqJ0.57 @ unix.amherst.edu > bhtulin...>,\n",
       " <Text: : tommy @ hoodlum wrat @ unisql.UUCP ( wharfie ) writes : $ [ ...>,\n",
       " <Text: In article < 930411.153152.amiller @ almaden.ibm.com > amiller...>,\n",
       " <Text: Originator : tommy @ hoodlum hagenjd @ wfu.edu...>,\n",
       " <Text: Hi everyone , I 'm getting a car...>,\n",
       " <Text: I was lloking at the Geo Prizm Lsi...>,\n",
       " <Text: Anyone have any opinions on fairly recent model...>,\n",
       " <Text: The car might also need a front end...>,\n",
       " <Text: In article < 93106.161324LIBEMC @ BYUVM.BITNET > <...>,\n",
       " <Text: I am presently doing a masters thesis to...>,\n",
       " <Text: Dear Netters : I am looking to buy...>,\n",
       " <Text: In article < 93Apr16.185044.18431 @ acs.ucalgary.ca > parr...>,\n",
       " <Text: If you hold off , there are a...>,\n",
       " <Text: an excellent automatic can be found in the...>,\n",
       " <Text: We get about 20 Taurus/Sables for fleet cars...>,\n",
       " <Text: In rec.autos you write : > if ayrton...>,\n",
       " <Text: ip02 @ ns1.cc.lehigh.edu ( Danny Phornprapha ) writes...>,\n",
       " <Text: jong @ halcyon.com ( Barking Weasel ) writes...>,\n",
       " <Text: Hello World , just bought a new Stealth...>,\n",
       " <Text: I am currently in the car market and...>,\n",
       " <Text: In article < 1993Apr17.175451.30896 @ ns1.cc.lehigh.edu > ,...>,\n",
       " <Text: I was in the great storm ..... my...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 In article <...>,\n",
       " <Text: X-Disclaimer : This message was written by a...>,\n",
       " <Text: From article < 1993Apr15.024246.8076 @ Virginia.EDU > ,...>,\n",
       " <Text: In article < 1993Apr15.192250.18815 @ cbnewse.cb.att.com > turbo...>,\n",
       " <Text: : TIN [ version 1.1 PL9>,\n",
       " <Text: I am looking for recommendations for a good...>,\n",
       " <Text: In article < 1993Apr15.020356.28944 @ magnus.acs.ohio-state.edu > sorlin...>,\n",
       " <Text: In article < 1993Apr13.111652 @ usho72.hou281.chevron.com > ,...>,\n",
       " <Text: My Honda Accord just hit the magic 100,000...>,\n",
       " <Text: I have the EuroWiper boots in White and...>,\n",
       " <Text: With the popularity of minivans , the market...>,\n",
       " <Text: In article < C5J5MI.FMI @ news.rich.bnr.ca > Peon...>,\n",
       " <Text: In article < C5H6F8.LDu @ news.rich.bnr.ca > jcyuhn...>,\n",
       " <Text: In article < 1qh61m $ b6l @ armory.centerline.com...>,\n",
       " <Text: In article < 1993Apr14.152328.15997 @ magnus.acs.ohio-state.edu > jnielsen...>,\n",
       " <Text: In article < 3090 @ shaman.wv.tek.com > andrew...>,\n",
       " <Text: wrat @ unisql.UUCP ( wharfie ) writes :...>,\n",
       " <Text: jcksnste @ ACF1.NYU.EDU writes : > Hi All...>,\n",
       " <Text: If your buying a compact pickup do yourself...>,\n",
       " <Text: I just visited the NY Auto Show ,...>,\n",
       " <Text: In article < 1993Apr14.130427.21349 @ porthos.cc.bellcore.com > dje...>,\n",
       " <Text: : TIN [ version 1.1 PL8>,\n",
       " <Text: In article < Apr09.084236.19413 @ engr.washington.edu > ,...>,\n",
       " <Text: < 1993Apr15.024246.8076 @ Virginia.EDU > < C5JCpA.1ptt @...>,\n",
       " <Text: In article < 1993Apr14.203800.12566 @ progress.com > damelio...>,\n",
       " <Text: One thing that everyone is forgetting in this...>,\n",
       " <Text: For those that are interested I got my...>,\n",
       " <Text: In article < 1993Apr15.203750.25764 @ walter.bellcore.com > jchen...>,\n",
       " <Text: In article < bob1.734909414 @ cos > bob1...>,\n",
       " <Text: In article < C5JnK3.JKt @ news.cso.uiuc.edu > cka52397...>,\n",
       " <Text: ( I deleted your name because I do...>,\n",
       " <Text: In < 1993Apr14.230524.9578 @ ctp.com > bpita @...>,\n",
       " <Text: In article < C5JGC4.AJJ @ dove.nist.gov > ,...>,\n",
       " <Text: In article < 9833 @ dirac.physics.purdue.edu > lovall...>,\n",
       " <Text: tobias @ convex.com ( Allen Tobias ) writes...>,\n",
       " <Text: Last night I had a dream that my...>,\n",
       " <Text: In article < NEILSON.93Apr15135919 @ seoul.mpr.ca > neilson...>,\n",
       " <Text: ... and in San Francisco recently , some...>,\n",
       " <Text: In article < 1993Apr14.155159.32619 @ ns1.cc.lehigh.edu > amh2...>,\n",
       " <Text: In article < 1993Apr15.062557.1224 @ slcs.slb.com > dcd...>,\n",
       " <Text: Why crawl under the car at all ?...>,\n",
       " <Text: In article < 9833 @ dirac.physics.purdue.edu > lovall...>,\n",
       " <Text: In article < 1qht5eINNjdf @ hp-col.col.hp.com > ,...>,\n",
       " <Text: In article < 1qkon8 $ 3re @ armory.centerline.com...>,\n",
       " <Text: In < Ifn=sPO00iV18_A8NZ @ andrew.cmu.edu > jr4q+ @...>,\n",
       " <Text: larose @ austin.cs.utk.edu ( Brian LaRose ) writes...>,\n",
       " <Text: Hi netters , My friend is seriously thinking...>,\n",
       " <Text: this week 's autoweek talks about how wagons...>,\n",
       " <Text: In article < 1qke5b $ mc4 @ spool.mu.edu...>,\n",
       " <Text: In article < 1993Apr15.161531.11737 @ newsgate.sps.mot.com > rapw20...>,\n",
       " <Text: I was following an example of the LH...>,\n",
       " <Text: In < 1993Apr14.045526.21945 @ cactus.org > boyle @...>,\n",
       " <Text: Hi .. Me and My roomate are going...>,\n",
       " <Text: In article < 1993Apr8.095119.5367 @ hasler.ascom.ch > kevinh...>,\n",
       " <Text: In < C5Dq2n.5uB @ news.cso.uiuc.edu > mwbg9715 @...>,\n",
       " <Text: In article < 1993Apr15.203750.25764 @ walter.bellcore.com > jchen...>,\n",
       " <Text: I 'd like to converse with anyone who...>,\n",
       " <Text: Originator : wl @ coast I need to...>,\n",
       " <Text: In article < 1qk5m9 $ pbe @ news.ysu.edu...>,\n",
       " <Text: In article < 1qh336INNfl5 @ CS.UTK.EDU > larose...>,\n",
       " <Text: In article < C5HHGM.1rM @ constellation.ecn.uoknor.edu > ,...>,\n",
       " <Text: > While not exactly a service incident ,...>,\n",
       " <Text: In article < crh.734864478 @ regent.e-technik.tu-muenchen.de > crh...>,\n",
       " <Text: Hi , maybe someone can help me here...>,\n",
       " <Text: srihari @ cirrus.com ( Srihari Shoroff ) writes...>,\n",
       " <Text: In article < 1ql178INN51q @ tamsun.tamu.edu > dlb5404...>,\n",
       " <Text: In article < Apr16.000710.27408 @ engr.washington.edu > eliot...>,\n",
       " <Text: In article < 1993Apr15.111910.1 @ bronco.fnal.gov > colombo...>,\n",
       " <Text: derek @ nezsdc.icl.co.nz ( Derek Tearne ) writes...>,\n",
       " <Text: In article < 1993Apr15.173951.20173 @ icf.hrb.com > jek...>,\n",
       " <Text: In article < 1993Apr16.000601.14223 @ jarvis.csri.toronto.edu > rkim...>,\n",
       " <Text: In article < 1993Apr15.223029.23340 @ cactus.org > boyle...>,\n",
       " <Text: Originator : qazi @ csd4.csd.uwm.edu > cs173sbw @...>,\n",
       " <Text: Originator : qazi @ csd4.csd.uwm.edu From article <...>,\n",
       " <Text: Originator : qazi @ csd4.csd.uwm.edu From article <...>,\n",
       " <Text: < 93Apr15.165432.44598 @ acs.ucalgary.ca > < C5JnK3.JKt @...>,\n",
       " <Text: In article < 1993Apr16.052013.23517 @ leland.Stanford.EDU > tedebear...>,\n",
       " <Text: In article < 1qlg02 $ iu6 @ uniwa.uwa.oz.au...>,\n",
       " <Text: In article < X3XZ2B2w165w @ vllyoak.resun.com > jp...>,\n",
       " <Text: Originator : kevinh @ nath In article <...>,\n",
       " <Text: In article < 5214 @ unisql.UUCP > wrat...>,\n",
       " <Text: Sorry for the mis-spelling , but I forgot...>,\n",
       " <Text: Hi from Australia , I am a car...>,\n",
       " <Text: Hi from Australia , I am a car...>,\n",
       " <Text: I just bought a 1962 T-BIRD and would...>,\n",
       " <Text: In article < 1993Apr16.091938.6821 @ hasler.ascom.ch > ,...>,\n",
       " <Text: In article 4DB @ vu-vlsi.ee.vill.edu , mobasser @...>,\n",
       " <Text: jimf @ centerline.com ( Jim Frost ) writes...>,\n",
       " <Text: > I too was puzzled by this obvious...>,\n",
       " <Text: X-Newsreader : Tin 1.1.3 PL5 Give out the...>,\n",
       " <Text: : TIN [ version 1.1.4 PL6>,\n",
       " <Text: rwong @ eis.calstate.edu ( Russel Wong ) writes...>,\n",
       " <Text: In article < 1993Apr20.002651.20797 @ sco.com > nathanp...>,\n",
       " <Text: My 1988 Toyota 4Runner has a rolldown rear...>,\n",
       " <Text: Hello netters ! I 'm visiting the US...>,\n",
       " <Text: nancy @ hayduke ( Nancy Feagans ) writes...>,\n",
       " <Text: You can be sure they would n't do...>,\n",
       " <Text: In article < 1993Apr20.124228.5357 @ ncsu.edu > chuck...>,\n",
       " <Text: In article < C5r43y.F0D @ mentor.cc.purdue.edu > marshatt...>,\n",
       " <Text: In article < C5r66A.6rB @ srgenprp.sr.hp.com > almanb...>,\n",
       " <Text: Alright , beat this automobile sighting . Driving...>,\n",
       " <Text: The restriction could have to do with the...>,\n",
       " <Text: If you want a summer without rain ,...>,\n",
       " <Text: In article 5276 @ unisql.UUCP , wrat @...>,\n",
       " <Text: amh2 @ ns1.cc.lehigh.edu ( ALOIS M. HIMSL )...>,\n",
       " <Text: > ip02 @ ns1.cc.lehigh.edu ( Danny Phornprapha )...>,\n",
       " <Text: In article < HOLCOMB.93Apr19073907 @ wgermany.ctron.com > holcomb...>,\n",
       " <Text: I had the exactly same problem with my...>,\n",
       " <Text: In article < 1qugvu $ ai8 @ quad.wfunet.wfu.edu...>,\n",
       " <Text: In article < 9595 @ tekig7.PEN.TEK.COM > ,...>,\n",
       " <Text: In article < 1993Apr19.164451.3744 @ news.eng.convex.com > dodson...>,\n",
       " <Text: In article < 34544 @ oasys.dt.navy.mil > glouie...>,\n",
       " <Text: In article < 19APR199316162857 @ erich.triumf.ca > music...>,\n",
       " <Text: In article < 1993Apr19.164451.3744 @ news.eng.convex.com > ,...>,\n",
       " <Text: It did it again . This morning ,...>,\n",
       " <Text: I guess that makes Altima the most generic...>,\n",
       " <Text: A local dealer is advertising `` No negotiation...>,\n",
       " <Text: '' Jeremy G. Mereness '' < zonker+ @...>,\n",
       " <Text: : TIN [ version 1.1 PL8>,\n",
       " <Text: tobias @ convex.com ( Allen Tobias ) writes...>,\n",
       " <Text: neilson @ seoul.mpr.ca ( Robert Neilson ) writes...>,\n",
       " <Text: In article < 1993Apr15.222254.6651 @ rtfm.mlb.fl.us > ,...>,\n",
       " <Text: In article < C5JoIt.E31 @ bcstec.ca.boeing.com > ,...>,\n",
       " <Text: boyle @ cactus.org ( Craig Boyle ) writes...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 Wharf Wrat rites...>,\n",
       " <Text: X-Posted-From : InterNews1.0b10 @ newshost.dartmouth.edu Well , I...>,\n",
       " <Text: Anybody got any good/bad experience with selling their...>,\n",
       " <Text: In article < 49422 @ fibercom.COM > rrg...>,\n",
       " <Text: X-Newsreader : Tin 1.1.3 PL5 : Ford and...>,\n",
       " <Text: rfelix @ netcom.com ( Robbie Felix ) writes...>,\n",
       " <Text: Water gradually builds up in the trunk of...>,\n",
       " <Text: In rec.autos Jay Lorenzana < U40348 @ uicvm.uic.edu...>,\n",
       " <Text: I was recently thumbing through the 1993 Lemon-Aid...>,\n",
       " <Text: In article < 1993Apr20.142818.14969 @ ericsson.se > etxmst...>,\n",
       " <Text: I am selling my FIAT 850 Spyder :...>,\n",
       " <Text: In a previous article , ( Eric Youngblood...>,\n",
       " <Text: Hi , My friend 's 1983 Toyota Tercel...>,\n",
       " <Text: : TIN [ version 1.1.4 PL6>,\n",
       " <Text: Originator : storrs @ c20002-121rd.che.ncsu.edu In article <...>,\n",
       " <Text: X-Newsreader : Tin 1.1 PL4 : nuet_ke @...>,\n",
       " <Text: In article < Apr.19.12.13.52.1993.387 @ remus.rutgers.edu > hong...>,\n",
       " <Text: In article < 1993Apr21.034751.23512 @ ntuix.ntu.ac.sg > mgqlu...>,\n",
       " <Text: In < wfnMBJG00WBOE3L2c0 @ andrew.cmu.edu > Srinagesh Gavirneni...>,\n",
       " <Text: In article < 1qqp2o $ 5ba @ usenet.INS.CWRU.Edu...>,\n",
       " <Text: I just read articals on this in Road...>,\n",
       " <Text: tcorkum @ bnr.ca ( Trevor Corkum ) writes...>,\n",
       " <Text: In article < 1993Apr19.145238.9561 @ magnus.acs.ohio-state.edu > bqueiser...>,\n",
       " <Text: Hmmm .... I was listening to the local...>,\n",
       " <Text: In article < 1993Apr13.182100.26650 @ magnus.acs.ohio-state.edu > jnielsen...>,\n",
       " <Text: I was wondering if anyone out there could...>,\n",
       " <Text: Can we please stick to AUTOMOTIVE topics ....>,\n",
       " <Text: FOR SALE : 20 inch Magnavox TV/VCR combination...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 > I just...>,\n",
       " <Text: In article < C5sxI4.J9B @ news.cso.uiuc.edu > cka52397...>,\n",
       " <Text: G'day people , Are there any MR2 owners...>,\n",
       " <Text: X-Xxdate : Tue , 20 Apr 93 00:07:01...>,\n",
       " <Text: sorry about that last post , my server...>,\n",
       " <Text: ajc @ philabs.philips.com ( Alec Cameron ) writes...>,\n",
       " <Text: boyle @ cactus.org ( Craig Boyle ) writes...>,\n",
       " <Text: X-Disclaimer : This message was written by a...>,\n",
       " <Text: In article < 1993Apr19.235711.7285 @ cactus.org > boyle...>,\n",
       " <Text: In article : Is there such a thing...>,\n",
       " <Text: X-Disclaimer : This message was written by a...>,\n",
       " <Text: tobias @ convex.com ( Allen Tobias ) writes...>,\n",
       " <Text: hanguyen @ megatest.com ( Ha Nguyen ) writes...>,\n",
       " <Text: In < smN42B1w165w @ cybernet.cse.fau.edu > vlasis @...>,\n",
       " <Text: Monthly posting regarding the Buick Grand National /...>,\n",
       " <Text: : TIN [ version 1.1 PL6>,\n",
       " <Text: In article < 5243 @ unisql.UUCP > ,...>,\n",
       " <Text: : TIN [ version 1.1 PL6>,\n",
       " <Text: In < 1993Apr15.040118.29272 @ slcs.slb.com > dcd @...>,\n",
       " <Text: In < 24485 @ drutx.ATT.COM > klf @...>,\n",
       " <Text: In < C5HI0B.26C @ constellation.ecn.uoknor.edu > callison @...>,\n",
       " <Text: In article < 1993Apr15.173851.25846 @ convex.com > ,...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 In article <...>,\n",
       " <Text: Arctic Wheels of Fairbanks Presents The 10th Anniversary...>,\n",
       " <Text: In article < 13269 @ news.duke.edu > klg...>,\n",
       " <Text: > Les Bartel 's comments : > >...>,\n",
       " <Text: Thanks to everyone who responded to my Honda...>,\n",
       " <Text: I was wondering if anyone out in net-land...>,\n",
       " <Text: In article < 1993Apr14.064702.26925 @ reed.edu > rseymour...>,\n",
       " <Text: In article < C5K5Co.F09 @ mentor.cc.purdue.edu > thwang...>,\n",
       " <Text: In article < 1993Apr15.222600.11690 @ research.nj.nec.com > behanna...>,\n",
       " <Text: : TIN [ version 1.1 PL9>,\n",
       " <Text: Are there any Honda groups out there ?...>,\n",
       " <Text: In article < C5HqJ0.57 @ unix.amherst.edu > ,...>,\n",
       " <Text: In a previous article , crh @ regent.e-technik.tu-muenchen.dbp.de...>,\n",
       " <Text: In article < 1993Apr15.234508.20032 @ slcs.slb.com > dcd...>,\n",
       " <Text: In article < 1993Apr14.140642.19875 @ cbnewsd.cb.att.com > hhm...>,\n",
       " <Text: In article < 1993Apr15.222254.6651 @ rtfm.mlb.fl.us > gwalker...>,\n",
       " <Text: In article < 1993Apr15.193712.25996 @ news.cs.brandeis.edu > ,...>,\n",
       " <Text: -- : I want only two things from...>,\n",
       " <Text: I do n't know about where you are...>,\n",
       " <Text: In < C5t3B2.DG @ news.cso.uiuc.edu > cka52397 @...>,\n",
       " <Text: I am in the process of looking for...>,\n",
       " <Text: I just had my 41 Chrysler painted ....>,\n",
       " <Text: -- My boss is interested in a new...>,\n",
       " <Text: Hello Netters , I would like to find...>,\n",
       " <Text: There was an article in Business week not...>,\n",
       " <Text: In article < 1qehi6 $ ork @ armory.centerline.com...>,\n",
       " <Text: In article < 1r1vofINN871 @ usenet.pa.dec.com > tomacj...>,\n",
       " <Text: In article < C5JoIt.E31 @ bcstec.ca.boeing.com > neil...>,\n",
       " <Text: In article < NEILSON.93Apr15135919 @ seoul.mpr.ca > neilson...>,\n",
       " <Text: In article < 1993Apr21.171811.25933 @ julian.uwo.ca > wlsmith...>,\n",
       " <Text: Does that mean that they 're gon na...>,\n",
       " <Text: X-Newsreader : Tin 1.1 PL4 mchaffee @ dcl-nxt07...>,\n",
       " <Text: I heard the diesels are considered cleaner-burning than...>,\n",
       " <Text: aas7 @ po.CWRU.Edu ( Andrew A. Spencer )...>,\n",
       " <Text: In article < 1993Apr20.174246.14375 @ wam.umd.edu > lerxst...>,\n",
       " <Text: Hi Netters I want to know if 13500...>,\n",
       " <Text: In article < C5t3B2.DG @ news.cso.uiuc.edu > cka52397...>,\n",
       " <Text: In article < 1993Apr20.203219.7724 @ pencom.com > stecz...>,\n",
       " <Text: I would also be interested in finding out...>,\n",
       " <Text: Here is a story . I bought a...>,\n",
       " <Text: I 'm about to buy a new car...>,\n",
       " <Text: boyle @ cactus.org writes : > In article...>,\n",
       " <Text: There is just something disconcerting about the name...>,\n",
       " <Text: X-Newsreader : Tin 1.1 PL4 By the way...>,\n",
       " <Text: In article < nataraja.735341980 @ opal12 > ,...>,\n",
       " <Text: In article < 1qqv7k $ e5g @ usenet.INS.CWRU.Edu...>,\n",
       " <Text: : TIN [ version 1.1 PL8.8>,\n",
       " <Text: In article < C5uwoJ.Bt @ usenet.ucs.indiana.edu > mliggett...>,\n",
       " <Text: Originator : newman @ howell.cps.msu.edu Does anyone know...>,\n",
       " <Text: > Eliot is right about 2.2 liter engine...>,\n",
       " <Text: In a previous article , twetzel @ ucs.indiana.edu...>,\n",
       " <Text: In a previous article , dwjz @ bnr.ca...>,\n",
       " <Text: In article < 1993Apr21.191744.3072 @ ole.cdac.com > ssave...>,\n",
       " <Text: -- In article < C5t3B2.DG @ news.cso.uiuc.edu >...>,\n",
       " <Text: -- In article < 1993Apr20.231748.26273 @ convex.com >...>,\n",
       " <Text: In article < 66758 @ mimsy.umd.edu > davew...>,\n",
       " <Text: In a previous article , marshatt @ feserve.cc.purdue.edu...>,\n",
       " <Text: In a previous article , jkjec @ westminster.ac.uk...>,\n",
       " <Text: mliggett @ silver.ucs.indiana.edu ( matthew liggett ) writes...>,\n",
       " <Text: matmcinn @ nuscc.nus.sg ( Matthew MacIntyre at the...>,\n",
       " <Text: Here is a press release from the U.S....>,\n",
       " <Text: I 'd like to hear stories on experiences...>,\n",
       " <Text: aas7 @ po.CWRU.Edu ( Andrew A. Spencer )...>,\n",
       " <Text: In article < 1r3oe8 $ c93 @ usenet.INS.CWRU.Edu...>,\n",
       " <Text: i of course car safety is important .....>,\n",
       " <Text: Another user recently requested info about the Shadow/Sundance...>,\n",
       " <Text: @ mxmsd.msd.measurex.com ( Bob LaGesse ) writes : [ Long silly discussion deleted ...>,\n",
       " <Text: In article < C5JGC4.AJJ @ dove.nist.gov > keys...>,\n",
       " <Text: In article < 1993Apr12.230031.160616 @ ua1ix.ua.edu > rpaturi...>,\n",
       " <Text: In article < 1993Mar31.181813.24122 @ magnus.acs.ohio-state.edu > jnielsen...>,\n",
       " <Text: X-UserAgent : Nuntius v1.1.1d16 X-XXMessage-ID : < A7F46B03C301085E...>,\n",
       " <Text: In article < 1993Apr15.193712.25996 @ news.cs.brandeis.edu > andyh...>,\n",
       " <Text: In article < 1qll56INNp9r @ uwm.edu > ,...>,\n",
       " <Text: In article < C5K9M5.7Ku @ constellation.ecn.uoknor.edu > callison...>,\n",
       " <Text: > Why should a good driver be terrified...>,\n",
       " <Text: Consumer Reports once wrote about the S-10 Blazer...>,\n",
       " <Text: In article < mxm1003.734826257 @ msi.umn.edu > ,...>,\n",
       " <Text: gwm @ spl1.spl.loral.com ( Gary W. Mahan )...>,\n",
       " <Text: In article < 24485 @ drutx.ATT.COM > klf...>,\n",
       " <Text: In article < 1993Apr15.232412.2261 @ ganglion.ann-arbor.mi.us > david...>,\n",
       " <Text: Hi everybody , I will buy a Honda...>,\n",
       " <Text: In article < 1qmq7tINN9l @ tamsun.tamu.edu > dlb5404...>,\n",
       " <Text: From article < 1993Apr16.162950.25849 @ newsgate.sps.mot.com > ,...>,\n",
       " <Text: In article < C5Fp8B.2Co @ megatest.com > alung...>,\n",
       " <Text: on wednesday morning , another driver decided to...>,\n",
       " <Text: A list of options that would be useful...>,\n",
       " <Text: The idea here is to list pointless options...>,\n",
       " <Text: In a previous article , gwm @ spl1.spl.loral.com...>,\n",
       " <Text: : TIN [ version 1.1.8 PL6>,\n",
       " <Text: I just ordered a Saturn SL1 after considering...>,\n",
       " <Text: In article < C5L8rE.28 @ constellation.ecn.uoknor.edu > callison...>,\n",
       " <Text: In article < 1qkon8 $ 3re @ armory.centerline.com...>,\n",
       " <Text: In article < 15631 @ ncrcan.Canada.NCR.CA > tnelson...>,\n",
       " <Text: I am considering buying an new car ,...>,\n",
       " <Text: Joni Ciarletta writes > My Honda Accord just...>,\n",
       " <Text: In a previous article , parr @ acs.ucalgary.ca...>,\n",
       " <Text: Now , my ego with regards to my...>,\n",
       " <Text: In article KA6 @ crdnns.crd.ge.com , cimjfg @...>,\n",
       " <Text: In a previous article , wrat @ unisql.UUCP...>,\n",
       " <Text: In a previous article , a207706 @ moe.dseg.ti.com...>,\n",
       " <Text: All you have to do is turn it...>,\n",
       " <Text: In article < 20726.2bcd8b62 @ ecs.umass.edu > sylveste...>,\n",
       " <Text: In article < C5unFy.E7I @ dove.nist.gov > keys...>,\n",
       " <Text: Bob : Excellent ! To the point and...>,\n",
       " <Text: First off , the correct spelling of Nissan...>,\n",
       " <Text: My ex-husband & I used to own Borgwards...>,\n",
       " <Text: In article < C5xtp7.MtB @ murdoch.acc.Virginia.EDU > jmh...>,\n",
       " <Text: Originator : tommy @ hoodlum The question is...>,\n",
       " <Text: I went to a place called American Car...>,\n",
       " <Text: In article < 20APR199310391109 @ csa3.lbl.gov > jtchew...>,\n",
       " <Text: In article < 1r1d62 $ d6s @ agate.berkeley.edu...>,\n",
       " <Text: In article < Apr22.202724.24131 @ engr.washington.edu > eliot...>,\n",
       " <Text: In rec.autos , mas @ skcla.monsanto.com writes :...>,\n",
       " <Text: In article < nataraja.735495588 @ geode14 > nataraja...>,\n",
       " <Text: X-Newsreader : Tin 1.1 PL3 rboudrie @ chpc.org...>,\n",
       " <Text: Hi ! This is my first time to...>,\n",
       " <Text: In article < 1993Apr23.105438.3245 @ msus1.msus.edu > w00026...>,\n",
       " <Text: In article < C5wyKp.L98 @ ulowell.ulowell.edu > gvahe...>,\n",
       " <Text: In article < gjg2001-220493224950 @ m248-103.bgsu.edu > gjg2001...>,\n",
       " <Text: In article < C5wEqE.5IG @ news.rich.bnr.ca > herling...>,\n",
       " <Text: I know this is the wrong place to...>,\n",
       " <Text: Nntp-Software : PC/TCP NNTP 1989 Honda CRX DX...>,\n",
       " <Text: < 1r3ghp $ 3n9 @ armory.centerline.com < 1993Apr22.204921.12644...>,\n",
       " <Text: < 1r7n42INNie1 @ shelley.u.washington.edu > I agree with...>,\n",
       " <Text: 89 ' Toyota Camry LE 4 dr sedan...>,\n",
       " <Text: boyle @ cactus.org ( Craig Boyle ) wrote...>,\n",
       " <Text: In article < 1993Apr23.105438.3245 @ msus1.msus.edu > w00026...>,\n",
       " <Text: In article < 1993Apr22.204921.12644 @ convex.com > ,...>,\n",
       " <Text: In < pwe.735571191 @ slipknot.mit.edu > pwe @...>,\n",
       " <Text: I want to thank all the people that...>,\n",
       " <Text: In < 1993Apr23.132214.6755 @ cs.tulane.edu > finnegan @...>,\n",
       " <Text: In article < C5unFJ.2pA @ usenet.ucs.indiana.edu > Tom...>,\n",
       " <Text: : TIN [ version 1.1 PL9>,\n",
       " <Text: I came across this interesting information in my...>,\n",
       " <Text: : TIN [ version 1.1.4 PL6>,\n",
       " <Text: In article < 1993Apr22.145940.1 @ skcla.monsanto.com > mas...>,\n",
       " <Text: Disclaimer : This posting represents the poster 's...>,\n",
       " <Text: - > 4 ) Are there any fairly...>,\n",
       " <Text: In article < 1993Apr23.010311.23110 @ ra.oc.com > ,...>,\n",
       " <Text: '' The Villager-Quest seem like the best of...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 Is it ok...>,\n",
       " <Text: In article < 10262 @ ceylon.gte.com > ,...>,\n",
       " <Text: If you had free reign to design your...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 In article <...>,\n",
       " <Text: In article < 1r8ufk $ fr7 @ usenet.INS.CWRU.Edu...>,\n",
       " <Text: : TIN [ version 1.1.4 PL6>,\n",
       " <Text: < 1r8uckINNcmf @ gap.caltech.edu > In article <...>,\n",
       " <Text: In article < 66758 @ mimsy.umd.edu > davew...>,\n",
       " <Text: I have tested both vehicles ( identically equipped...>,\n",
       " <Text: > > Dont get me wrong , I...>,\n",
       " <Text: In a previous article , parr @ acs.ucalgary.ca...>,\n",
       " <Text: In a previous article , gwm @ spl1.spl.loral.com...>,\n",
       " <Text: Originator : laszlo @ csd4.csd.uwm.edu From article <...>,\n",
       " <Text: Originator : laszlo @ csd4.csd.uwm.edu > In article...>,\n",
       " <Text: In article < 1993Apr15.163411.27443 @ dsd.es.com > bmoss...>,\n",
       " <Text: 1991 Toyota Camry for sale : Deluxe package...>,\n",
       " <Text: In article < buck.735568034 @ granite > buck...>,\n",
       " <Text: mad9a @ fermi.clas.Virginia.EDU ( Michael A. Davis )...>,\n",
       " <Text: In article < 1993Apr23.144326.9535 @ ctp.com > bpita...>,\n",
       " <Text: In article < C5wpHp.5KL @ megatest.com > alung...>,\n",
       " <Text: X-Disclaimer : This message was written by a...>,\n",
       " <Text: In article < 1r7n42INNie1 @ shelley.u.washington.edu > gaia...>,\n",
       " <Text: Originator : brad @ buck In article <...>,\n",
       " <Text: In article < C5st37.HF3 @ ns1.nodak.edu > bell...>,\n",
       " <Text: In article < 93113.123459U59985 @ uicvm.uic.edu > <...>,\n",
       " <Text: In article < 1r0vk6INNaft @ cronkite.Central.Sun.COM > dbernard...>,\n",
       " <Text: Originator : c23reg @ koptsw21 In article <...>,\n",
       " <Text: Originator : c23tvr @ koptsy17 In article <...>,\n",
       " <Text: > : In response to a post about...>,\n",
       " <Text: jnielsen @ magnus.acs.ohio-state.edu ( John F Nielsen )...>,\n",
       " <Text: troy @ sequent.com ( Troy Wecker ) writes...>,\n",
       " <Text: R1004 @ vmcms.csuohio.edu writes : > In article...>,\n",
       " <Text: eliot @ stalfos.engr.washington.edu ( eliot ) writes :...>,\n",
       " <Text: aas7 @ po.CWRU.Edu ( Andrew A. Spencer )...>,\n",
       " <Text: In article < 1qvrnpINNnid @ shelley.u.washington.edu > yongje...>,\n",
       " <Text: In article < 1993Apr20.163527.12773 @ bnr.ca > tcorkum...>,\n",
       " <Text: After a tip from Gary Crum ( crum...>,\n",
       " <Text: As a matter of interest does anyone know...>,\n",
       " <Text: kchong @ mothra.nts.uci.edu ( Keith Chong ) writes...>,\n",
       " <Text: We were at a dealership today looking at...>,\n",
       " <Text: In article < 1r93m7INNnb3 @ shelley.u.washington.edu > monet...>,\n",
       " <Text: < rfelixC5sJpE.Bq8 @ netcom.com > < 1r1d62 $...>,\n",
       " <Text: In article < 13798 @ news.duke.edu > infante...>,\n",
       " <Text: > > Admittedly an irrelavent question : for...>,\n",
       " <Text: In article < 1r1crn $ 27g @ transfer.stratus.com...>,\n",
       " <Text: In article < C5w7or.DEx @ news.cso.uiuc.edu > cka52397...>,\n",
       " <Text: In article < 1r6j9lINNac6 @ phakt.usc.edu > rmakarem...>,\n",
       " <Text: In article < 1993Apr22.112904.6771 @ ericsson.se > etxmst...>,\n",
       " <Text: In article < 24553 @ drutx.ATT.COM > klf...>,\n",
       " <Text: X-Newsreader : Tin 1.1 PL5 For Sale :...>,\n",
       " <Text: > Do n't the numbers in the car...>,\n",
       " <Text: In article < C5sxI4.J9B @ news.cso.uiuc.edu > cka52397...>,\n",
       " <Text: In a previous article , eliot @ lanmola.engr.washington.edu...>,\n",
       " <Text: Is there a Honda mailing list , and...>,\n",
       " <Text: In article < tcora-220493100925 @ b329-gator-3.pica.army.mil > tcora...>,\n",
       " <Text: I need to get some info . on...>,\n",
       " <Text: > In article < 1993Apr22.145940.1 @ skcla.monsanto.com >...>,\n",
       " <Text: which are them main trucking companeies and their...>,\n",
       " <Text: : TIN [ version 1.1 PL9.2>,\n",
       " <Text: In article < C5yBo4.E5I @ vcd.hp.com > dmunroe...>,\n",
       " <Text: edwards @ world.std.com ( Jonathan Edwards ) writes...>,\n",
       " <Text: Hi : I am looking for tires ....>,\n",
       " <Text: If I 'm going to drive on a...>,\n",
       " <Text: In article < lth2onINN3r0 @ exodus.Eng.Sun.COM > tut...>,\n",
       " <Text: tszeto @ sneezy.ts.stratus.com ( Tommy Szeto ) writes...>,\n",
       " <Text: In article < 9866 @ ceylon.gte.com > hhd0...>,\n",
       " <Text: Mark Monninger ( markm @ latium . )...>,\n",
       " <Text: I want to get a car alarm and...>,\n",
       " <Text: The rubber drain plugs under my carpet in...>,\n",
       " <Text: In article 2550 @ ericsson.se , etxmst @...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.4-b1 In article <...>,\n",
       " <Text: In article < 1qn19m $ c9s @ vela.acs.oakland.edu...>,\n",
       " <Text: > they are pretty much junk , stay...>,\n",
       " <Text: Nf-ID : # R : opal12:735341980 : trsvax:1178967313:000:304...>,\n",
       " <Text: My wife and I looked at , and...>,\n",
       " <Text: I 'm considering switching to Geico insurance ,...>,\n",
       " <Text: mchaffee @ dcl-nxt07 ( Michael T Chaffee )...>,\n",
       " <Text: [ nntpd-29970>,\n",
       " <Text: > > 'cause a friend rented a car...>,\n",
       " <Text: I have manual transmission 5 speed . It...>,\n",
       " <Text: dmunroe @ vcd.hp.com ( Dave Gauge ) writes...>,\n",
       " <Text: < 1r8ufk $ fr7 @ usenet.INS.CWRU.Edu > <...>,\n",
       " <Text: : TIN [ version 1.1 PL9>,\n",
       " <Text: < 1993Apr15.112826.25211 @ colorado.edu > > From :...>,\n",
       " <Text: X-Newsreader : Tin 1.1 PL4 aas7 @ po.CWRU.Edu...>,\n",
       " <Text: yjwon @ deca.cs.umn.edu ( Youjip Won ) writes...>,\n",
       " <Text: In article < C5K5Co.F09 @ mentor.cc.purdue.edu > thwang...>,\n",
       " <Text: Save youself the cash . Take it from...>,\n",
       " <Text: Originator : qazi @ csd4.csd.uwm.edu From article <...>,\n",
       " <Text: In article < C5L86z.E73 @ cbnewsj.cb.att.com > rdb1...>,\n",
       " <Text: In article < 1qvrnpINNnid @ shelley.u.washington.edu > yongje...>,\n",
       " <Text: x > > x > > > >...>,\n",
       " <Text: In a previous article , aas7 @ po.CWRU.Edu...>,\n",
       " <Text: ljbartel @ naomi.b23b.ingr.com ( Les Bartel ) writes...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 I am in...>,\n",
       " <Text: In article < 93111.12475032HNBAK @ CMUVM.CSV.CMICH.EDU > John...>,\n",
       " <Text: jlong @ emcnext2.tamu.edu ( James Long ) writes...>,\n",
       " <Text: In a previous article , jimf @ centerline.com...>,\n",
       " <Text: Yeah , but I hate to follow them...>,\n",
       " <Text: Originator : dchan @ cisco.com Does anyone know...>,\n",
       " <Text: In article < andrei.735406817 @ namao > andrei...>,\n",
       " <Text: X-Useragent : Nuntius v1.1 < rjnC5sxMG.JqH @ netcom.com...>,\n",
       " <Text: In article < 1993Apr21.100149.1501 @ rtsg.mot.com > ,...>,\n",
       " <Text: * * * * * * * *...>,\n",
       " <Text: markm @ bigfoot.sps.mot.com ( Mark Monninger ) writes...>,\n",
       " <Text: HELP ! ! ! my wife has informed...>,\n",
       " <Text: Since this posting , I 've received no...>,\n",
       " <Text: In a previous article , tedebear @ leland.Stanford.EDU...>,\n",
       " <Text: In article < 1993Apr16.193553.27118 @ mksol.dseg.ti.com > a207706...>,\n",
       " <Text: In article < C5LMtr.Mo7 @ mentor.cc.purdue.edu > marshatt...>,\n",
       " <Text: In article < 1qmcih $ dhs @ armory.centerline.com...>,\n",
       " <Text: Remember roads in America are NOT designed for...>,\n",
       " <Text: Hello , I have a 92 Toyota 4X4...>,\n",
       " <Text: I 'm wondering if anybody else out there...>,\n",
       " <Text: > In article < 1993Apr14.140642.19875 @ cbnewsd.cb.att.com >...>,\n",
       " <Text: To reader , Can anyone out there tell...>,\n",
       " <Text: petebre @ elof.iit.edu ( BrentA . Peterson )...>,\n",
       " <Text: cka52397 @ uxa.cso.uiuc.edu ( OrioleFan @ uiuc )...>,\n",
       " <Text: < 1993Apr23.223836.672 @ magnus.acs.ohio-state.edu > sorlin @ magnus.acs.ohio-state.edu...>,\n",
       " <Text: Excerpts from netnews.rec.autos : 24-Apr-93 Honda Mailing list...>,\n",
       " <Text: : TIN [ version 1.1 PL9>,\n",
       " <Text: I 'm having an interesting problem with my...>,\n",
       " <Text: I was whatching The History Of The Indy...>,\n",
       " <Text: Hi Folks , I recently bought a 1981...>,\n",
       " <Text: I offered to relay this information for a...>,\n",
       " <Text: o Subaru Service Manuals ................................... $ 10.00 This...>,\n",
       " <Text: In article < 1993Apr22.195519.11104 @ convex.com > tobias...>,\n",
       " <Text: Is there anyone out there in NetLand that...>,\n",
       " <Text: In article < 93Apr16.185510.36600 @ acs.ucalgary.ca > ,...>,\n",
       " <Text: : TIN [ version 1.1 PL8.8>,\n",
       " <Text: In article < 185900002 @ hpindda.cup.hp.com > jimb...>,\n",
       " <Text: In article < 1993Apr23.163129.53125 @ gmuvax.gmu.edu > lcarr...>,\n",
       " <Text: When do the new M.benz `` C ''...>,\n",
       " <Text: In article < 1993Apr24.125621.7311 @ magnus.acs.ohio-state.edu > bqueiser...>,\n",
       " <Text: < crh.735198797 @ regent.e-technik.tu-muenchen.de > < Apr19.195700.19699 @...>,\n",
       " <Text: < 1993Apr24.150653.8115 @ magnus.acs.ohio-state.edu > In article <...>,\n",
       " <Text: In article < 1993Apr24.150653.8115 @ magnus.acs.ohio-state.edu > bqueiser...>,\n",
       " <Text: Hey all , I 'm looking at buying...>,\n",
       " <Text: X-Disclaimer : This message was written by a...>,\n",
       " <Text: I am interested in finding out how the...>,\n",
       " <Text: daubendr @ NeXTwork.Rose-Hulman.Edu ( Darren R Daubenspeck )...>,\n",
       " <Text: In article < 1993Apr10.013011.808 @ lrc.edu > ,...>,\n",
       " <Text: Originator : chaos @ merle.acns.nwu.edu For sale :...>,\n",
       " <Text: In article < Apr21.053718.19765 @ engr.washington.edu > ,...>,\n",
       " <Text: RADAR ( Radio Association Defending Airwave Rights )...>,\n",
       " <Text: In article < 23056.74.uupcb @ cutting.hou.tx.us > ,...>,\n",
       " <Text: In article < Apr21.053718.19765 @ engr.washington.edu > ,...>,\n",
       " <Text: In article < C5uLLq.Ds @ acsu.buffalo.edu > v064mb9k...>,\n",
       " <Text: In article < 1993Apr24.145353.8006 @ magnus.acs.ohio-state.edu > bqueiser...>,\n",
       " <Text: jmh @ hopper.Virginia.EDU ( Jeffrey Hoffmeister ) writes...>,\n",
       " <Text: Hi all , I have available to me...>,\n",
       " <Text: In < 1r3n32INNk9p @ ctron-news.ctron.com > smith @...>,\n",
       " <Text: In article < C5uI6u.Ao0 @ murdoch.acc.Virginia.EDU > jmh...>,\n",
       " <Text: In article < 1993Apr15.155325.6329 @ jpl-devvax.jpl.nasa.gov > ,...>,\n",
       " <Text: I am curious about knowing which commericial cars...>,\n",
       " <Text: I am planning on buying a repair manual...>,\n",
       " <Text: In article < CONRADIE.49.735390036 @ firga.sun.ac.za > CONRADIE...>,\n",
       " <Text: You guys are correct . The Bricklin was...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 I am a...>,\n",
       " <Text: I have both an '84 and an '86...>,\n",
       " <Text: X-Software : HERMES GUS 1.04 Rev . Sep...>,\n",
       " <Text: Originator : heiser @ acs2.bu.edu Having recently purchased...>,\n",
       " <Text: I want to start of list for Syclone...>,\n",
       " <Text: In article < 1993Apr21.204521.21182 @ ultb.isc.rit.edu > adn6285...>,\n",
       " <Text: In article < 1993Apr20.124228.5357 @ ncsu.edu > chuck...>,\n",
       " <Text: In article < 1993Apr22.000337.10096 @ news.arc.nasa.gov > chung...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.4-b1 In article <...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.4-b1 In article <...>,\n",
       " <Text: I 'm glad this forum came up ....>,\n",
       " <Text: nuet_ke @ pts.mot.com ( KEITH NUETZMAN X3153 P7625...>,\n",
       " <Text: Probably the most famous V16 is the one...>,\n",
       " <Text: Review of 1989 Ford Taurus SHO -- By...>,\n",
       " <Text: The best auto-shifters on the street ( AND...>,\n",
       " <Text: I just wanted to know : To wheelspin...>,\n",
       " <Text: Dumbest options ? Well here in the UK...>,\n",
       " <Text: In article < 1993Apr22.180150.12377 @ telxon.mis.telxon.com > joes...>,\n",
       " <Text: Does anyone know what kind of car Mad...>,\n",
       " <Text: In article < 1r1r4bINNfja @ tamsun.tamu.edu > jlong...>,\n",
       " <Text: In article < 1993Apr20.163527.12773 @ bnr.ca > tcorkum...>,\n",
       " <Text: - > The current 4.9l V-8 will soldier...>,\n",
       " <Text: Does anybody have any information on the second...>,\n",
       " <Text: Yeah , it seems toyota has always had...>,\n",
       " <Text: In < 1993Apr19.193417.18601 @ ucsu.Colorado.EDU > dunnjj @...>,\n",
       " <Text: article < C5syDn.C2v @ megatest.com > jao @ megatest.com ( John Oswalt ) writes : > [ ...>,\n",
       " <Text: In article 1EL @ targhee.idaho.amdahl.com , rbs @...>,\n",
       " <Text: In article 21071 @ sernews.raleigh.ibm.com , mperry @...>,\n",
       " <Text: I am considering the purchse of a 1987...>,\n",
       " <Text: In article < C5LIw2.CAx @ news.rich.bnr.ca > Peon...>,\n",
       " <Text: X-Newsreader : Tin 1.1 PL4 callison @ uokmax.ecn.uoknor.edu...>,\n",
       " <Text: In article < C5L8rE.28 @ constellation.ecn.uoknor.edu > callison...>,\n",
       " <Text: In article < 1qmcih $ dhs @ armory.centerline.com...>,\n",
       " <Text: In article < oprsfnx.735015349 @ gsusgi1.gsu.edu > oprsfnx...>,\n",
       " <Text: I purchased a used 1988 Nissan 300ZX (...>,\n",
       " <Text: > They beat Ford to the market with...>,\n",
       " <Text: You guys are correct . The Bricklin was...>,\n",
       " <Text: wlsmith @ valve.heart.rri.uwo.ca ( Wayne Smith ) writes...>,\n",
       " <Text: goldberg @ oasys.dt.navy.mil ( Mark Goldberg ) writes...>,\n",
       " <Text: In article < Apr16.215151.28035 @ engr.washington.edu > eliot...>,\n",
       " <Text: As the subject says . It has 70k...>,\n",
       " <Text: : TIN [ version 1.1 PL8>,\n",
       " <Text: Originator : butt @ camis.Stanford.EDU For sale ,...>,\n",
       " <Text: In article < oprsfnx.735015349 @ gsusgi1.gsu.edu > oprsfnx...>,\n",
       " <Text: I looked at that Bimmer yesterday . It...>,\n",
       " <Text: My 85 Caprice Classic with 120K+ miles has...>,\n",
       " <Text: I have a '71 Buick Skylark with 148K...>,\n",
       " <Text: In article < 1993Apr22.041452.27262 @ eecs.nwu.edu > andrew...>,\n",
       " <Text: - > Does that mean that they 're...>,\n",
       " <Text: ssave @ ole.cdac.com ( The Devil Reincarnate )...>,\n",
       " <Text: From article < 1r1i7mINN4n4 @ cronkite.cisco.com > ,...>,\n",
       " <Text: In article < 1993Apr22.044605.29922 @ leland.Stanford.EDU > underdog...>,\n",
       " <Text: Just a quick , simple question really ......>,\n",
       " <Text: I was curious as to what people thought...>,\n",
       " <Text: In article < 1r5acf $ nh1 @ agate.berkeley.edu...>,\n",
       " <Text: anyone else experiencing a similar problem ? This...>,\n",
       " <Text: To anyone with experience about Honda Civic (...>,\n",
       " <Text: Hello , I am moving to Houston to...>,\n",
       " <Text: I have a few questions about the TAX...>,\n",
       " <Text: In article 6126 @ midway.uchicago.edu , buzy @...>,\n",
       " <Text: In article < Apr21.221608.22391 @ engr.washington.edu > ,...>,\n",
       " <Text: Originator : kevinh @ nath In article <...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.4-b1 In article <...>,\n",
       " <Text: -- Are the any Opel GT 's out...>,\n",
       " <Text: Bruce James writes : - > Without the...>,\n",
       " <Text: GM has always screwed the rest of the...>,\n",
       " <Text: < C5yDwp.6G0 @ ncube.com > In article <...>,\n",
       " <Text: In article < 1993Apr19.000758.53229 @ ns1.cc.lehigh.edu > ip02...>,\n",
       " <Text: agate ! iat.holonet.net ! psinntp ! psinntp !...>,\n",
       " <Text: In article 1r3n32INNk9p @ ctron-news.ctron.com , smith @...>,\n",
       " <Text: jchen @ wind.bellcore.com ( Jason Chen ) writes...>,\n",
       " <Text: kissane @ black.Berkeley.EDU ( John G. Kissane )...>,\n",
       " <Text: My son is considering the purchase of a...>,\n",
       " <Text: : TIN [ version 1.1 PL8>,\n",
       " <Text: Originator : kevinh @ nath In article <...>,\n",
       " <Text: From Kay Honda 's `` Helpful HInts ABout...>,\n",
       " <Text: Originator : c23tvr @ koptsy17 In article <...>,\n",
       " <Text: In article < C5uFLH.4p4 @ srgenprp.sr.hp.com > markg...>,\n",
       " <Text: In article < 34666 @ oasys.dt.navy.mil > glouie...>,\n",
       " <Text: In article Dxp @ lut.fi , jahonen @...>,\n",
       " <Text: I would gladly spend twice the money for...>,\n",
       " <Text: AW > > > My 85 Caprice Classic...>,\n",
       " <Text: I was wondering what the country extension are...>,\n",
       " <Text: It 's been a while since I 've...>,\n",
       " <Text: In article < 1993Apr22.045328.630 @ cheshire.oxy.edu > colello...>,\n",
       " <Text: Derek .... There is a tool available to...>,\n",
       " <Text: Just a quick note on the nwe shape...>,\n",
       " <Text: I used to drive a truck a few...>,\n",
       " <Text: In article < 1993Apr23.155215.2838 @ chpc.utexas.edu > ivab015...>,\n",
       " <Text: In article < 1993Apr14.225821.13000 @ advtech.uswest.com > joe...>,\n",
       " <Text: jahonen @ cc.lut.fi ( Jarmo Ahonen ) writes...>,\n",
       " <Text: In article < 185900001 @ hpindda.cup.hp.com > jimb...>,\n",
       " <Text: In rec.autos , grahamt @ phantom.gatech.edu ( Graham...>,\n",
       " <Text: In my opinion , the limited tort option...>,\n",
       " <Text: < 1993Apr22.081335.2550 @ ericsson.se > The Bricklin was...>,\n",
       " <Text: In article < 185900001 @ hpindda.cup.hp.com > ,...>,\n",
       " <Text: In article < C5srIB.6AH @ constellation.ecn.uoknor.edu > ,...>,\n",
       " <Text: newton @ convex.com ( Vicki Newton ) writes...>,\n",
       " <Text: In article < 1993Apr22.143709.13360 @ news.eng.convex.com > newton...>,\n",
       " <Text: -- -- -- -- -- -- -- --...>,\n",
       " <Text: Does anyone have a listing of Pontiac 's...>,\n",
       " <Text: In article < 1993Apr22.052857.9758 @ galileo.cc.rochester.edu > jg003b...>,\n",
       " <Text: Hi everybody ... Well I do n't know...>,\n",
       " <Text: if you want to annoy geico , call...>,\n",
       " <Text: Originator : blf @ stargazer From article <...>,\n",
       " <Text: < 21APR199314371355 @ stdvax > > Still its...>,\n",
       " <Text: Hi , I need your help with a...>,\n",
       " <Text: In article < C5yBo4.E5I @ vcd.hp.com > dmunroe...>,\n",
       " <Text: Could someone explain how to make sense of...>,\n",
       " <Text: Talking about car alarms , there are certain...>,\n",
       " <Text: I dont know about Saabs but whenever there...>,\n",
       " <Text: Yeah ... and BMW 525e has 2.7 litres...>,\n",
       " <Text: Enough , already . Let 's take this...>,\n",
       " <Text: In article < 1993Apr22.143529.20494 @ porthos.cc.bellcore.com > tvl...>,\n",
       " <Text: tvervaek @ col.hp.com ( Tom Vervaeke ) writes...>,\n",
       " <Text: hhd0 @ harvey.gte.com ( Horace Dediu ) writes...>,\n",
       " <Text: Remove LEGEND from the V-8 list , it...>,\n",
       " <Text: > gibbonsa @ fraser.sfu.ca ( Darren Gibbons )...>,\n",
       " <Text: An aquaintence has a 87 Accord . The...>,\n",
       " <Text: jcorry @ erasure_sl.cc.emory.edu ( Jeremy Corry ) writes...>,\n",
       " <Text: Mail bounced , so ... In article <...>,\n",
       " <Text: In article < 66758 @ mimsy.umd.edu > ,...>,\n",
       " <Text: In article < C5yDwp.6G0 @ ncube.com > bob...>,\n",
       " <Text: In article < 1993Apr22.165444.11830 @ wdl.loral.com > gwm...>,\n",
       " <Text: It 's a toll for insurance companies and...>,\n",
       " <Text: GK > Occasionally , I have trouble shifting...>,\n",
       " <Text: GK > I hear that tires for this...>,\n",
       " <Text: In article < 2820016 @ iftccu.ca.boeing.com > ,...>,\n",
       " <Text: In article < 1r3sbbINN8e0 @ hp-col.col.hp.com > ,...>,\n",
       " <Text: Having had my car die on me (...>,\n",
       " <Text: dcd @ se.houston.geoquest.slb.com ( Dan Day ) writes...>,\n",
       " <Text: Does anyone have one of these that would...>,\n",
       " <Text: In article < 1993Apr22.141927.15716 @ bnr.ca > dwjz...>,\n",
       " <Text: In article < 1993Apr22.093956 @ is.morgan.com > sergei...>,\n",
       " <Text: In a previous article , smith @ ctron.com...>,\n",
       " <Text: nataraja @ rtsg.mot.com writes : > I heard...>,\n",
       " <Text: News-Software : IBM OS/2 PM RN ( NR/2...>,\n",
       " <Text: In a previous article , gwm @ spl1.spl.loral.com...>,\n",
       " <Text: The whire wheels are n't chromed , they...>,\n",
       " <Text: My sunroof leaks . I 've always thought...>,\n",
       " <Text: Originator : dchan @ cisco.com In article <...>,\n",
       " <Text: > In article < 1993Apr21.160341.24707 @ westminster.ac.uk >...>,\n",
       " <Text: In article < 1993Apr22.114401.7152 @ ericsson.se > etxmst...>,\n",
       " <Text: I prefer a manual to an automatic as...>,\n",
       " <Text: In article < 1993Apr23.013802.4157 @ freenet.carleton.ca > ae446...>,\n",
       " <Text: In article < 1qofeaINNn7h @ shelley.u.washington.edu > gaia...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.4-b1 As you can...>,\n",
       " <Text: : TIN [ version 1.1 PL9>,\n",
       " <Text: X-Useragent : Nuntius v1.1 In article < 1993Apr26.154428.17764...>,\n",
       " <Text: > > You know , I 'm a...>,\n",
       " <Text: In article < 1993Apr23.163129.53125 @ gmuvax.gmu.edu > ,...>,\n",
       " <Text: News-Software : VAX/VMS VNEWS 1.41 In article <...>,\n",
       " <Text: Go with the Mercedes , if you can...>,\n",
       " <Text: In article < C605Fr.CDo @ cs.uiuc.edu > ,...>,\n",
       " <Text: Originator : leapman @ junior.austin.ibm.com I tried the...>,\n",
       " <Text: Originator : leapman @ junior.austin.ibm.com Before we get...>,\n",
       " <Text: In article < 1r5acf $ nh1 @ agate.berkeley.edu...>,\n",
       " <Text: Originator : homi @ csd4.csd.uwm.edu Hello again ,...>,\n",
       " <Text: In article < 1993Apr21.191744.3072 @ ole.cdac.com > ssave...>,\n",
       " <Text: In article < 1993Apr22.180150.12377 @ telxon.mis.telxon.com > joes...>,\n",
       " <Text: Originator : daveb @ lotus In-reply-to : kissane...>,\n",
       " <Text: This whole discussion is just a religous war...>,\n",
       " <Text: V16 anyone ? Anyone heard of a Cizata...>,\n",
       " <Text: Thanx Craig .... in addition to Craigs coments...>,\n",
       " <Text: Since we 're on the subject of brakes...>,\n",
       " <Text: Yeah , diesels are cleaner than petrol powered...>,\n",
       " <Text: In the EC , the Corrado VR6 is...>,\n",
       " <Text: In article < 1r6omsINNnbk @ ctron-news.ctron.com > smith...>,\n",
       " <Text: Did youy guys know that it is LEGAL...>,\n",
       " <Text: In article < 1r7js5 $ k50 @ biz.ecs.umass.edu...>,\n",
       " <Text: In article < 1993Apr24.003549.126206 @ ns1.cc.lehigh.edu > amh2...>,\n",
       " <Text: In article < 1993Apr26.160911.28922 @ westminster.ac.uk > ,...>,\n",
       " <Text: cbh @ windsurf.scd.ucar.edu ( Cris Hannu ) writes...>,\n",
       " <Text: In article < 21APR199314371355 @ stdvax > oaddab...>,\n",
       " <Text: vlasis @ cybernet.cse.fau.edu ( vlasis theodore ) writes...>,\n",
       " <Text: In article < 1993Apr26.155800.29900 @ noao.edu > ,...>,\n",
       " <Text: In article < 1r7f9qINNk24 @ phantom.gatech.edu > grahamt...>,\n",
       " <Text: Originator : matthews @ cloy.oswego.edu 1954 MG-TF with...>,\n",
       " <Text: In article < 1993Apr26.174602.28054 @ magnus.acs.ohio-state.edu > bqueiser...>,\n",
       " <Text: Originator : dchan @ cisco.com Thanks for all...>,\n",
       " <Text: Hi fellow auto enthusiasts ! Does anyone have...>,\n",
       " <Text: In article < C63uqs.H46 @ usenet.ucs.indiana.edu > Tom...>,\n",
       " <Text: < Apr09.084236.19413 @ engr.washington.edu > < 20726.2bcd8b62 @...>,\n",
       " <Text: Hello all , I know that after market...>,\n",
       " <Text: : TIN [ version 1.1 PL8>,\n",
       " <Text: Any one with experience in having a centreforce...>,\n",
       " <Text: : TIN [ version 1.1.4 PL6>,\n",
       " <Text: A question for any high-mileage Audi owners out...>,\n",
       " <Text: In article < 1993Apr21.191744.3072 @ ole.cdac.com > ssave...>,\n",
       " <Text: [ nntpd-28159>,\n",
       " <Text: In a previous article , george.howell % goucher...>,\n",
       " <Text: wrat @ unisql.UUCP ( wharfie ) writes :...>,\n",
       " <Text: > In the past few years I have...>,\n",
       " <Text: On the subject of the V4 , Ford...>,\n",
       " <Text: kchupp @ kchupp ( Kevin Chupp ) writes...>,\n",
       " <Text: In article < 1993Apr26.193657.10019 @ ultb.isc.rit.edu > adn6285...>,\n",
       " <Text: In article < 1993Apr22.192652.3032 @ virginia.edu > jmm4h...>,\n",
       " <Text: X-Newsreader : Tin 1.1 PL4 dchan @ cisco.com...>,\n",
       " <Text: QUESTION : what 's your experience with car...>,\n",
       " <Text: In article < 24326.74.uupcb @ cutting.hou.tx.us > david.bonds...>,\n",
       " <Text: > Does anybody have any information on the...>,\n",
       " <Text: In article < 1993Apr22.133415.21443 @ magnus.acs.ohio-state.edu > ,...>,\n",
       " <Text: In article < 93112.103631LRR105 @ psuvm.psu.edu > ,...>,\n",
       " <Text: In article < AfqzkhS00iV1E2YIss @ andrew.cmu.edu > ``...>,\n",
       " <Text: I am thinking of buying a used Audi...>,\n",
       " <Text: I 'm new to this group and this...>,\n",
       " <Text: I 've heard * unconfirmed * rumours that...>,\n",
       " <Text: tomh @ metrics.com ( Tom Haapanen ) writes...>,\n",
       " <Text: In a previous article , lusky @ ccwf.cc.utexas.edu...>,\n",
       " <Text: In a previous article , finnegan @ nrlssc.navy.mil...>,\n",
       " <Text: I just entered the market for a Radar...>,\n",
       " <Text: u1815 @ cs.uiuc.edu ( Ronald E Garnett )...>,\n",
       " <Text: I have a 90 Eagle Talon and I...>,\n",
       " <Text: In a previous article , Thomas.Tornblom @ Nexus.Comm.SE...>,\n",
       " <Text: I do n't think that a transmission fluid...>,\n",
       " <Text: I agree with Jeff 's reply . I...>,\n",
       " <Text: Hi Javier , ( how are things at...>,\n",
       " <Text: In article < 1r7cr2INNvar @ sumax.seattleu.edu > smorris...>,\n",
       " <Text: In article < 1993Apr23.183318.4635 @ ll.mit.edu > singer...>,\n",
       " <Text: Ok , so in my ongoing search for...>,\n",
       " <Text: I 'm not sure if this made it...>,\n",
       " <Text: In article < C63ypt.47D @ tsegw.tse.com > pbhandar...>,\n",
       " <Text: In article < 1993Apr16.162950.25849 @ newsgate.sps.mot.com > rapw20...>,\n",
       " <Text: Originator : newman @ howell.cps.msu.edu Okay , okay...>,\n",
       " <Text: In article < 1993Apr26.150614.27597 @ westminster.ac.uk > jkjec...>,\n",
       " <Text: In article < 1rgvv2 $ am4 @ haven.umd.edu...>,\n",
       " <Text: In article < ... > heiser @ acs2.bu.edu...>,\n",
       " <Text: Excerpts from rec.autos : 26-Apr-93 Re : REVIEW...>,\n",
       " <Text: mcrosbie @ batman.bmd.trw.com writes : > In article...>,\n",
       " <Text: In article < 1993Apr21.190251.14371 @ sequent.com > troy...>,\n",
       " <Text: In article < 1993Apr22.204921.12644 @ convex.com > tobias...>,\n",
       " <Text: Originator : homi @ csd4.csd.uwm.edu Hello again ....>,\n",
       " <Text: In article < C5yBo4.E5I @ vcd.hp.com > dmunroe...>,\n",
       " <Text: In article < C63xp2.KJB @ constellation.ecn.uoknor.edu > callison...>,\n",
       " <Text: : TIN [ version 1.1 PL9>,\n",
       " <Text: In article < 1993Apr17.175451.30896 @ ns1.cc.lehigh.edu > ,...>,\n",
       " <Text: In article < C63ypt.47D @ tsegw.tse.com > pbhandar...>,\n",
       " <Text: In article < C5zzD8.1Kt @ mentor.cc.purdue.edu > marshatt...>,\n",
       " <Text: In article < 1993Apr25.180954.20425 @ ultb.isc.rit.edu > ,...>,\n",
       " <Text: In article < oTNm3B1w165w @ cybernet.cse.fau.edu > vlasis...>,\n",
       " <Text: Tony , I believe , first of all...>,\n",
       " <Text: Deloreans NEVER had a factory V8 . They...>,\n",
       " <Text: In article < C64Mux.Bpr @ constellation.ecn.uoknor.edu > callison...>,\n",
       " <Text: In a previous article , ip02 @ ns1.cc.lehigh.edu...>,\n",
       " <Text: Actually I was n't too surprised , since...>,\n",
       " <Text: cka52397 @ uxa.cso.uiuc.edu ( CarolinaFan @ uiuc )...>,\n",
       " <Text: Hi , I was looking for some helpful...>,\n",
       " <Text: In article < 2BD0BDC3.25868 @ news.service.uci.edu > raman...>,\n",
       " <Text: In a previous article , nuet_ke @ pts.mot.com...>,\n",
       " <Text: In a previous article , callison @ uokmax.ecn.uoknor.edu...>,\n",
       " <Text: matmcinn @ nuscc.nus.sg ( Matthew MacIntyre at the...>,\n",
       " <Text: rmt6r @ faraday.clas.Virginia.EDU ( Roy Matthew Thigpen )...>,\n",
       " <Text: In article < 1993Apr17.051701.3419 @ nuscc.nus.sg > matmcinn...>,\n",
       " <Text: eliot @ lanmola.engr.washington.edu ( eliot ) writes :...>,\n",
       " <Text: thwang @ mentor.cc.purdue.edu ( Tommy Hwang ) writes...>,\n",
       " <Text: daubendr @ NeXTwork.Rose-Hulman.Edu ( Darren R Daubenspeck )...>,\n",
       " <Text: In article < 1993Apr24.150653.8115 @ magnus.acs.ohio-state.edu > ,...>,\n",
       " <Text: asdch @ acad2.alaska.edu writes : > Tony ,...>,\n",
       " <Text: In article < Apr24.180313.21646 @ engr.washington.edu > ,...>,\n",
       " <Text: < 34729 @ oasys.dt.navy.mil > < 1993Apr26.155548.28552 @...>,\n",
       " <Text: ssave @ ole.cdac.com ( The Devil Reincarnate )...>,\n",
       " <Text: Can taking the car to a car wash...>,\n",
       " <Text: Eve ' . I am looking to buy...>,\n",
       " <Text: In article < issa.735601408 @ cwis > issa...>,\n",
       " <Text: Originator : kevinh @ nath In article <...>,\n",
       " <Text: I still ca n't understand all the hype...>,\n",
       " <Text: re : extended Ka bands . I recently...>,\n",
       " <Text: < < I wrote > < Is there...>,\n",
       " <Text: In article < 1993Apr27.021456.7594 @ slcs.slb.com > dcd...>,\n",
       " <Text: We have seen lots of discussion on automobile...>,\n",
       " <Text: In article < kfr=ewC00WA1Q6wtt7 @ andrew.cmu.edu > ,...>,\n",
       " <Text: In article anl @ ollie.solbourne.com , guerra @...>,\n",
       " <Text: Greetings automobile enthusiasts . Can anyone tell me...>,\n",
       " <Text: X-Newsreader : NN version 6.4.19 # 1 I...>,\n",
       " <Text: Hello everyone , I have an insurance question...>,\n",
       " <Text: In < 1ri9rv $ jfl @ msuinfo.cl.msu.edu >...>,\n",
       " <Text: In article < C63rrw.1G9w @ austin.ibm.com > $...>,\n",
       " <Text: > > And bythe way 5.0 and Camaro...>,\n",
       " <Text: > Safety is an important criterium for me...>,\n",
       " <Text: In article < 1993Apr26.143540.29917 @ cs.tulane.edu > ,...>,\n",
       " <Text: In article < bense.33.735855979 @ oasys.dt.navy.mil > bense...>,\n",
       " <Text: Hi there , maybe you can help me...>,\n",
       " <Text: Well , the Opel deal fell through ......>,\n",
       " <Text: In article < 1993Apr27.172335.23392 @ magnus.acs.ohio-state.edu > bbarnard...>,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycrawled_nltktexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Make all crawled texts lowercase\n",
    "mycrawled_lowercasetexts = []\n",
    "for k in range(len(mycrawled_nltktexts)):\n",
    "    temp_lowercasetext = []\n",
    "    for l in range(len(mycrawled_nltktexts[k])):\n",
    "        lowercaseword = mycrawled_nltktexts[k][l].lower()\n",
    "        temp_lowercasetext.append(lowercaseword)\n",
    "    temp_lowercasetest = nltk.Text(temp_lowercasetext)\n",
    "    mycrawled_lowercasetexts.append(temp_lowercasetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Convert a POS tag for WordNet\n",
    "def tagtowordnet(postag):\n",
    "    wordnettag = -1\n",
    "    if postag[0] == \"N\":\n",
    "        wordnettag = \"n\"\n",
    "    elif postag[0] == \"V\":\n",
    "        wordnettag = \"v\"\n",
    "    elif postag[0] == \"J\":\n",
    "        wordnettag = \"a\"\n",
    "    elif postag[0] == \"R\":\n",
    "        wordnettag = \"r\"\n",
    "    return wordnettag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% POS tag and lemmatize the loaded texts\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemmatizetext(nltktexttolemmatize):\n",
    "    # Tag the text with POS tags\n",
    "    taggedtext = nltk.pos_tag(nltktexttolemmatize)\n",
    "    # Lemmatize each word text\n",
    "    lemmatizedtext = []\n",
    "    for l in range(len(taggedtext)):\n",
    "        # Lemmatize a word using the WordNet converted POS tag\n",
    "        wordtolemmatize = taggedtext[l][0]\n",
    "        wordnettag = tagtowordnet(taggedtext[l][1])\n",
    "        if wordnettag != -1:\n",
    "            lemmatizedword = lemmatizer.lemmatize(wordtolemmatize, wordnettag)\n",
    "        else:\n",
    "            lemmatizedword = wordtolemmatize\n",
    "        # Store the lemmatized word\n",
    "        lemmatizedtext.append(lemmatizedword)\n",
    "    return lemmatizedtext\n",
    "\n",
    "\n",
    "mycrawled_lemmatizedtexts = []\n",
    "for k in range(len(mycrawled_lowercasetexts)):\n",
    "    lemmatizedtext = lemmatizetext(mycrawled_lowercasetexts[k])\n",
    "    lemmatizedtext = nltk.Text(lemmatizedtext)\n",
    "    mycrawled_lemmatizedtexts.append(lemmatizedtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Find the vocabulary, in a distributed fashion\n",
    "myvocabularies = []\n",
    "myindices_in_vocabularies = []\n",
    "# Find the vocabulary of each document\n",
    "for k in range(len(mycrawled_lemmatizedtexts)):\n",
    "    # Get unique words and where they occur\n",
    "    temptext = mycrawled_lemmatizedtexts[k]\n",
    "    uniqueresults = numpy.unique(temptext, return_inverse=True)\n",
    "    uniquewords = uniqueresults[0]\n",
    "    wordindices = uniqueresults[1]\n",
    "    # Store the vocabulary and indices of document words in it\n",
    "    myvocabularies.append(uniquewords)\n",
    "    myindices_in_vocabularies.append(wordindices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify the vocabularies.\n",
    "# First concatenate all vocabularies\n",
    "tempvocabulary = []\n",
    "for k in range(len(mycrawled_lemmatizedtexts)):\n",
    "    tempvocabulary.extend(myvocabularies[k])\n",
    "# Find the unique elements among all vocabularies\n",
    "uniqueresults = numpy.unique(tempvocabulary, return_inverse=True)\n",
    "unifiedvocabulary = uniqueresults[0]\n",
    "wordindices = uniqueresults[1]\n",
    "# Translate previous indices to the unified vocabulary.\n",
    "# Must keep track where each vocabulary started in\n",
    "# the concatenated one.\n",
    "vocabularystart = 0\n",
    "myindices_in_unifiedvocabulary = []\n",
    "for k in range(len(mycrawled_lemmatizedtexts)):\n",
    "    # In order to shift word indices, we must temporarily\n",
    "    # change their data type to a Numpy array\n",
    "    tempindices = numpy.array(myindices_in_vocabularies[k])\n",
    "    tempindices = tempindices + vocabularystart\n",
    "    tempindices = wordindices[tempindices]\n",
    "    myindices_in_unifiedvocabulary.append(tempindices)\n",
    "    vocabularystart = vocabularystart + len(myvocabularies[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Count the numbers of occurrences of each unique word\n",
    "# Let's count also various statistics over the documents\n",
    "unifiedvocabulary_totaloccurrencecounts = numpy.zeros((len(unifiedvocabulary), 1))\n",
    "unifiedvocabulary_documentcounts = numpy.zeros((len(unifiedvocabulary), 1))\n",
    "unifiedvocabulary_meancounts = numpy.zeros((len(unifiedvocabulary), 1))\n",
    "unifiedvocabulary_countvariances = numpy.zeros((len(unifiedvocabulary), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pass: count occurrences\n",
    "for k in range(len(mycrawled_lemmatizedtexts)):\n",
    "    occurrencecounts = numpy.zeros((len(unifiedvocabulary), 1))\n",
    "    for l in range(len(myindices_in_unifiedvocabulary[k])):\n",
    "        occurrencecounts[myindices_in_unifiedvocabulary[k][l]] = (\n",
    "            occurrencecounts[myindices_in_unifiedvocabulary[k][l]] + 1\n",
    "        )\n",
    "    unifiedvocabulary_totaloccurrencecounts = (\n",
    "        unifiedvocabulary_totaloccurrencecounts + occurrencecounts\n",
    "    )\n",
    "    unifiedvocabulary_documentcounts = unifiedvocabulary_documentcounts + (\n",
    "        occurrencecounts > 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>' 'the' ',' '.' '--' 'be' '*' 'a' 'to' 'i' ')' 'in' 'and' '(' 'of' ':'\n",
      " '@' 'have' 'that' 'it' 'you' '!' 'for' 'do' '?' 'on' '|' \"'s\" '-' \"n't\"\n",
      " 'this' \"''\" 'with' 'but' 'he' 'not' '0' 'they' '1' 'as' '<' 'at' 'if'\n",
      " 'get' '``' 'write' 'or' 'my' '...' '2' 'article' 'game' 'go' 'would' '#'\n",
      " 'can' 'about' 'one' 'will' 'all' 'there' 'an' 'what' 'from' 'out' 'so'\n",
      " 'good' 'car' 'like' 'year' 'think' 'by' 'me' 'team' 'up' 'his' '%' 'just'\n",
      " 'when' '3' 'more' 'make' 'your' 'no' 'know' 'any' 'say' 'who' 'than' '4'\n",
      " 'we' 'time' 'some' 'play' 'well' 'see' 'how' 'player' 'win' 'only']\n",
      "[40640. 40032. 39497. 39110. 35859. 27296. 20092. 17910. 17358. 15952.\n",
      " 14883. 14110. 14036. 13692. 13180. 11444.  9901.  9477.  9199.  8716.\n",
      "  7144.  7079.  7017.  6890.  6686.  6048.  6030.  5907.  4914.  4911.\n",
      "  4768.  4515.  4514.  4288.  4140.  4041.  3977.  3925.  3803.  3753.\n",
      "  3648.  3569.  3533.  3267.  3265.  3261.  3241.  3225.  2855.  2854.\n",
      "  2745.  2728.  2696.  2671.  2518.  2416.  2392.  2376.  2314.  2295.\n",
      "  2259.  2257.  2254.  2249.  2219.  2204.  2098.  2078.  2077.  2057.\n",
      "  2044.  2043.  1990.  1959.  1938.  1879.  1869.  1867.  1859.  1821.\n",
      "  1762.  1762.  1762.  1760.  1758.  1752.  1735.  1712.  1572.  1566.\n",
      "  1559.  1522.  1498.  1463.  1425.  1396.  1370.  1348.  1304.  1303.]\n"
     ]
    }
   ],
   "source": [
    "# %% Inspect frequent words\n",
    "# Sort words by largest total (or mean) occurrence count\n",
    "highest_totaloccurrences_indices = numpy.argsort(\n",
    "    -1 * unifiedvocabulary_totaloccurrencecounts, axis=0\n",
    ")\n",
    "print(numpy.squeeze(unifiedvocabulary[highest_totaloccurrences_indices[0:100]]))\n",
    "print(\n",
    "    numpy.squeeze(\n",
    "        unifiedvocabulary_totaloccurrencecounts[highest_totaloccurrences_indices[0:100]]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42038"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unifiedvocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Vocabulary pruning\n",
    "nltkstopwords=nltk.corpus.stopwords.words('english')\n",
    "pruningdecisions=numpy.zeros((len(unifiedvocabulary),1))\n",
    "for k in range(len(unifiedvocabulary)):\n",
    "    # Rule 1: check the nltk stop word list\n",
    "    if (unifiedvocabulary[k] in nltkstopwords):\n",
    "        pruningdecisions[k]=1\n",
    "    # Rule 2: if the word is in the top 1% of frequent words\n",
    "    if (k in highest_totaloccurrences_indices[\\\n",
    "        0:int(numpy.floor(len(unifiedvocabulary)*0.01))]):\n",
    "        pruningdecisions[k]=1\n",
    "    # Rule 3: if the word is too short\n",
    "    if len(unifiedvocabulary[k])<3:\n",
    "        pruningdecisions[k]=1\n",
    "    # Rule 4: if the word is too long\n",
    "    if len(unifiedvocabulary[k])>20:\n",
    "        pruningdecisions[k]=1\n",
    "    # Rule 5: if the word has unwanted characters\n",
    "    # (here for simplicity only a-z allowed)\n",
    "    # if unifiedvocabulary[k].isalpha()==False:\n",
    "    #     pruningdecisions[k]=1\n",
    "    # Rule 7: if the word occurs less than 4 times\n",
    "    if(unifiedvocabulary_totaloccurrencecounts[k] < 4):\n",
    "        pruningdecisions[k] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wheel' 'yet' 'driver' 'live' 'model' 'able' 'bit' 'ago' 'city' 'cost'\n",
      " 'total' 'mind' 'mention' 'man' 'brave' 'ford' 'penalty' 'final' 'large'\n",
      " 'anyway' 'bill' 'idea' 'coach' 'saw' 'performance' 'beat' 'version'\n",
      " 'montreal' 'rule' 'group' 'ice' 'seat' 'face' 'hitter' 'friend'\n",
      " 'although' 'almost' 'today' 'order' 'comment' 'bos' 'minute' 'stats'\n",
      " 'hold' 'det' 'follow' 'american' 'insurance' 'job' 'month' 'walk' 'local'\n",
      " 'past' 'smith' 'joe' 'honda' 'easy' 'tie' 'cal' 'news' 'hell' 'ticket'\n",
      " 'x-newsreader' 'wait' 'bring' 'hope' 'jet' 'helmet' 'stuff' 'morris'\n",
      " 'rider' 'left' 'word' 'compare' 'van' 'note' 'experience' 'york' 'center'\n",
      " 'information' 'flyer' 'add' 'rear' 'pen' 'puck' 'contact' 'set' 'defense'\n",
      " 'young' 'break' 'netcom.com' 'others' 'claim' 'later' 'e-mail' 'design'\n",
      " 'matter' 'late' 'whether' 'tor']\n",
      "[254. 253. 251. 251. 250. 249. 248. 247. 246. 246. 245. 245. 244. 244.\n",
      " 243. 241. 240. 240. 239. 237. 232. 232. 230. 229. 229. 228. 225. 224.\n",
      " 223. 222. 222. 222. 221. 221. 221. 220. 219. 219. 219. 218. 218. 217.\n",
      " 217. 216. 215. 215. 213. 213. 213. 212. 212. 211. 211. 211. 210. 210.\n",
      " 210. 210. 209. 208. 208. 207. 207. 207. 207. 205. 204. 204. 203. 202.\n",
      " 202. 201. 201. 201. 201. 201. 199. 199. 198. 197. 197. 197. 196. 196.\n",
      " 196. 196. 196. 196. 196. 196. 195. 194. 193. 193. 193. 192. 191. 191.\n",
      " 189. 189.]\n"
     ]
    }
   ],
   "source": [
    "#%% Inspect remaining frequent words\n",
    "# Sort remaining words by largest total (or mean) occurrence count\n",
    "remainingindices=numpy.squeeze(numpy.where(pruningdecisions==0)[0])\n",
    "remainingvocabulary=unifiedvocabulary[remainingindices]\n",
    "remainingvocabulary_totaloccurrencecounts= \\\n",
    "    unifiedvocabulary_totaloccurrencecounts[remainingindices]\n",
    "remaining_highest_totaloccurrences_indices= \\\n",
    "    numpy.argsort(-1*remainingvocabulary_totaloccurrencecounts,axis=0)\n",
    "print(numpy.squeeze(remainingvocabulary[remaining_highest_totaloccurrences_indices[0:100]]))\n",
    "print(numpy.squeeze(remainingvocabulary_totaloccurrencecounts[ \\\n",
    "    remaining_highest_totaloccurrences_indices[0:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Get indices of documents to remaining words\n",
    "oldtopruned = []\n",
    "tempind = -1\n",
    "for k in range(len(unifiedvocabulary)):\n",
    "    if pruningdecisions[k] == 0:\n",
    "        tempind = tempind + 1\n",
    "        oldtopruned.append(tempind)\n",
    "    else:\n",
    "        oldtopruned.append(-1)\n",
    "\n",
    "# %% Create pruned texts\n",
    "\n",
    "mycrawled_prunedtexts = []\n",
    "myindices_in_prunedvocabulary = []\n",
    "for k in range(len(mycrawled_lemmatizedtexts)):\n",
    "    temp_newindices = []\n",
    "    temp_newdoc = []\n",
    "    for l in range(len(mycrawled_lemmatizedtexts[k])):\n",
    "        temp_oldindex = myindices_in_unifiedvocabulary[k][l]\n",
    "        temp_newindex = oldtopruned[temp_oldindex]\n",
    "        if temp_newindex != -1:\n",
    "            temp_newindices.append(temp_newindex)\n",
    "            temp_newdoc.append(unifiedvocabulary[temp_oldindex])\n",
    "    mycrawled_prunedtexts.append(temp_newdoc)\n",
    "    myindices_in_prunedvocabulary.append(temp_newindices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Create a TF-IDF representation for the documents, using Length-normalized frequency (TF)\n",
    "and Smoothed logarithmic inverse document frequency (IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Create TF-IDF vectors\n",
    "n_docs = len(mycrawled_prunedtexts)\n",
    "n_vocab = len(remainingvocabulary)\n",
    "# Matrix of term frequencies\n",
    "tfmatrix = scipy.sparse.lil_matrix((n_docs, n_vocab))\n",
    "# Row vector of document frequencies\n",
    "dfvector = scipy.sparse.lil_matrix((1, n_vocab))\n",
    "# Loop over documents\n",
    "for k in range(n_docs):\n",
    "    # Row vector of which words occurred in this document\n",
    "    temp_dfvector = scipy.sparse.lil_matrix((1, n_vocab))\n",
    "    # Loop over words\n",
    "    for l in range(len(mycrawled_prunedtexts[k])):\n",
    "        # Add current word to term-frequency count and document-count\n",
    "        currentword = myindices_in_prunedvocabulary[k][l]\n",
    "        tfmatrix[k, currentword] = tfmatrix[k, currentword] + 1\n",
    "        temp_dfvector[0, currentword] = 1\n",
    "    # Add which words occurred in this document to overall document counts\n",
    "    dfvector = dfvector + temp_dfvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length-normalized frequency for the TF part\n",
    "for i in range(n_docs):\n",
    "    for j in range(len(tfmatrix.data[i])):\n",
    "        tfmatrix.data[i][j] = tfmatrix.data[i][j] / len(mycrawled_prunedtexts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use raw term count, and smoothed logarithmic idf\n",
    "idfvector = numpy.squeeze(numpy.array(dfvector.todense()))\n",
    "idfvector=1+numpy.log(((idfvector+1)**-1)*n_docs)\n",
    "# Use the count statistics to compute the tf-idf matrix\n",
    "tfidfmatrix = scipy.sparse.lil_matrix((n_docs, n_vocab))\n",
    "for k in range(n_docs):\n",
    "    # Combine the tf and idf terms\n",
    "    tempindices = numpy.nonzero(tfmatrix[k, :])[1]\n",
    "    tfterm = numpy.squeeze(numpy.array(tfmatrix[k, tempindices].todense()))\n",
    "    tfidfmatrix[k, tempindices] = tfterm * idfvector[tempindices]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Apply latent semantic analysis to the TF-IDF matrix, to find 10 underlying factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute 10 factors from LSA\n",
    "n_low_dimensions = 10\n",
    "Uleft, D, UrightT = scipy.sparse.linalg.svds(tfidfmatrix.todense(), k=n_low_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.94222698 4.95987316 5.07631109 5.11003131 5.22036183 5.63519183\n",
      " 5.9375771  6.68093678 7.36644399 7.78621439]\n"
     ]
    }
   ],
   "source": [
    "# Examine the singular values\n",
    "# print(D)\n",
    "# Examine a factor (here the one with largest singular value)\n",
    "# print(UrightT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 words with largest absolute weights in factor 1\n",
      "-------------------------------------------------------------\n",
      "['osf.org' 'research.nj.nec.com' 'tin' 'x-newsreader' '1.1' 'version'\n",
      " 'group' 'pl8' 'appreciate' 'honda']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 2\n",
      "-------------------------------------------------------------\n",
      "['tin' 'x-newsreader' '1.1' 'version' 'pl8' 'osf.org'\n",
      " 'research.nj.nec.com' 'appreciate' 'group' 'pl4']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 3\n",
      "-------------------------------------------------------------\n",
      "['altima' 'generic' 'jewish' 'kingman' 'appreciate' 'stanza' 'nissan'\n",
      " 'group' 'paperwork' 'nameplate']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 4\n",
      "-------------------------------------------------------------\n",
      "['jewish' 'kingman' 'tin' 'x-newsreader' '1.1' 'vb30'\n",
      " 'lafibm.lafayette.edu' 'appreciate' 'acad.drake.edu' 'version']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 5\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'cub' 'tin' 'x-newsreader' 'captain' 'jewish' '1.1'\n",
      " 'version' 'join' 'kingman']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 6\n",
      "-------------------------------------------------------------\n",
      "['luck' 'jim' 'appreciate' 'advance' 'group' 'cub' 'honda' 'e-mail'\n",
      " 'captain' 'stats']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 7\n",
      "-------------------------------------------------------------\n",
      "['luck' 'appreciate' 'x-newsreader' 'tin' '1.1' 'version' 'jim' 'e-mail'\n",
      " 'stats' 'group']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 8\n",
      "-------------------------------------------------------------\n",
      "['mattingly' 'career' '.....' 'tesla.njit.edu' 'baseman' 'history'\n",
      " 'drm6640' 'overall' '1993apr20.102857.1' 'yankee']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 9\n",
      "-------------------------------------------------------------\n",
      "['inquiry' 'rider.cactus.org' 'joe' 'senner' 'manually' 'austin' 'reply'\n",
      " 'directly' 'michael' 'return']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 10\n",
      "-------------------------------------------------------------\n",
      "['test' 'hello' 'message' 'bye' 'flames' 'dream' 'resident' 'license'\n",
      " 'viper' 'dad']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10 words with largest absolute weights in each factor\n",
    "for i in range(UrightT.shape[0]):\n",
    "    print('10 words with largest absolute weights in factor ' + str(i+1))\n",
    "    print('-------------------------------------------------------------')\n",
    "    topweights_indices=numpy.argsort(-1*numpy.abs(UrightT[i,:]))\n",
    "    print(remainingvocabulary[topweights_indices[0:10]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some words, which is realted to the main subject of the directory.\n",
    "For example:\n",
    "\n",
    "rec.autos: honda, pl8, nissan, kingman, altima, tesla.njit.edu, license, 1993apr20.102857.1...\n",
    "rec.motorcycles: nissan, honda, kingman, cub, rider.cactus.org, license...\n",
    "rec.sport.baseball: captain, career, group, baseman,...\n",
    "rec.sport.hockey: career, dream, group,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Do the same with 15 factors (the first 10 factors will be the same). Do the new 5 factors seem more or less meaningful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 15 factors from LSA\n",
    "n_low_dimensions = 15\n",
    "Uleft, D, UrightT = scipy.sparse.linalg.svds(tfidfmatrix.todense(), k=n_low_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 words with largest absolute weights in factor 1\n",
      "-------------------------------------------------------------\n",
      "['arocha' '=-=' 'eliot' 'jeffries' 'status' 'yankee' 'blah' 'stats'\n",
      " 'thank' 'dolven']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 2\n",
      "-------------------------------------------------------------\n",
      "['honda' 'subscribe' 'group' 'tour' 'lake' 'forget' 'final' 'blah' 'stats'\n",
      " 'advantage']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 3\n",
      "-------------------------------------------------------------\n",
      "['group' 'lake' 'final' 'maine' 'advantage' '5-4' 'lssu' 'blah'\n",
      " 'appreciate' 'terry']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 4\n",
      "-------------------------------------------------------------\n",
      "['advantage' 'lake' 'final' 'group' 'maine' '5-4' 'lssu' 'honda' 'terry'\n",
      " 'blah']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 5\n",
      "-------------------------------------------------------------\n",
      "['advantage' 'group' 'lake' 'final' 'honda' 'maine' 'subscribe' '5-4'\n",
      " 'blah' 'lssu']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 6\n",
      "-------------------------------------------------------------\n",
      "['osf.org' 'research.nj.nec.com' 'tin' 'x-newsreader' '1.1' 'version'\n",
      " 'group' 'pl8' 'appreciate' 'honda']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 7\n",
      "-------------------------------------------------------------\n",
      "['tin' 'x-newsreader' '1.1' 'version' 'pl8' 'osf.org'\n",
      " 'research.nj.nec.com' 'appreciate' 'group' 'pl4']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 8\n",
      "-------------------------------------------------------------\n",
      "['altima' 'generic' 'jewish' 'kingman' 'appreciate' 'stanza' 'nissan'\n",
      " 'group' 'paperwork' 'nameplate']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 9\n",
      "-------------------------------------------------------------\n",
      "['jewish' 'kingman' 'tin' 'x-newsreader' '1.1' 'vb30'\n",
      " 'lafibm.lafayette.edu' 'appreciate' 'acad.drake.edu' 'version']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 10\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'cub' 'tin' 'x-newsreader' 'captain' 'jewish' '1.1'\n",
      " 'version' 'join' 'kingman']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 11\n",
      "-------------------------------------------------------------\n",
      "['luck' 'jim' 'appreciate' 'advance' 'group' 'cub' 'honda' 'e-mail'\n",
      " 'captain' 'stats']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 12\n",
      "-------------------------------------------------------------\n",
      "['luck' 'appreciate' 'x-newsreader' 'tin' '1.1' 'version' 'jim' 'e-mail'\n",
      " 'stats' 'group']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 13\n",
      "-------------------------------------------------------------\n",
      "['mattingly' 'career' '.....' 'tesla.njit.edu' 'baseman' 'history'\n",
      " 'drm6640' 'overall' '1993apr20.102857.1' 'yankee']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 14\n",
      "-------------------------------------------------------------\n",
      "['inquiry' 'rider.cactus.org' 'joe' 'senner' 'manually' 'austin' 'reply'\n",
      " 'directly' 'michael' 'return']\n",
      "\n",
      "\n",
      "10 words with largest absolute weights in factor 15\n",
      "-------------------------------------------------------------\n",
      "['test' 'hello' 'message' 'bye' 'flames' 'dream' 'resident' 'license'\n",
      " 'viper' 'dad']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10 words with largest absolute weights in each factor\n",
    "for i in range(UrightT.shape[0]):\n",
    "    print('10 words with largest absolute weights in factor ' + str(i+1))\n",
    "    print('-------------------------------------------------------------')\n",
    "    topweights_indices=numpy.argsort(-1*numpy.abs(UrightT[i,:]))\n",
    "    print(remainingvocabulary[topweights_indices[0:10]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new 5 factors seem less meaningful as they are overlapping with the first 10 factors and fewer words are related to the main subject of the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 6.2: Probabilistic latent semantic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Using the same data as in Exercise 6.1 (four newsgroups), create a term frequency matrix of raw term counts for the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Apply PLSA to the term frequency matrix to find 10 underlying factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, numpy.matlib, scipy, scipy.stats\n",
    "def plsa(document_to_word_matrix, n_topics, n_iterations):    \n",
    "    n_docs=numpy.shape(document_to_word_matrix)[0]            # Number of documents and vocabulary words\n",
    "    n_vocab=numpy.shape(document_to_word_matrix)[1]       \n",
    "    theta = scipy.stats.uniform.rvs(size=(n_vocab,n_topics))  # Prob of words per topic: random init\n",
    "    theta = theta/numpy.matlib.repmat(numpy.sum(theta,axis=0),n_vocab,1)    \n",
    "    psi = scipy.stats.uniform.rvs(size=(n_topics,n_docs))     # Probs topics per document: random init\n",
    "    psi = psi/numpy.matlib.repmat(numpy.sum(psi,axis=0),n_topics,1)    \n",
    "    n_words_in_docs = numpy.squeeze(numpy.array(             # Numbers of words in documents: computed once\n",
    "        numpy.sum(document_to_word_matrix,axis=1)))    \n",
    "    n_totalwords = numpy.sum(n_words_in_docs)                 # Total number of words: computed once    \n",
    "    pi = n_words_in_docs/n_totalwords                         # Document probs: computed once        \n",
    "    for myiter in range(n_iterations):                        # Perform Expectation-Maximization iterations\n",
    "        # ===Perform E-step====\n",
    "        doc_word_to_topics = []               # Compute theta_{v|t}psi_{t|d}/sum_t' theta_{v|t'}psi_{t'|d} \n",
    "        doc_word_to_topic_sum = numpy.zeros((n_docs,n_vocab))               \n",
    "        for t in range(n_topics):\n",
    "            doc_word_to_topict = \\\n",
    "                numpy.matlib.repmat(theta[:,t],n_docs,1) * \\\n",
    "                numpy.matlib.repmat(psi[t,:],n_vocab,1).T             \n",
    "            myepsilon=1e-14           # Add a positive number to avoid divisions by zero\n",
    "            doc_word_to_topict += myepsilon \n",
    "            doc_word_to_topics.append(doc_word_to_topict)\n",
    "            doc_word_to_topic_sum += doc_word_to_topict\n",
    "        # Print the progress of the algorithm every 5% of iterations\n",
    "        if numpy.mod(myiter,numpy.floor(n_iterations/20))==0:\n",
    "            print('Iteration ' + str(myiter) + ' of ' + str(n_iterations))\n",
    "        for t in range(n_topics):\n",
    "            doc_word_to_topics[t] /= doc_word_to_topic_sum \n",
    "        # =======Perform M-step=======                        \n",
    "        # Add a small number to word counts to avoid divisions by zero\n",
    "        for t in range(n_topics):                            # Compute document-to-topic probabilities.\n",
    "            psi[t,:] = numpy.squeeze(numpy.array(numpy.sum( \\\n",
    "               numpy.multiply(document_to_word_matrix+myepsilon,doc_word_to_topics[t]),axis=1)))        \n",
    "        psi /= numpy.matlib.repmat(numpy.sum(psi,axis=0),n_topics,1)        \n",
    "        for t in range(n_topics):                            # Compute topic-to-word probabilities\n",
    "            theta[:,t]= numpy.squeeze(numpy.array(numpy.sum( \\\n",
    "                 numpy.multiply(document_to_word_matrix,doc_word_to_topics[t]),axis=0).T))       \n",
    "        theta /= numpy.matlib.repmat(numpy.sum(theta,axis=0),n_vocab,1)\n",
    "    return(pi,psi,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 of 200\n",
      "Iteration 10 of 200\n",
      "Iteration 20 of 200\n",
      "Iteration 30 of 200\n",
      "Iteration 40 of 200\n",
      "Iteration 50 of 200\n",
      "Iteration 60 of 200\n",
      "Iteration 70 of 200\n",
      "Iteration 80 of 200\n",
      "Iteration 90 of 200\n",
      "Iteration 100 of 200\n",
      "Iteration 110 of 200\n",
      "Iteration 120 of 200\n",
      "Iteration 130 of 200\n",
      "Iteration 140 of 200\n",
      "Iteration 150 of 200\n",
      "Iteration 160 of 200\n",
      "Iteration 170 of 200\n",
      "Iteration 180 of 200\n",
      "Iteration 190 of 200\n"
     ]
    }
   ],
   "source": [
    "#%% Try PLSA on a very small data set\n",
    "# Let's take the same 500 features as in LSI, \n",
    "# and the same 1000 baseball documents but use\n",
    "# the term-frequency (TF) values for the features\n",
    "dimensiontotals=numpy.squeeze(numpy.array(numpy.sum(tfidfmatrix,axis=0)))\n",
    "highesttotals=numpy.argsort(-1*dimensiontotals)\n",
    "Xsmall=tfmatrix[:,highesttotals[0:500]].todense()\n",
    "\n",
    "# Due to the progress is really slow, we will limit Xsmall\n",
    "# Run PLSA\n",
    "n_topics=10\n",
    "n_iterations=200\n",
    "pi,psi,theta=plsa(Xsmall, n_topics, n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10072331 0.11888919 0.1144711  0.09718951 0.09335478 0.08529077\n",
      " 0.09806643 0.08731324 0.09328984 0.11141181]\n"
     ]
    }
   ],
   "source": [
    "# Examine the factor probabilities p(t) = sum_d p(t|d) p(d)\n",
    "print(numpy.sum(psi*numpy.matlib.repmat(pi,n_topics,1),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.23519449e-14 3.61921970e-14 5.51155102e-14 8.92854254e-14\n",
      " 2.68913444e-14 4.68117189e-14 2.22540615e-14 6.29719086e-14\n",
      " 8.21385373e-14 2.05973091e-14 6.80604126e-03 4.07289393e-14\n",
      " 3.49066954e-03 5.91797288e-14 9.33565208e-14 2.91972735e-02\n",
      " 8.06864014e-03 6.69046476e-14 3.93836766e-14 1.80921007e-02\n",
      " 2.63238919e-02 1.87210794e-13 2.30226157e-13 5.50440314e-14\n",
      " 6.31047409e-14 1.37492096e-13 5.59832019e-14 2.50968681e-03\n",
      " 5.74334758e-14 4.29524364e-14 1.19586598e-02 6.38241939e-14\n",
      " 3.75930694e-14 2.77888024e-14 8.87490917e-14 5.30363440e-03\n",
      " 1.41782277e-13 4.90522970e-14 5.57111703e-14 1.71061811e-13\n",
      " 1.44548989e-14 8.39292098e-03 7.97421553e-14 7.60799880e-13\n",
      " 1.03118091e-12 1.29038344e-13 6.21256602e-14 6.58959030e-14\n",
      " 5.90213397e-03 1.29328147e-13 6.60231477e-14 1.73968286e-13\n",
      " 5.35671718e-14 1.16596851e-02 4.33086614e-14 1.22426050e-13\n",
      " 8.14149267e-14 3.02502059e-13 1.91406945e-13 1.04255786e-13\n",
      " 3.05050952e-13 1.17067091e-02 1.95935906e-02 4.36587948e-14\n",
      " 7.20427193e-14 1.03056969e-13 1.99287770e-02 2.19404918e-02\n",
      " 1.10913991e-10 1.03334157e-02 6.97167477e-14 3.94449139e-14\n",
      " 2.73785960e-13 3.28483428e-14 7.35534543e-14 2.43545865e-02\n",
      " 1.01907212e-13 1.59655480e-14 9.59654247e-03 9.36210031e-14\n",
      " 1.08471507e-13 2.68003614e-13 1.52797509e-02 3.47658132e-10\n",
      " 1.18629332e-13 4.88556910e-14 2.82203715e-14 8.38997576e-14\n",
      " 9.45569961e-14 1.19722642e-13 1.60762378e-13 5.43757452e-14\n",
      " 1.92881870e-13 8.22964141e-03 3.25650186e-14 5.38769454e-14\n",
      " 1.60119442e-13 6.52094208e-14 6.60998688e-03 1.45427064e-13\n",
      " 5.24816136e-14 3.73830016e-14 4.61524081e-03 1.33795778e-13\n",
      " 8.26838268e-14 1.59813323e-10 4.62702986e-03 7.58119314e-14\n",
      " 1.70589756e-13 5.57570685e-14 1.51220066e-02 5.39185372e-13\n",
      " 3.32351202e-14 2.10726605e-13 1.29595155e-03 5.41911031e-14\n",
      " 1.00696629e-02 1.49386665e-13 3.38999734e-13 2.37126753e-13\n",
      " 6.15819600e-14 6.60101247e-14 1.90647284e-02 2.34676426e-14\n",
      " 4.69959060e-14 2.16013075e-14 5.72488146e-14 8.88001194e-14\n",
      " 1.14805859e-13 2.45678431e-13 5.68347157e-14 7.80522010e-14\n",
      " 8.18912827e-03 6.00288233e-14 1.92331075e-13 7.47883026e-14\n",
      " 6.80567920e-03 1.22684461e-13 1.37976383e-13 7.25291068e-14\n",
      " 4.55858049e-14 3.79394687e-10 1.41232671e-13 8.23067326e-14\n",
      " 1.97951278e-11 1.30168646e-12 1.21643717e-13 7.29481503e-03\n",
      " 1.82973236e-02 2.38143291e-13 5.67303902e-03 5.86183846e-14\n",
      " 9.71169680e-14 1.38296271e-13 8.31148880e-03 1.80668085e-13\n",
      " 3.12065732e-13 1.64972433e-13 3.78855103e-14 2.47348969e-11\n",
      " 2.51584876e-13 3.65504193e-14 1.65751151e-03 1.23446715e-02\n",
      " 1.86865488e-13 5.25143669e-14 4.57676576e-08 3.63444770e-09\n",
      " 1.47001084e-13 9.55542003e-14 6.53123469e-04 1.33297714e-13\n",
      " 8.92459513e-03 8.45291955e-14 4.45924083e-14 2.73403044e-03\n",
      " 8.32074088e-03 7.79130301e-03 9.83522764e-14 6.29663170e-12\n",
      " 1.72629677e-02 1.56043381e-13 8.99859276e-14 1.84791117e-02\n",
      " 8.59411647e-03 1.64652066e-02 2.83107732e-13 6.76290042e-14\n",
      " 7.16655145e-14 2.01775856e-13 6.14647072e-14 1.48303590e-02\n",
      " 1.95979450e-13 8.10981472e-14 8.53869010e-14 1.71252284e-02\n",
      " 1.08118748e-13 1.65440448e-13 3.21190889e-13 2.35506483e-03\n",
      " 1.01501752e-13 8.43817477e-14 2.19241058e-13 1.21770397e-13\n",
      " 7.00481525e-14 7.90657856e-13 6.01964421e-14 1.92621709e-13\n",
      " 3.31639771e-14 3.36055467e-13 1.49690478e-02 7.26737564e-14\n",
      " 7.39831974e-03 2.53303191e-13 7.21679608e-03 8.95096017e-14\n",
      " 9.94464091e-14 1.64839326e-13 5.86548053e-14 1.30694229e-13\n",
      " 1.57996242e-02 5.05686247e-14 6.94513480e-03 8.51712137e-14\n",
      " 7.87800417e-14 1.44127265e-13 2.11456648e-13 1.19811976e-13\n",
      " 2.52370866e-13 2.40445528e-13 5.48273417e-14 2.24413956e-03\n",
      " 3.29618867e-13 8.65674618e-13 7.72789652e-14 3.32860621e-14\n",
      " 5.75942477e-14 1.06040495e-03 1.58018407e-02 6.55541297e-14\n",
      " 2.85468489e-13 4.09239458e-14 1.30588688e-13 6.20061074e-14\n",
      " 1.13153785e-02 1.28736135e-02 7.55056223e-14 3.84185466e-14\n",
      " 8.18725503e-14 1.78406558e-07 5.81428589e-14 6.33794129e-14\n",
      " 9.03921614e-14 1.67728335e-13 4.26971585e-03 1.20788134e-13\n",
      " 1.87109769e-10 3.98729723e-14 1.62181859e-02 4.23495271e-13\n",
      " 2.43862144e-14 1.90153791e-03 1.98731562e-13 1.46453736e-02\n",
      " 5.18932285e-14 3.12685811e-13 1.63499841e-14 4.43708866e-04\n",
      " 3.35301575e-14 1.49808222e-02 6.34548423e-14 1.34970905e-13\n",
      " 1.08209430e-02 2.92958320e-03 3.43555389e-03 3.75238017e-03\n",
      " 3.94925704e-14 1.96030902e-13 1.10795332e-13 1.26338132e-13\n",
      " 9.96354667e-14 7.02682099e-03 1.78482938e-13 7.11493665e-14\n",
      " 6.18752536e-14 1.86903163e-14 9.04123749e-03 1.27168637e-13\n",
      " 3.35739633e-14 6.41471044e-14 5.51565004e-14 7.42086959e-14\n",
      " 1.04178889e-02 1.10828521e-13 6.92493044e-14 2.19341112e-14\n",
      " 9.06691801e-04 8.81512723e-14 5.48784333e-03 1.22705399e-13\n",
      " 1.45858980e-13 8.23780296e-14 1.28974217e-13 9.10842460e-03\n",
      " 7.35592718e-13 8.61016834e-14 2.67368737e-13 3.17766967e-13\n",
      " 1.98895336e-13 1.42215717e-02 1.45661716e-13 7.20920719e-14\n",
      " 5.81525959e-13 4.86516149e-14 7.17984889e-14 1.31773443e-13\n",
      " 9.97618729e-14 2.54424785e-13 1.68329106e-14 5.02819664e-14\n",
      " 2.88286799e-13 1.26317634e-03 6.03601139e-03 5.60115339e-03\n",
      " 2.08655957e-11 1.74627062e-14 6.61187967e-14 7.37540921e-14\n",
      " 1.03818519e-08 8.15733800e-14 1.03529839e-13 3.72969640e-14\n",
      " 2.38325737e-14 3.42816369e-03 3.71869860e-03 1.12443460e-13\n",
      " 1.31554976e-02 5.31255343e-03 1.57185474e-13 2.32848150e-13\n",
      " 5.61626791e-14 7.45179593e-14 4.42575828e-03 1.00371226e-13\n",
      " 2.04473545e-13 1.11024427e-13 5.81336812e-14 1.35412169e-13\n",
      " 1.26905554e-13 6.45059839e-14 2.77580251e-14 3.54247168e-14\n",
      " 1.38354455e-02 1.87379139e-13 2.02509840e-13 1.12634347e-13\n",
      " 3.18686631e-14 2.36157908e-13 3.56663294e-14 5.12735263e-03\n",
      " 2.03893478e-03 4.68882611e-13 9.54273757e-14 8.06429642e-14\n",
      " 6.04574711e-03 9.01574115e-14 4.76176290e-13 4.63508267e-03\n",
      " 1.76923339e-13 9.79022189e-14 5.13162692e-14 1.19105808e-02\n",
      " 6.86569860e-03 1.01887896e-13 5.43584687e-14 1.26040662e-13\n",
      " 9.41675084e-03 1.32949918e-13 1.35241355e-13 1.52821869e-13\n",
      " 7.50717005e-14 3.61369411e-14 1.86905794e-13 5.26839096e-14\n",
      " 5.75231498e-03 1.86480805e-13 2.19735970e-13 8.24060115e-14\n",
      " 2.10705942e-14 5.65682868e-14 7.75844839e-03 5.66886885e-14\n",
      " 5.97786547e-03 7.78691347e-14 5.50600793e-14 4.32448553e-10\n",
      " 2.01304144e-13 4.04139784e-13 1.18994332e-14 9.33038438e-14\n",
      " 8.24759584e-14 3.10069558e-03 4.40338116e-14 8.46893387e-14\n",
      " 4.86377281e-03 5.08111670e-03 4.53845992e-14 6.29297969e-14\n",
      " 8.25137888e-14 7.72890723e-14 1.00877926e-13 2.31590376e-08\n",
      " 5.75077648e-14 1.27976940e-13 7.66519946e-14 1.17668233e-13\n",
      " 2.45917018e-03 2.48490893e-14 4.54876262e-03 2.66270733e-12\n",
      " 1.16056119e-13 1.99543024e-13 6.55127185e-03 4.99784443e-14\n",
      " 4.76089994e-13 5.04498727e-14 3.74270181e-14 1.69910585e-03\n",
      " 1.09766154e-13 6.24211828e-13 8.49917905e-14 6.51848490e-05\n",
      " 2.36538456e-10 1.69657830e-13 6.04297942e-14 8.06311478e-03\n",
      " 1.58816366e-10 2.59934087e-03 7.54182397e-14 7.28508398e-13\n",
      " 1.08614974e-02 5.54232564e-13 1.43978913e-13 4.54447763e-14\n",
      " 3.76689351e-14 3.16377011e-13 7.84887023e-14 1.39354197e-13\n",
      " 6.26954286e-03 6.04790920e-14 1.14545546e-13 2.09620148e-03\n",
      " 2.35022859e-14 2.23223445e-13 8.76408009e-14 1.54257462e-13\n",
      " 7.03165939e-13 2.47739660e-13 1.05189645e-13 1.36931211e-13\n",
      " 1.86795504e-06 3.96046842e-04 3.37768336e-03 5.57538065e-14\n",
      " 6.88494212e-14 3.18838249e-14 7.78825210e-14 5.97880922e-14\n",
      " 3.36878294e-03 7.22304432e-14 9.40556392e-03 7.72699222e-13\n",
      " 1.41808059e-13 2.56636029e-14 2.52246351e-14 1.01756654e-03\n",
      " 1.07500086e-02 5.47552632e-03 5.07373317e-10 1.33244809e-13\n",
      " 8.20016387e-13 3.22294014e-03 5.24342256e-10 6.84087525e-03\n",
      " 1.06200606e-13 2.75457331e-13 3.66112196e-14 4.02585277e-14\n",
      " 5.64015753e-14 1.40015736e-13 9.69837250e-14 1.99491967e-14\n",
      " 2.65527221e-13 5.58474823e-14 1.01318233e-02 6.70259141e-03\n",
      " 5.83532276e-14 1.32890821e-03 1.90974320e-13 1.58689933e-14]\n"
     ]
    }
   ],
   "source": [
    "# Examine a factor (here the one with largest probability, factor 1)\n",
    "print(theta[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model' 'ticket' 'bring' 'rider' 'stuff' 'love' 'possible' 'pull' 'star'\n",
      " 'saw' 'delete' 'folk' 'suck' 'stand' 'school' 'penalty' 'follow'\n",
      " 'information' 'exactly' 'learn']\n"
     ]
    }
   ],
   "source": [
    "# Words with largest absolute weights in the factor\n",
    "topweights_indices=numpy.argsort(-1*numpy.abs(theta[:,1]))\n",
    "print(remainingvocabulary[highesttotals[topweights_indices[0:20]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['michael' 'man' 'group' 'news' 'city' 'wave' 'phillies' 'scott' 'already'\n",
      " 'dead' 'york' 'internet' 'radio' 'station' 'philadelphia' 'tie' 'field'\n",
      " 'charles' 'cage' 'green']\n"
     ]
    }
   ],
   "source": [
    "# Same for the next biggest factor (here factor 4)\n",
    "topweights_indices=numpy.argsort(-1*numpy.abs(theta[:,4]))\n",
    "print(remainingvocabulary[highesttotals[topweights_indices[0:20]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Describe the resulting factors: list the 10 words with highest probability in each factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 words with highest probability in factor 1\n",
      "-------------------------------------------------------------\n",
      "['tin' 'stats' 'appreciate' 'version' '1.1' 'x-newsreader' 'email' 'test'\n",
      " 'honda' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 2\n",
      "-------------------------------------------------------------\n",
      "['honda' 'version' 'stats' 'email' 'appreciate' 'tin' 'x-newsreader'\n",
      " 'e-mail' 'test' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 3\n",
      "-------------------------------------------------------------\n",
      "['stats' 'tin' 'version' 'appreciate' 'x-newsreader' 'honda' 'email'\n",
      " 'e-mail' 'test' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 4\n",
      "-------------------------------------------------------------\n",
      "['email' 'appreciate' 'stats' 'test' 'version' 'x-newsreader' 'honda'\n",
      " '1.1' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 5\n",
      "-------------------------------------------------------------\n",
      "['tin' 'version' 'stats' 'x-newsreader' 'honda' 'email' 'e-mail'\n",
      " 'appreciate' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 6\n",
      "-------------------------------------------------------------\n",
      "['tin' 'version' 'stats' 'email' 'appreciate' 'x-newsreader' 'honda'\n",
      " 'test' '1.1' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 7\n",
      "-------------------------------------------------------------\n",
      "['tin' 'stats' 'version' 'email' 'x-newsreader' 'e-mail' 'honda'\n",
      " 'appreciate' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 8\n",
      "-------------------------------------------------------------\n",
      "['tin' 'email' 'e-mail' 'version' 'stats' '1.1' 'x-newsreader' 'honda'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 9\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'stats' 'tin' 'x-newsreader' 'e-mail' 'version' 'honda'\n",
      " '1.1' 'email' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 10\n",
      "-------------------------------------------------------------\n",
      "['tin' 'stats' 'version' 'email' 'x-newsreader' 'honda' 'e-mail'\n",
      " 'appreciate' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 11\n",
      "-------------------------------------------------------------\n",
      "['tin' 'test' 'stats' 'appreciate' 'version' 'e-mail' 'honda' 'email'\n",
      " '1.1' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 12\n",
      "-------------------------------------------------------------\n",
      "['stats' 'tin' 'version' '1.1' 'email' 'x-newsreader' 'e-mail' 'honda'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 13\n",
      "-------------------------------------------------------------\n",
      "['stats' 'test' 'tin' 'email' '1.1' 'e-mail' 'version' 'x-newsreader'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 14\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'stats' 'honda' 'version' 'email' 'tin' 'e-mail' '1.1'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 15\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'appreciate' 'version' 'stats' 'tin' 'email' 'test'\n",
      " 'e-mail' 'honda' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 16\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'version' 'honda' 'stats' 'email' '1.1' 'e-mail'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 17\n",
      "-------------------------------------------------------------\n",
      "['tin' 'test' 'appreciate' 'e-mail' 'stats' '1.1' 'x-newsreader' 'version'\n",
      " 'email' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 18\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' '1.1' 'stats' 'email' 'x-newsreader' 'e-mail'\n",
      " 'honda' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 19\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'email' '1.1' 'x-newsreader' 'stats' 'version' 'tin' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 20\n",
      "-------------------------------------------------------------\n",
      "['test' 'e-mail' '1.1' 'stats' 'x-newsreader' 'tin' 'honda' 'version'\n",
      " 'email' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 21\n",
      "-------------------------------------------------------------\n",
      "['test' 'stats' 'tin' 'honda' '1.1' 'x-newsreader' 'version' 'appreciate'\n",
      " 'e-mail' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 22\n",
      "-------------------------------------------------------------\n",
      "['honda' 'x-newsreader' 'stats' 'appreciate' 'version' 'test' '1.1'\n",
      " 'e-mail' 'tin' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 23\n",
      "-------------------------------------------------------------\n",
      "['tin' '1.1' 'stats' 'appreciate' 'version' 'email' 'test' 'e-mail'\n",
      " 'x-newsreader' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 24\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'tin' 'x-newsreader' 'version' 'honda' 'email' '1.1' 'stats'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 25\n",
      "-------------------------------------------------------------\n",
      "['tin' 'stats' 'x-newsreader' 'e-mail' 'email' 'version' 'test' '1.1'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 26\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'test' '1.1' 'version' 'honda' 'stats' 'email' 'e-mail'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 27\n",
      "-------------------------------------------------------------\n",
      "['honda' 'stats' 'email' 'version' 'appreciate' 'e-mail' 'test' 'tin'\n",
      " 'x-newsreader' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 28\n",
      "-------------------------------------------------------------\n",
      "['version' 'appreciate' 'stats' 'honda' 'test' 'x-newsreader' '1.1'\n",
      " 'e-mail' 'tin' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 29\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'appreciate' 'version' 'stats' 'x-newsreader' 'email' 'honda'\n",
      " 'test' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 30\n",
      "-------------------------------------------------------------\n",
      "['stats' 'email' 'x-newsreader' 'version' '1.1' 'tin' 'e-mail' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 31\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'test' 'honda' 'version' 'x-newsreader' '1.1' 'tin' 'stats'\n",
      " 'email' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 32\n",
      "-------------------------------------------------------------\n",
      "['honda' 'appreciate' 'version' 'x-newsreader' 'stats' 'email' '1.1'\n",
      " 'test' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 33\n",
      "-------------------------------------------------------------\n",
      "['version' 'stats' 'email' 'e-mail' 'x-newsreader' 'tin' 'honda' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 34\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'honda' 'version' 'email' 'stats' '1.1' 'x-newsreader' 'tin'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 35\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'tin' 'version' 'e-mail' 'email' 'honda' 'x-newsreader' 'stats'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 36\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'tin' 'email' 'test' 'stats' 'honda' 'x-newsreader' 'version'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 37\n",
      "-------------------------------------------------------------\n",
      "['honda' 'x-newsreader' 'version' 'stats' 'tin' 'test' '1.1' 'email'\n",
      " 'appreciate' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 38\n",
      "-------------------------------------------------------------\n",
      "['stats' 'e-mail' 'tin' 'version' 'x-newsreader' 'honda' 'appreciate'\n",
      " 'email' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 39\n",
      "-------------------------------------------------------------\n",
      "['email' '1.1' 'stats' 'version' 'x-newsreader' 'e-mail' 'honda' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 40\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'email' '1.1' 'test' 'stats' 'e-mail' 'version' 'honda'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 41\n",
      "-------------------------------------------------------------\n",
      "['version' 'x-newsreader' 'stats' 'email' 'e-mail' 'tin' 'honda' '1.1'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 42\n",
      "-------------------------------------------------------------\n",
      "['tin' 'test' 'honda' '1.1' 'e-mail' 'version' 'stats' 'x-newsreader'\n",
      " 'appreciate' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 43\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'version' 'x-newsreader' 'stats' 'appreciate' 'honda' 'email'\n",
      " '1.1' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 44\n",
      "-------------------------------------------------------------\n",
      "['honda' '1.1' 'stats' 'tin' 'e-mail' 'test' 'email' 'x-newsreader'\n",
      " 'version' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 45\n",
      "-------------------------------------------------------------\n",
      "['stats' 'e-mail' 'version' 'tin' '1.1' 'honda' 'appreciate' 'email'\n",
      " 'test' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 46\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'x-newsreader' 'email' 'tin' 'version' 'honda' '1.1'\n",
      " 'e-mail' 'stats' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 47\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'appreciate' 'stats' 'honda' 'version' 'email' 'x-newsreader'\n",
      " '1.1' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 48\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' 'stats' 'email' 'e-mail' '1.1' 'tin' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 49\n",
      "-------------------------------------------------------------\n",
      "['stats' 'e-mail' 'test' 'appreciate' '1.1' 'version' 'x-newsreader'\n",
      " 'email' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 50\n",
      "-------------------------------------------------------------\n",
      "['honda' 'tin' 'e-mail' 'x-newsreader' 'email' 'test' 'stats' 'version'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 51\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'e-mail' 'tin' 'email' 'version' 'stats' '1.1' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 52\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'e-mail' 'stats' 'tin' 'version' 'honda' 'email'\n",
      " 'appreciate' 'test' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 53\n",
      "-------------------------------------------------------------\n",
      "['version' 'stats' 'tin' 'x-newsreader' 'honda' 'e-mail' 'appreciate'\n",
      " 'email' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 54\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'stats' 'email' 'e-mail' 'version' 'x-newsreader'\n",
      " '1.1' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 55\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' 'test' 'email' 'stats' 'honda' 'e-mail'\n",
      " 'appreciate' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 56\n",
      "-------------------------------------------------------------\n",
      "['version' 'tin' 'stats' 'honda' '1.1' 'x-newsreader' 'test' 'e-mail'\n",
      " 'email' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 57\n",
      "-------------------------------------------------------------\n",
      "['tin' 'email' 'honda' 'appreciate' 'version' 'e-mail' 'stats' 'test'\n",
      " 'x-newsreader' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 58\n",
      "-------------------------------------------------------------\n",
      "['version' 'x-newsreader' 'test' 'honda' 'tin' 'email' 'stats'\n",
      " 'appreciate' '1.1' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 59\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'stats' '1.1' 'email' 'honda' 'test' 'tin' 'x-newsreader'\n",
      " 'version' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 60\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'e-mail' 'stats' 'version' 'x-newsreader' '1.1' 'test'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 61\n",
      "-------------------------------------------------------------\n",
      "['email' 'e-mail' '1.1' 'version' 'test' 'honda' 'stats' 'x-newsreader'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 62\n",
      "-------------------------------------------------------------\n",
      "['version' 'test' '1.1' 'email' 'e-mail' 'appreciate' 'stats' 'tin'\n",
      " 'honda' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 63\n",
      "-------------------------------------------------------------\n",
      "['test' 'email' 'appreciate' 'version' 'x-newsreader' 'tin' 'e-mail' '1.1'\n",
      " 'stats' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 64\n",
      "-------------------------------------------------------------\n",
      "['tin' 'version' 'e-mail' 'x-newsreader' 'stats' 'honda' 'email'\n",
      " 'appreciate' 'test' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 65\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' '1.1' 'honda' 'email' 'stats' 'e-mail' 'version' 'test'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 66\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'tin' 'stats' 'version' '1.1' 'email' 'x-newsreader'\n",
      " 'appreciate' 'test' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 67\n",
      "-------------------------------------------------------------\n",
      "['test' '1.1' 'honda' 'stats' 'appreciate' 'version' 'email' 'tin'\n",
      " 'x-newsreader' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 68\n",
      "-------------------------------------------------------------\n",
      "['test' 'x-newsreader' 'honda' 'appreciate' 'stats' 'version' '1.1'\n",
      " 'email' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 69\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'version' 'stats' 'tin' 'test' 'e-mail' 'honda' 'x-newsreader'\n",
      " 'appreciate' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 70\n",
      "-------------------------------------------------------------\n",
      "['test' 'email' '1.1' 'e-mail' 'honda' 'tin' 'x-newsreader' 'stats'\n",
      " 'version' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 71\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'email' 'x-newsreader' 'version' 'honda' 'stats' 'e-mail'\n",
      " '1.1' 'tin' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 72\n",
      "-------------------------------------------------------------\n",
      "['tin' 'e-mail' 'email' 'x-newsreader' 'stats' 'version' 'test' 'honda'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 73\n",
      "-------------------------------------------------------------\n",
      "['tin' 'x-newsreader' 'appreciate' '1.1' 'honda' 'version' 'test' 'email'\n",
      " 'stats' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 74\n",
      "-------------------------------------------------------------\n",
      "['tin' 'e-mail' 'stats' 'x-newsreader' 'version' 'email' 'honda' 'test'\n",
      " 'appreciate' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 75\n",
      "-------------------------------------------------------------\n",
      "['honda' 'appreciate' '1.1' 'email' 'stats' 'version' 'e-mail'\n",
      " 'x-newsreader' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 76\n",
      "-------------------------------------------------------------\n",
      "['test' 'email' 'e-mail' 'version' 'stats' 'tin' 'x-newsreader' '1.1'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 77\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'appreciate' 'stats' 'honda' 'version' 'test' 'tin' 'x-newsreader'\n",
      " 'e-mail' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 78\n",
      "-------------------------------------------------------------\n",
      "['tin' 'stats' 'version' 'x-newsreader' 'email' 'honda' 'e-mail' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 79\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'tin' 'email' 'version' '1.1' 'stats' 'honda'\n",
      " 'x-newsreader' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 80\n",
      "-------------------------------------------------------------\n",
      "['stats' 'tin' 'x-newsreader' 'version' 'honda' 'e-mail' 'test' 'email'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 81\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'version' 'honda' 'e-mail' 'x-newsreader' 'tin' 'test' 'stats'\n",
      " 'email' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 82\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'appreciate' 'stats' '1.1' 'honda' 'test' 'version' 'tin'\n",
      " 'x-newsreader' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 83\n",
      "-------------------------------------------------------------\n",
      "['test' 'version' 'honda' 'appreciate' 'e-mail' 'email' 'tin' '1.1'\n",
      " 'x-newsreader' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 84\n",
      "-------------------------------------------------------------\n",
      "['tin' 'stats' 'version' 'test' 'x-newsreader' '1.1' 'appreciate' 'honda'\n",
      " 'email' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 85\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'x-newsreader' 'test' 'version' 'honda' '1.1' 'e-mail'\n",
      " 'stats' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 86\n",
      "-------------------------------------------------------------\n",
      "['version' 'stats' 'email' 'test' 'x-newsreader' 'e-mail' 'honda' '1.1'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 87\n",
      "-------------------------------------------------------------\n",
      "['tin' 'e-mail' 'version' 'stats' 'x-newsreader' 'email' 'honda'\n",
      " 'appreciate' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 88\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'x-newsreader' 'email' 'stats' 'e-mail' 'version' 'tin' 'honda'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 89\n",
      "-------------------------------------------------------------\n",
      "['tin' 'appreciate' 'stats' 'honda' 'email' 'test' 'version'\n",
      " 'x-newsreader' 'e-mail' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 90\n",
      "-------------------------------------------------------------\n",
      "['honda' 'appreciate' 'test' '1.1' 'e-mail' 'email' 'version' 'stats'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 91\n",
      "-------------------------------------------------------------\n",
      "['stats' 'appreciate' '1.1' 'honda' 'tin' 'e-mail' 'test' 'version'\n",
      " 'x-newsreader' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 92\n",
      "-------------------------------------------------------------\n",
      "['version' 'e-mail' 'x-newsreader' 'tin' '1.1' 'stats' 'honda' 'email'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 93\n",
      "-------------------------------------------------------------\n",
      "['stats' '1.1' 'version' 'honda' 'email' 'tin' 'test' 'e-mail'\n",
      " 'x-newsreader' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 94\n",
      "-------------------------------------------------------------\n",
      "['honda' 'test' 'email' '1.1' 'x-newsreader' 'stats' 'version' 'e-mail'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 95\n",
      "-------------------------------------------------------------\n",
      "['email' '1.1' 'version' 'e-mail' 'stats' 'x-newsreader' 'honda' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 96\n",
      "-------------------------------------------------------------\n",
      "['honda' 'stats' 'appreciate' 'x-newsreader' 'version' 'e-mail' 'email'\n",
      " 'test' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 97\n",
      "-------------------------------------------------------------\n",
      "['version' '1.1' 'x-newsreader' 'e-mail' 'honda' 'stats' 'email'\n",
      " 'appreciate' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 98\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'email' '1.1' 'version' 'stats' 'x-newsreader' 'tin' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 99\n",
      "-------------------------------------------------------------\n",
      "['test' 'version' 'email' 'honda' 'e-mail' 'tin' 'appreciate' '1.1'\n",
      " 'stats' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 100\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'honda' 'test' 'stats' 'version' 'tin' 'email' 'e-mail'\n",
      " 'appreciate' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 101\n",
      "-------------------------------------------------------------\n",
      "['stats' 'x-newsreader' '1.1' 'version' 'tin' 'appreciate' 'email'\n",
      " 'e-mail' 'honda' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 102\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'tin' 'version' 'x-newsreader' 'stats' 'honda' 'email' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 103\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'stats' 'test' 'email' '1.1' 'honda' 'version'\n",
      " 'appreciate' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 104\n",
      "-------------------------------------------------------------\n",
      "['honda' 'appreciate' 'version' 'e-mail' 'stats' 'email' 'test'\n",
      " 'x-newsreader' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 105\n",
      "-------------------------------------------------------------\n",
      "['version' '1.1' 'e-mail' 'email' 'honda' 'x-newsreader' 'stats' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 106\n",
      "-------------------------------------------------------------\n",
      "['honda' 'e-mail' 'appreciate' 'tin' 'stats' '1.1' 'test' 'version'\n",
      " 'x-newsreader' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 107\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'honda' 'version' 'test' 'e-mail' 'email' 'tin' 'stats'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 108\n",
      "-------------------------------------------------------------\n",
      "['honda' 'appreciate' 'email' 'version' 'stats' 'e-mail' '1.1' 'test'\n",
      " 'tin' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 109\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'version' 'tin' 'email' '1.1' 'stats' 'x-newsreader' 'test'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 110\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'x-newsreader' 'e-mail' 'stats' 'version' 'honda' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 111\n",
      "-------------------------------------------------------------\n",
      "['test' 'e-mail' 'x-newsreader' '1.1' 'stats' 'email' 'version' 'honda'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 112\n",
      "-------------------------------------------------------------\n",
      "['stats' 'e-mail' 'tin' '1.1' 'x-newsreader' 'test' 'version' 'email'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 113\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'stats' 'e-mail' 'version' 'email' 'tin' '1.1' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 114\n",
      "-------------------------------------------------------------\n",
      "['tin' 'appreciate' 'x-newsreader' 'e-mail' 'honda' 'test' '1.1' 'stats'\n",
      " 'version' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 115\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'e-mail' 'x-newsreader' 'honda' 'version' 'test' 'tin' 'appreciate'\n",
      " 'email' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 116\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'tin' 'stats' 'version' 'honda' 'e-mail' 'x-newsreader'\n",
      " 'email' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 117\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'test' 'honda' 'version' 'stats' 'x-newsreader' 'e-mail'\n",
      " 'email' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 118\n",
      "-------------------------------------------------------------\n",
      "['honda' 'e-mail' 'email' 'x-newsreader' 'stats' 'version' 'test'\n",
      " 'appreciate' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 119\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'appreciate' '1.1' 'e-mail' 'test' 'email' 'honda' 'stats'\n",
      " 'version' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 120\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' 'honda' 'appreciate' '1.1' 'e-mail' 'stats'\n",
      " 'test' 'tin' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 121\n",
      "-------------------------------------------------------------\n",
      "['stats' 'email' 'e-mail' 'x-newsreader' 'version' '1.1' 'appreciate'\n",
      " 'tin' 'honda' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 122\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'stats' 'version' 'honda' 'x-newsreader' 'e-mail' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 123\n",
      "-------------------------------------------------------------\n",
      "['test' 'honda' 'appreciate' '1.1' 'stats' 'x-newsreader' 'version' 'tin'\n",
      " 'email' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 124\n",
      "-------------------------------------------------------------\n",
      "['email' 'version' 'stats' 'e-mail' '1.1' 'honda' 'x-newsreader'\n",
      " 'appreciate' 'tin' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 125\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'tin' 'version' 'appreciate' 'stats' 'x-newsreader' 'honda'\n",
      " 'email' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 126\n",
      "-------------------------------------------------------------\n",
      "['email' 'version' 'honda' 'stats' 'x-newsreader' 'tin' 'e-mail' 'test'\n",
      " 'appreciate' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 127\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'stats' 'version' 'x-newsreader' 'e-mail' 'honda' 'test'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 128\n",
      "-------------------------------------------------------------\n",
      "['stats' '1.1' 'email' 'x-newsreader' 'appreciate' 'e-mail' 'version'\n",
      " 'tin' 'honda' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 129\n",
      "-------------------------------------------------------------\n",
      "['e-mail' '1.1' 'appreciate' 'email' 'stats' 'x-newsreader' 'version'\n",
      " 'tin' 'test' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 130\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'x-newsreader' 'stats' 'test' 'email' 'appreciate' 'version' 'tin'\n",
      " 'e-mail' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 131\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'e-mail' 'stats' 'x-newsreader' 'version' 'honda' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 132\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' 'test' 'honda' 'stats' 'x-newsreader' 'tin'\n",
      " 'email' 'e-mail' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 133\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'x-newsreader' 'tin' 'email' '1.1' 'stats' 'honda'\n",
      " 'version' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 134\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'email' 'version' 'x-newsreader' 'stats' 'tin' 'honda' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 135\n",
      "-------------------------------------------------------------\n",
      "['honda' 'stats' '1.1' 'email' 'x-newsreader' 'version' 'test'\n",
      " 'appreciate' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 136\n",
      "-------------------------------------------------------------\n",
      "['email' 'honda' 'appreciate' 'stats' 'test' 'version' 'e-mail'\n",
      " 'x-newsreader' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 137\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'test' 'email' 'honda' 'tin' 'version' 'stats' 'appreciate'\n",
      " 'x-newsreader' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 138\n",
      "-------------------------------------------------------------\n",
      "['honda' '1.1' 'appreciate' 'email' 'version' 'stats' 'e-mail' 'test'\n",
      " 'tin' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 139\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' '1.1' 'tin' 'appreciate' 'email' 'version' 'stats'\n",
      " 'e-mail' 'honda' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 140\n",
      "-------------------------------------------------------------\n",
      "['stats' 'x-newsreader' 'email' 'version' 'e-mail' 'tin' 'test'\n",
      " 'appreciate' 'honda' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 141\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'honda' 'version' 'tin' 'stats' 'x-newsreader' '1.1' 'email'\n",
      " 'e-mail' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 142\n",
      "-------------------------------------------------------------\n",
      "['e-mail' '1.1' 'x-newsreader' 'version' 'test' 'appreciate' 'email' 'tin'\n",
      " 'honda' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 143\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'stats' 'test' 'honda' 'version' '1.1' 'tin' 'email'\n",
      " 'x-newsreader' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 144\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'version' 'e-mail' 'stats' 'honda' 'appreciate' 'tin' 'email'\n",
      " 'test' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 145\n",
      "-------------------------------------------------------------\n",
      "['version' 'e-mail' '1.1' 'appreciate' 'email' 'x-newsreader' 'test' 'tin'\n",
      " 'stats' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 146\n",
      "-------------------------------------------------------------\n",
      "['honda' 'x-newsreader' 'appreciate' 'test' 'stats' 'version' 'tin'\n",
      " 'e-mail' '1.1' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 147\n",
      "-------------------------------------------------------------\n",
      "['honda' 'email' 'e-mail' '1.1' 'version' 'test' 'stats' 'x-newsreader'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 148\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'test' 'appreciate' 'version' 'stats' 'honda' 'x-newsreader'\n",
      " 'e-mail' 'tin' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 149\n",
      "-------------------------------------------------------------\n",
      "['test' 'email' 'x-newsreader' 'version' 'honda' 'tin' 'e-mail' 'stats'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 150\n",
      "-------------------------------------------------------------\n",
      "['email' 'appreciate' 'version' 'stats' '1.1' 'e-mail' 'honda'\n",
      " 'x-newsreader' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 151\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'test' 'email' '1.1' 'appreciate' 'version' 'x-newsreader'\n",
      " 'stats' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 152\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' 'stats' 'email' 'e-mail' 'tin' 'honda' '1.1'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 153\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'e-mail' 'stats' 'x-newsreader' 'test' 'honda' 'version'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 154\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'e-mail' 'email' 'honda' 'x-newsreader' 'version' 'stats' 'test'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 155\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'test' 'version' 'honda' '1.1' 'email' 'e-mail'\n",
      " 'appreciate' 'stats' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 156\n",
      "-------------------------------------------------------------\n",
      "['version' '1.1' 'x-newsreader' 'appreciate' 'test' 'stats' 'email'\n",
      " 'honda' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 157\n",
      "-------------------------------------------------------------\n",
      "['stats' 'test' '1.1' 'email' 'version' 'e-mail' 'x-newsreader' 'honda'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 158\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'honda' 'e-mail' 'version' 'x-newsreader' 'test'\n",
      " 'appreciate' 'stats' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 159\n",
      "-------------------------------------------------------------\n",
      "['tin' 'e-mail' 'version' 'x-newsreader' 'stats' 'honda' 'email' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 160\n",
      "-------------------------------------------------------------\n",
      "['email' 'stats' 'e-mail' 'appreciate' '1.1' 'x-newsreader' 'test' 'honda'\n",
      " 'version' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 161\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' 'email' 'appreciate' 'e-mail' '1.1' 'tin'\n",
      " 'honda' 'test' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 162\n",
      "-------------------------------------------------------------\n",
      "['tin' 'appreciate' 'stats' 'honda' 'version' 'x-newsreader' 'email'\n",
      " 'e-mail' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 163\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'stats' 'test' 'tin' 'appreciate' 'version' 'honda' 'x-newsreader'\n",
      " 'e-mail' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 164\n",
      "-------------------------------------------------------------\n",
      "['test' 'e-mail' '1.1' 'stats' 'version' 'appreciate' 'email' 'honda'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 165\n",
      "-------------------------------------------------------------\n",
      "['version' 'honda' 'test' 'email' 'x-newsreader' 'appreciate' 'stats'\n",
      " '1.1' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 166\n",
      "-------------------------------------------------------------\n",
      "['tin' 'e-mail' 'x-newsreader' 'version' 'stats' 'honda' 'email' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 167\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'email' 'honda' '1.1' 'appreciate' 'version' 'test' 'tin'\n",
      " 'stats' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 168\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'stats' 'test' 'honda' 'version' 'e-mail' '1.1' 'tin'\n",
      " 'x-newsreader' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 169\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'honda' 'e-mail' 'x-newsreader' 'version' 'test' 'stats'\n",
      " 'email' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 170\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'stats' 'x-newsreader' 'honda' '1.1' 'email' 'test' 'appreciate'\n",
      " 'version' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 171\n",
      "-------------------------------------------------------------\n",
      "['version' '1.1' 'test' 'tin' 'x-newsreader' 'email' 'honda' 'appreciate'\n",
      " 'stats' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 172\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'e-mail' 'version' 'appreciate' 'stats' 'email' 'honda' 'test'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 173\n",
      "-------------------------------------------------------------\n",
      "['test' 'e-mail' '1.1' 'version' 'honda' 'x-newsreader' 'email' 'stats'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 174\n",
      "-------------------------------------------------------------\n",
      "['honda' '1.1' 'x-newsreader' 'version' 'stats' 'email' 'e-mail' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 175\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'honda' 'email' 'stats' 'version' 'tin' 'x-newsreader' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 176\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'honda' 'x-newsreader' 'test' 'appreciate' 'version' 'email'\n",
      " 'tin' '1.1' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 177\n",
      "-------------------------------------------------------------\n",
      "['test' '1.1' 'appreciate' 'email' 'x-newsreader' 'stats' 'e-mail'\n",
      " 'version' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 178\n",
      "-------------------------------------------------------------\n",
      "['email' 'test' 'version' 'e-mail' 'x-newsreader' 'honda' 'appreciate'\n",
      " '1.1' 'tin' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 179\n",
      "-------------------------------------------------------------\n",
      "['honda' 'version' 'e-mail' 'x-newsreader' 'email' 'stats' 'tin' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 180\n",
      "-------------------------------------------------------------\n",
      "['honda' 'e-mail' 'appreciate' 'x-newsreader' '1.1' 'email' 'test'\n",
      " 'version' 'stats' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 181\n",
      "-------------------------------------------------------------\n",
      "['test' 'stats' 'version' '1.1' 'x-newsreader' 'honda' 'appreciate' 'tin'\n",
      " 'email' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 182\n",
      "-------------------------------------------------------------\n",
      "['stats' 'tin' 'e-mail' 'appreciate' 'test' 'honda' 'x-newsreader' '1.1'\n",
      " 'version' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 183\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'stats' '1.1' 'email' 'version' 'appreciate' 'tin'\n",
      " 'e-mail' 'honda' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 184\n",
      "-------------------------------------------------------------\n",
      "['test' 'x-newsreader' 'version' 'e-mail' 'honda' 'appreciate' 'email'\n",
      " 'tin' 'stats' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 185\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'test' 'email' 'appreciate' 'stats' 'x-newsreader' 'honda' 'e-mail'\n",
      " 'version' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 186\n",
      "-------------------------------------------------------------\n",
      "['test' 'tin' 'version' 'e-mail' 'email' '1.1' 'stats' 'x-newsreader'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 187\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'tin' 'test' 'x-newsreader' 'version' 'appreciate' 'e-mail'\n",
      " 'honda' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 188\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'tin' 'email' 'version' 'honda' 'e-mail' 'x-newsreader'\n",
      " 'stats' 'test' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 189\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' '1.1' 'stats' 'e-mail' 'email' 'tin' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 190\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'appreciate' 'x-newsreader' 'stats' 'version' 'test' 'honda' 'tin'\n",
      " 'e-mail' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 191\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'email' 'honda' 'stats' 'e-mail' 'version' 'x-newsreader'\n",
      " 'test' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 192\n",
      "-------------------------------------------------------------\n",
      "['test' 'stats' 'appreciate' 'version' 'x-newsreader' 'honda' 'e-mail'\n",
      " '1.1' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 193\n",
      "-------------------------------------------------------------\n",
      "['honda' 'appreciate' 'tin' 'email' 'stats' 'x-newsreader' 'test'\n",
      " 'version' 'e-mail' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 194\n",
      "-------------------------------------------------------------\n",
      "['stats' '1.1' 'e-mail' 'version' 'email' 'tin' 'x-newsreader' 'test'\n",
      " 'appreciate' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 195\n",
      "-------------------------------------------------------------\n",
      "['email' 'e-mail' 'stats' 'appreciate' 'x-newsreader' '1.1' 'version'\n",
      " 'test' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 196\n",
      "-------------------------------------------------------------\n",
      "['test' 'honda' 'e-mail' '1.1' 'version' 'x-newsreader' 'email'\n",
      " 'appreciate' 'stats' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 197\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'email' 'e-mail' 'stats' 'version' 'honda' '1.1'\n",
      " 'x-newsreader' 'tin' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 198\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'appreciate' '1.1' 'stats' 'email' 'honda' 'version'\n",
      " 'test' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 199\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'version' 'honda' 'e-mail' 'stats' 'appreciate' 'x-newsreader'\n",
      " 'test' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 200\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' '1.1' 'test' 'e-mail' 'tin' 'honda' 'stats'\n",
      " 'x-newsreader' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 201\n",
      "-------------------------------------------------------------\n",
      "['stats' 'honda' 'email' 'version' 'x-newsreader' 'test' 'appreciate'\n",
      " '1.1' 'tin' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 202\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'email' 'stats' '1.1' 'e-mail' 'appreciate' 'version'\n",
      " 'test' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 203\n",
      "-------------------------------------------------------------\n",
      "['email' '1.1' 'appreciate' 'honda' 'x-newsreader' 'e-mail' 'stats'\n",
      " 'version' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 204\n",
      "-------------------------------------------------------------\n",
      "['stats' 'honda' 'x-newsreader' '1.1' 'version' 'test' 'email' 'e-mail'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 205\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'tin' 'e-mail' 'stats' 'version' 'email' 'test' 'honda'\n",
      " 'appreciate' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 206\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'e-mail' '1.1' 'email' 'tin' 'x-newsreader' 'test' 'version'\n",
      " 'honda' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 207\n",
      "-------------------------------------------------------------\n",
      "['email' 'x-newsreader' 'stats' 'test' 'e-mail' '1.1' 'version' 'honda'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 208\n",
      "-------------------------------------------------------------\n",
      "['version' 'x-newsreader' 'email' 'stats' 'tin' 'e-mail' 'test' '1.1'\n",
      " 'appreciate' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 209\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'stats' 'x-newsreader' 'version' 'e-mail' 'honda' 'tin'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 210\n",
      "-------------------------------------------------------------\n",
      "['stats' '1.1' 'appreciate' 'honda' 'version' 'test' 'tin' 'x-newsreader'\n",
      " 'email' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 211\n",
      "-------------------------------------------------------------\n",
      "['test' 'stats' 'version' 'honda' 'e-mail' 'x-newsreader' 'email' 'tin'\n",
      " 'appreciate' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 212\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'e-mail' '1.1' 'version' 'stats' 'honda' 'tin'\n",
      " 'x-newsreader' 'email' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 213\n",
      "-------------------------------------------------------------\n",
      "['test' 'stats' 'appreciate' '1.1' 'email' 'version' 'x-newsreader'\n",
      " 'honda' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 214\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'x-newsreader' 'stats' '1.1' 'version' 'email' 'honda' 'test'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 215\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' '1.1' 'honda' 'stats' 'e-mail' 'email' 'version'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 216\n",
      "-------------------------------------------------------------\n",
      "['email' '1.1' 'test' 'honda' 'x-newsreader' 'e-mail' 'version' 'stats'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 217\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'appreciate' 'e-mail' 'stats' 'email' 'test' 'version'\n",
      " 'x-newsreader' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 218\n",
      "-------------------------------------------------------------\n",
      "['version' 'stats' 'email' 'e-mail' '1.1' 'x-newsreader' 'honda' 'test'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 219\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'honda' 'version' 'x-newsreader' 'stats' 'e-mail' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 220\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'stats' 'test' 'tin' 'honda' 'e-mail' 'version' 'email'\n",
      " 'appreciate' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 221\n",
      "-------------------------------------------------------------\n",
      "['test' 'e-mail' 'x-newsreader' 'stats' 'tin' 'version' 'email' 'honda'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 222\n",
      "-------------------------------------------------------------\n",
      "['email' 'honda' 'version' 'e-mail' 'appreciate' 'x-newsreader' 'stats'\n",
      " 'test' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 223\n",
      "-------------------------------------------------------------\n",
      "['test' 'version' 'x-newsreader' 'e-mail' 'tin' 'appreciate' '1.1' 'email'\n",
      " 'stats' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 224\n",
      "-------------------------------------------------------------\n",
      "['email' 'version' 'stats' 'appreciate' 'test' 'e-mail' '1.1' 'honda'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 225\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'honda' 'stats' 'version' 'test' 'appreciate' 'e-mail'\n",
      " 'email' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 226\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' 'email' 'stats' 'honda' '1.1' 'e-mail' 'test'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 227\n",
      "-------------------------------------------------------------\n",
      "['version' 'appreciate' 'honda' 'test' 'e-mail' '1.1' 'x-newsreader'\n",
      " 'stats' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 228\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'version' 'tin' 'e-mail' 'stats' 'x-newsreader' 'honda'\n",
      " 'appreciate' 'email' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 229\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'stats' 'honda' '1.1' 'email' 'test' 'e-mail' 'x-newsreader'\n",
      " 'version' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 230\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'appreciate' 'x-newsreader' 'email' 'test' 'version' 'e-mail'\n",
      " 'honda' 'stats' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 231\n",
      "-------------------------------------------------------------\n",
      "['version' 'honda' 'appreciate' 'stats' 'e-mail' 'x-newsreader' 'test'\n",
      " '1.1' 'tin' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 232\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'honda' 'test' 'email' 'version' 'e-mail' 'stats' 'tin'\n",
      " '1.1' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 233\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'e-mail' 'email' 'test' 'stats' 'version' 'x-newsreader' 'tin'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 234\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' '1.1' 'honda' 'stats' 'e-mail' 'test' 'version'\n",
      " 'appreciate' 'tin' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 235\n",
      "-------------------------------------------------------------\n",
      "['stats' 'email' 'x-newsreader' 'version' '1.1' 'e-mail' 'tin' 'test'\n",
      " 'appreciate' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 236\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'tin' 'version' 'x-newsreader' 'stats' 'email' 'honda' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 237\n",
      "-------------------------------------------------------------\n",
      "['email' 'honda' 'version' 'e-mail' 'x-newsreader' 'stats' 'tin' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 238\n",
      "-------------------------------------------------------------\n",
      "['version' '1.1' 'appreciate' 'test' 'x-newsreader' 'stats' 'email'\n",
      " 'honda' 'tin' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 239\n",
      "-------------------------------------------------------------\n",
      "['test' 'stats' 'version' 'x-newsreader' 'appreciate' 'honda' '1.1' 'tin'\n",
      " 'email' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 240\n",
      "-------------------------------------------------------------\n",
      "['version' 'appreciate' 'honda' 'email' 'test' 'e-mail' 'stats' 'tin'\n",
      " 'x-newsreader' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 241\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'honda' '1.1' 'appreciate' 'tin' 'stats' 'version' 'test'\n",
      " 'e-mail' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 242\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' 'tin' 'honda' 'stats' 'e-mail' 'email' 'test'\n",
      " 'appreciate' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 243\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'test' 'x-newsreader' 'tin' 'version' 'email' 'e-mail'\n",
      " 'honda' 'stats' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 244\n",
      "-------------------------------------------------------------\n",
      "['version' 'appreciate' 'stats' 'honda' 'e-mail' 'tin' '1.1' 'test'\n",
      " 'x-newsreader' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 245\n",
      "-------------------------------------------------------------\n",
      "['test' 'email' 'stats' 'e-mail' '1.1' 'honda' 'version' 'tin'\n",
      " 'x-newsreader' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 246\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'honda' 'stats' '1.1' 'x-newsreader' 'e-mail'\n",
      " 'version' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 247\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'x-newsreader' 'stats' 'e-mail' 'version' 'honda' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 248\n",
      "-------------------------------------------------------------\n",
      "['honda' 'email' 'x-newsreader' 'stats' 'e-mail' 'version' 'tin' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 249\n",
      "-------------------------------------------------------------\n",
      "['honda' 'e-mail' '1.1' 'stats' 'x-newsreader' 'email' 'version' 'tin'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 250\n",
      "-------------------------------------------------------------\n",
      "['email' 'stats' 'version' 'x-newsreader' 'test' '1.1' 'appreciate'\n",
      " 'honda' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 251\n",
      "-------------------------------------------------------------\n",
      "['email' '1.1' 'stats' 'x-newsreader' 'version' 'tin' 'e-mail' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 252\n",
      "-------------------------------------------------------------\n",
      "['version' 'e-mail' 'tin' 'x-newsreader' 'email' 'stats' 'test' 'honda'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 253\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'x-newsreader' 'tin' 'honda' 'version' 'email' 'stats' 'appreciate'\n",
      " 'e-mail' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 254\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'x-newsreader' 'e-mail' 'version' 'test' 'stats' 'honda'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 255\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'x-newsreader' 'test' 'tin' 'stats' 'version' 'honda' 'appreciate'\n",
      " 'email' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 256\n",
      "-------------------------------------------------------------\n",
      "['e-mail' '1.1' 'appreciate' 'tin' 'version' 'email' 'honda'\n",
      " 'x-newsreader' 'stats' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 257\n",
      "-------------------------------------------------------------\n",
      "['email' 'appreciate' 'e-mail' '1.1' 'test' 'version' 'stats' 'honda'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 258\n",
      "-------------------------------------------------------------\n",
      "['stats' 'email' 'x-newsreader' 'e-mail' 'version' 'tin' 'honda' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 259\n",
      "-------------------------------------------------------------\n",
      "['test' 'version' 'e-mail' 'x-newsreader' 'stats' '1.1' 'appreciate'\n",
      " 'honda' 'tin' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 260\n",
      "-------------------------------------------------------------\n",
      "['appreciate' '1.1' 'email' 'test' 'version' 'x-newsreader' 'e-mail'\n",
      " 'honda' 'stats' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 261\n",
      "-------------------------------------------------------------\n",
      "['version' 'stats' 'honda' 'x-newsreader' '1.1' 'email' 'test'\n",
      " 'appreciate' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 262\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'email' 'test' '1.1' 'tin' 'honda' 'e-mail' 'version'\n",
      " 'stats' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 263\n",
      "-------------------------------------------------------------\n",
      "['email' '1.1' 'e-mail' 'x-newsreader' 'appreciate' 'test' 'stats'\n",
      " 'version' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 264\n",
      "-------------------------------------------------------------\n",
      "['test' 'version' 'appreciate' 'stats' 'honda' 'e-mail' 'email'\n",
      " 'x-newsreader' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 265\n",
      "-------------------------------------------------------------\n",
      "['version' 'email' 'stats' '1.1' 'honda' 'e-mail' 'tin' 'x-newsreader'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 266\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'appreciate' 'e-mail' 'test' 'honda' 'version' 'stats'\n",
      " 'email' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 267\n",
      "-------------------------------------------------------------\n",
      "['tin' 'version' 'stats' 'x-newsreader' 'email' 'honda' 'e-mail'\n",
      " 'appreciate' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 268\n",
      "-------------------------------------------------------------\n",
      "['version' '1.1' 'email' 'test' 'appreciate' 'stats' 'honda'\n",
      " 'x-newsreader' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 269\n",
      "-------------------------------------------------------------\n",
      "['tin' 'version' 'e-mail' 'email' 'x-newsreader' 'stats' 'honda' '1.1'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 270\n",
      "-------------------------------------------------------------\n",
      "['test' 'email' '1.1' 'e-mail' 'x-newsreader' 'version' 'appreciate'\n",
      " 'stats' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 271\n",
      "-------------------------------------------------------------\n",
      "['stats' '1.1' 'version' 'honda' 'email' 'e-mail' 'x-newsreader'\n",
      " 'appreciate' 'tin' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 272\n",
      "-------------------------------------------------------------\n",
      "['version' 'appreciate' '1.1' 'email' 'e-mail' 'tin' 'honda' 'test'\n",
      " 'x-newsreader' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 273\n",
      "-------------------------------------------------------------\n",
      "['test' 'tin' 'stats' 'honda' 'appreciate' 'x-newsreader' 'email'\n",
      " 'version' 'e-mail' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 274\n",
      "-------------------------------------------------------------\n",
      "['email' 'test' 'appreciate' '1.1' 'x-newsreader' 'version' 'e-mail'\n",
      " 'stats' 'tin' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 275\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'test' 'e-mail' '1.1' 'honda' 'stats' 'tin' 'x-newsreader'\n",
      " 'email' 'version']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 276\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'test' 'honda' 'appreciate' 'email' 'x-newsreader' 'e-mail' 'stats'\n",
      " 'version' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 277\n",
      "-------------------------------------------------------------\n",
      "['tin' 'e-mail' 'x-newsreader' 'stats' 'version' 'email' 'test' 'honda'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 278\n",
      "-------------------------------------------------------------\n",
      "['stats' 'x-newsreader' '1.1' 'test' 'appreciate' 'e-mail' 'version'\n",
      " 'email' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 279\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' '1.1' 'e-mail' 'email' 'tin' 'stats' 'honda'\n",
      " 'x-newsreader' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 280\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'email' 'stats' '1.1' 'version' 'e-mail' 'honda' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 281\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'honda' 'stats' 'email' 'version' 'e-mail' 'tin' '1.1'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 282\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'stats' 'honda' '1.1' 'tin' 'x-newsreader' 'email'\n",
      " 'e-mail' 'version']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 283\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'honda' 'appreciate' 'test' 'version' 'x-newsreader' 'stats'\n",
      " 'email' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 284\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'e-mail' 'version' '1.1' 'test' 'honda' 'stats'\n",
      " 'x-newsreader' 'tin' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 285\n",
      "-------------------------------------------------------------\n",
      "['honda' '1.1' 'stats' 'version' 'email' 'x-newsreader' 'test'\n",
      " 'appreciate' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 286\n",
      "-------------------------------------------------------------\n",
      "['tin' 'version' 'x-newsreader' 'e-mail' 'stats' 'honda' 'email'\n",
      " 'appreciate' 'test' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 287\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'honda' 'tin' 'stats' 'version' '1.1' 'x-newsreader'\n",
      " 'email' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 288\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'appreciate' 'email' 'honda' 'version' 'x-newsreader' 'test'\n",
      " 'stats' 'tin' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 289\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'tin' 'stats' 'version' 'x-newsreader' 'honda' 'e-mail'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 290\n",
      "-------------------------------------------------------------\n",
      "['stats' 'x-newsreader' 'version' 'honda' 'tin' 'email' 'test' '1.1'\n",
      " 'e-mail' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 291\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'appreciate' 'e-mail' 'stats' 'version' 'x-newsreader'\n",
      " 'tin' 'honda' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 292\n",
      "-------------------------------------------------------------\n",
      "['stats' '1.1' 'email' 'version' 'honda' 'x-newsreader' 'e-mail' 'test'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 293\n",
      "-------------------------------------------------------------\n",
      "['test' '1.1' 'email' 'honda' 'e-mail' 'stats' 'appreciate' 'tin'\n",
      " 'x-newsreader' 'version']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 294\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'honda' 'email' 'stats' 'version' 'appreciate' 'x-newsreader'\n",
      " 'tin' 'test' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 295\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'honda' 'appreciate' 'version' 'e-mail' 'stats' '1.1'\n",
      " 'test' 'tin' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 296\n",
      "-------------------------------------------------------------\n",
      "['email' 'x-newsreader' 'version' 'stats' '1.1' 'honda' 'e-mail' 'tin'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 297\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'appreciate' 'email' 'tin' 'version' 'test' 'honda' 'stats'\n",
      " 'x-newsreader' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 298\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'x-newsreader' '1.1' 'tin' 'stats' 'version' 'email' 'honda'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 299\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'stats' 'e-mail' 'x-newsreader' 'honda' 'version'\n",
      " 'tin' '1.1' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 300\n",
      "-------------------------------------------------------------\n",
      "['stats' '1.1' 'e-mail' 'email' 'version' 'x-newsreader' 'tin' 'test'\n",
      " 'appreciate' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 301\n",
      "-------------------------------------------------------------\n",
      "['stats' '1.1' 'test' 'x-newsreader' 'honda' 'e-mail' 'appreciate'\n",
      " 'version' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 302\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'honda' 'appreciate' 'e-mail' 'email' 'version' 'stats'\n",
      " 'x-newsreader' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 303\n",
      "-------------------------------------------------------------\n",
      "['tin' '1.1' 'email' 'stats' 'e-mail' 'version' 'x-newsreader' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 304\n",
      "-------------------------------------------------------------\n",
      "['test' 'e-mail' 'email' 'x-newsreader' 'appreciate' 'stats' 'version'\n",
      " '1.1' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 305\n",
      "-------------------------------------------------------------\n",
      "['email' 'honda' 'e-mail' 'stats' '1.1' 'appreciate' 'tin' 'test'\n",
      " 'version' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 306\n",
      "-------------------------------------------------------------\n",
      "['honda' 'stats' 'tin' 'e-mail' 'x-newsreader' '1.1' 'version' 'email'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 307\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'honda' '1.1' 'email' 'test' 'stats' 'appreciate'\n",
      " 'version' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 308\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'version' '1.1' 'x-newsreader' 'email' 'honda' 'appreciate'\n",
      " 'test' 'stats' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 309\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'tin' 'honda' 'test' 'appreciate' 'stats' 'x-newsreader' 'email'\n",
      " 'version' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 310\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'x-newsreader' 'version' 'e-mail' 'email' 'stats'\n",
      " '1.1' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 311\n",
      "-------------------------------------------------------------\n",
      "['tin' 'version' 'appreciate' '1.1' 'honda' 'e-mail' 'stats' 'email'\n",
      " 'x-newsreader' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 312\n",
      "-------------------------------------------------------------\n",
      "['email' 'e-mail' 'stats' 'tin' 'x-newsreader' 'version' '1.1' 'test'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 313\n",
      "-------------------------------------------------------------\n",
      "['version' 'appreciate' '1.1' 'test' 'stats' 'e-mail' 'x-newsreader'\n",
      " 'honda' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 314\n",
      "-------------------------------------------------------------\n",
      "['honda' 'version' 'appreciate' 'x-newsreader' 'email' 'test' 'tin'\n",
      " 'stats' '1.1' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 315\n",
      "-------------------------------------------------------------\n",
      "['stats' 'tin' 'appreciate' 'version' 'honda' 'x-newsreader' '1.1' 'test'\n",
      " 'email' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 316\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' 'test' 'x-newsreader' '1.1' 'email' 'tin' 'honda'\n",
      " 'stats' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 317\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'honda' 'version' 'tin' 'stats' 'appreciate' 'e-mail'\n",
      " 'email' 'test' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 318\n",
      "-------------------------------------------------------------\n",
      "['stats' 'version' 'x-newsreader' 'test' 'honda' 'tin' 'appreciate'\n",
      " 'email' 'e-mail' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 319\n",
      "-------------------------------------------------------------\n",
      "['version' 'stats' 'email' 'x-newsreader' 'e-mail' 'honda' 'tin' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 320\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'honda' 'appreciate' 'stats' 'email' 'version' '1.1'\n",
      " 'x-newsreader' 'tin' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 321\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'stats' 'email' '1.1' 'test' 'version' 'x-newsreader'\n",
      " 'appreciate' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 322\n",
      "-------------------------------------------------------------\n",
      "['stats' 'honda' 'appreciate' 'test' '1.1' 'e-mail' 'email' 'version'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 323\n",
      "-------------------------------------------------------------\n",
      "['test' 'email' 'version' 'stats' 'e-mail' 'x-newsreader' 'tin' 'honda'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 324\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'test' '1.1' 'email' 'stats' 'x-newsreader' 'tin' 'version'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 325\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' '1.1' 'e-mail' 'appreciate' 'honda' 'test' 'tin' 'version'\n",
      " 'email' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 326\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'stats' 'version' 'email' 'e-mail' 'x-newsreader' 'honda' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 327\n",
      "-------------------------------------------------------------\n",
      "['email' 'stats' '1.1' 'x-newsreader' 'honda' 'e-mail' 'tin' 'version'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 328\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' 'appreciate' 'stats' 'honda' 'test' 'email'\n",
      " '1.1' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 329\n",
      "-------------------------------------------------------------\n",
      "['e-mail' '1.1' 'tin' 'stats' 'test' 'email' 'x-newsreader' 'version'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 330\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'tin' 'x-newsreader' 'email' 'version' 'honda' '1.1' 'stats'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 331\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'honda' 'version' 'test' 'stats' 'appreciate' 'e-mail'\n",
      " 'email' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 332\n",
      "-------------------------------------------------------------\n",
      "['email' 'stats' 'version' '1.1' 'x-newsreader' 'honda' 'e-mail' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 333\n",
      "-------------------------------------------------------------\n",
      "['honda' 'x-newsreader' 'version' 'stats' '1.1' 'email' 'appreciate'\n",
      " 'e-mail' 'tin' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 334\n",
      "-------------------------------------------------------------\n",
      "['stats' 'email' 'test' 'appreciate' 'tin' '1.1' 'x-newsreader' 'version'\n",
      " 'e-mail' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 335\n",
      "-------------------------------------------------------------\n",
      "['version' 'test' '1.1' 'honda' 'tin' 'e-mail' 'stats' 'email'\n",
      " 'x-newsreader' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 336\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'x-newsreader' 'honda' 'stats' 'test' 'email' 'e-mail'\n",
      " 'version' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 337\n",
      "-------------------------------------------------------------\n",
      "['test' 'version' 'email' 'honda' 'e-mail' 'appreciate' 'stats' '1.1'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 338\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'test' 'appreciate' 'e-mail' 'honda' 'email' '1.1' 'stats'\n",
      " 'tin' 'version']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 339\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'email' 'tin' 'test' 'stats' '1.1' 'version' 'e-mail'\n",
      " 'x-newsreader' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 340\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'e-mail' 'honda' 'version' 'test' '1.1' 'x-newsreader'\n",
      " 'stats' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 341\n",
      "-------------------------------------------------------------\n",
      "['tin' 'e-mail' 'stats' 'x-newsreader' 'email' 'version' 'honda'\n",
      " 'appreciate' 'test' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 342\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'stats' 'x-newsreader' 'e-mail' 'honda' 'version' 'tin' 'email'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 343\n",
      "-------------------------------------------------------------\n",
      "['test' 'email' 'stats' 'x-newsreader' '1.1' 'honda' 'appreciate' 'e-mail'\n",
      " 'version' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 344\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'appreciate' 'honda' 'email' 'stats' 'test' 'version' 'tin'\n",
      " 'e-mail' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 345\n",
      "-------------------------------------------------------------\n",
      "['email' 'e-mail' 'stats' 'honda' 'version' '1.1' 'x-newsreader' 'test'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 346\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'x-newsreader' 'e-mail' 'version' 'email' 'tin' 'stats'\n",
      " 'appreciate' 'test' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 347\n",
      "-------------------------------------------------------------\n",
      "['tin' 'email' 'x-newsreader' 'stats' 'version' 'e-mail' 'honda' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 348\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'honda' 'version' 'test' 'email' '1.1' 'x-newsreader'\n",
      " 'stats' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 349\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'email' '1.1' 'version' 'stats' 'x-newsreader' 'honda' 'test'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 350\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'version' '1.1' 'stats' 'x-newsreader' 'honda' 'appreciate'\n",
      " 'email' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 351\n",
      "-------------------------------------------------------------\n",
      "['email' 'version' '1.1' 'stats' 'x-newsreader' 'e-mail' 'honda' 'tin'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 352\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'x-newsreader' 'stats' 'version' 'test' 'honda' 'email'\n",
      " 'e-mail' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 353\n",
      "-------------------------------------------------------------\n",
      "['test' '1.1' 'x-newsreader' 'e-mail' 'appreciate' 'stats' 'honda'\n",
      " 'version' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 354\n",
      "-------------------------------------------------------------\n",
      "['honda' 'x-newsreader' 'test' 'e-mail' 'email' 'version' 'stats' 'tin'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 355\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' '1.1' 'e-mail' 'version' 'email' 'tin' 'stats' 'test'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 356\n",
      "-------------------------------------------------------------\n",
      "['honda' '1.1' 'version' 'e-mail' 'stats' 'email' 'appreciate'\n",
      " 'x-newsreader' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 357\n",
      "-------------------------------------------------------------\n",
      "['version' 'tin' 'x-newsreader' 'stats' 'honda' 'e-mail' 'email' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 358\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' '1.1' 'appreciate' 'tin' 'e-mail' 'version' 'email'\n",
      " 'honda' 'stats' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 359\n",
      "-------------------------------------------------------------\n",
      "['honda' 'x-newsreader' 'tin' 'stats' 'email' 'version' 'e-mail' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 360\n",
      "-------------------------------------------------------------\n",
      "['test' 'honda' 'appreciate' '1.1' 'e-mail' 'x-newsreader' 'stats' 'email'\n",
      " 'tin' 'version']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 361\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'x-newsreader' 'email' 'test' 'stats' 'honda' 'e-mail' 'version'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 362\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'stats' 'test' 'version' '1.1' 'tin' 'email' 'e-mail'\n",
      " 'x-newsreader' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 363\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'test' 'honda' 'tin' '1.1' 'stats' 'version' 'email'\n",
      " 'x-newsreader' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 364\n",
      "-------------------------------------------------------------\n",
      "['honda' 'email' 'x-newsreader' 'e-mail' 'version' 'stats' 'test' 'tin'\n",
      " 'appreciate' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 365\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'honda' 'stats' 'version' 'x-newsreader' 'e-mail'\n",
      " '1.1' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 366\n",
      "-------------------------------------------------------------\n",
      "['honda' '1.1' 'x-newsreader' 'stats' 'version' 'e-mail' 'test' 'email'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 367\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'email' 'x-newsreader' 'test' '1.1' 'version' 'stats'\n",
      " 'appreciate' 'tin' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 368\n",
      "-------------------------------------------------------------\n",
      "['stats' 'test' '1.1' 'honda' 'appreciate' 'email' 'version' 'e-mail'\n",
      " 'tin' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 369\n",
      "-------------------------------------------------------------\n",
      "['honda' 'version' 'e-mail' 'email' 'appreciate' 'x-newsreader' 'tin'\n",
      " '1.1' 'stats' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 370\n",
      "-------------------------------------------------------------\n",
      "['stats' 'e-mail' 'version' 'x-newsreader' 'appreciate' 'test' 'email'\n",
      " 'honda' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 371\n",
      "-------------------------------------------------------------\n",
      "['email' '1.1' 'version' 'e-mail' 'stats' 'test' 'x-newsreader' 'honda'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 372\n",
      "-------------------------------------------------------------\n",
      "['test' 'version' 'honda' 'x-newsreader' 'stats' 'email' '1.1' 'tin'\n",
      " 'e-mail' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 373\n",
      "-------------------------------------------------------------\n",
      "['test' '1.1' 'x-newsreader' 'appreciate' 'stats' 'honda' 'e-mail' 'tin'\n",
      " 'version' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 374\n",
      "-------------------------------------------------------------\n",
      "['tin' 'stats' '1.1' 'x-newsreader' 'e-mail' 'version' 'test' 'honda'\n",
      " 'email' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 375\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'x-newsreader' '1.1' 'email' 'version' 'stats' 'tin' 'honda'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 376\n",
      "-------------------------------------------------------------\n",
      "['honda' 'x-newsreader' 'version' 'tin' 'e-mail' 'stats' 'test' 'email'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 377\n",
      "-------------------------------------------------------------\n",
      "['test' '1.1' 'honda' 'appreciate' 'version' 'x-newsreader' 'stats'\n",
      " 'e-mail' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 378\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'stats' 'appreciate' 'version' 'x-newsreader' 'e-mail'\n",
      " 'test' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 379\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' 'honda' 'tin' 'stats' 'test' 'email' '1.1'\n",
      " 'e-mail' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 380\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'appreciate' '1.1' 'honda' 'x-newsreader' 'e-mail' 'stats'\n",
      " 'test' 'version']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 381\n",
      "-------------------------------------------------------------\n",
      "['email' 'appreciate' 'honda' 'version' 'test' 'e-mail' 'stats' '1.1'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 382\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'stats' '1.1' 'version' 'email' 'e-mail' 'honda' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 383\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'appreciate' 'honda' '1.1' 'x-newsreader' 'email' 'tin' 'test'\n",
      " 'version' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 384\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'tin' 'x-newsreader' '1.1' 'email' 'version' 'stats' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 385\n",
      "-------------------------------------------------------------\n",
      "['test' 'e-mail' 'x-newsreader' 'honda' '1.1' 'tin' 'version' 'appreciate'\n",
      " 'email' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 386\n",
      "-------------------------------------------------------------\n",
      "['honda' '1.1' 'email' 'appreciate' 'test' 'stats' 'version'\n",
      " 'x-newsreader' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 387\n",
      "-------------------------------------------------------------\n",
      "['honda' 'version' '1.1' 'test' 'appreciate' 'stats' 'x-newsreader'\n",
      " 'email' 'tin' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 388\n",
      "-------------------------------------------------------------\n",
      "['version' 'x-newsreader' 'stats' '1.1' 'email' 'honda' 'test' 'e-mail'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 389\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'stats' 'version' 'x-newsreader' 'honda' 'email' 'e-mail'\n",
      " 'tin' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 390\n",
      "-------------------------------------------------------------\n",
      "['email' 'appreciate' 'stats' 'version' 'tin' 'e-mail' 'honda' '1.1'\n",
      " 'x-newsreader' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 391\n",
      "-------------------------------------------------------------\n",
      "['test' 'x-newsreader' 'e-mail' 'version' 'tin' 'email' 'stats' '1.1'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 392\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'tin' 'honda' 'email' 'stats' 'e-mail' 'version' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 393\n",
      "-------------------------------------------------------------\n",
      "['honda' 'test' 'x-newsreader' 'stats' 'e-mail' 'tin' 'version'\n",
      " 'appreciate' '1.1' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 394\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'tin' 'e-mail' 'version' 'stats' 'email' 'test' 'honda'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 395\n",
      "-------------------------------------------------------------\n",
      "['version' 'email' 'x-newsreader' 'stats' 'tin' '1.1' 'e-mail'\n",
      " 'appreciate' 'honda' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 396\n",
      "-------------------------------------------------------------\n",
      "['e-mail' '1.1' 'test' 'x-newsreader' 'honda' 'stats' 'version' 'email'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 397\n",
      "-------------------------------------------------------------\n",
      "['version' 'honda' 'test' 'appreciate' 'x-newsreader' '1.1' 'email'\n",
      " 'stats' 'tin' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 398\n",
      "-------------------------------------------------------------\n",
      "['email' 'appreciate' 'e-mail' 'tin' '1.1' 'version' 'x-newsreader' 'test'\n",
      " 'stats' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 399\n",
      "-------------------------------------------------------------\n",
      "['email' 'stats' 'version' 'e-mail' 'x-newsreader' 'honda' 'tin'\n",
      " 'appreciate' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 400\n",
      "-------------------------------------------------------------\n",
      "['honda' 'test' 'email' 'stats' 'x-newsreader' 'appreciate' 'tin' '1.1'\n",
      " 'e-mail' 'version']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 401\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'e-mail' 'version' 'stats' '1.1' 'test' 'honda'\n",
      " 'x-newsreader' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 402\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'test' 'x-newsreader' 'honda' 'stats' 'appreciate' 'email' 'tin'\n",
      " 'version' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 403\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'x-newsreader' 'stats' 'email' 'version' 'tin' 'honda' '1.1'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 404\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'test' '1.1' 'honda' 'email' 'version' 'stats'\n",
      " 'x-newsreader' 'tin' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 405\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'test' 'tin' 'x-newsreader' 'stats' 'email' 'version'\n",
      " 'appreciate' 'honda' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 406\n",
      "-------------------------------------------------------------\n",
      "['test' 'tin' 'version' 'x-newsreader' 'email' 'stats' 'e-mail' 'honda'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 407\n",
      "-------------------------------------------------------------\n",
      "['email' 'appreciate' 'stats' 'version' 'x-newsreader' 'honda' 'e-mail'\n",
      " '1.1' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 408\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'email' 'tin' 'x-newsreader' 'stats' 'version' 'honda' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 409\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'appreciate' 'stats' 'e-mail' 'test' 'version'\n",
      " 'x-newsreader' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 410\n",
      "-------------------------------------------------------------\n",
      "['honda' 'appreciate' 'test' 'version' '1.1' 'e-mail' 'stats' 'email'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 411\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'x-newsreader' 'test' 'version' 'e-mail' 'stats'\n",
      " 'appreciate' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 412\n",
      "-------------------------------------------------------------\n",
      "['version' '1.1' 'test' 'email' 'stats' 'honda' 'x-newsreader'\n",
      " 'appreciate' 'tin' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 413\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'version' '1.1' 'honda' 'stats' 'e-mail' 'x-newsreader'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 414\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' 'test' '1.1' 'email' 'honda' 'stats'\n",
      " 'x-newsreader' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 415\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' 'stats' 'honda' 'x-newsreader' 'tin' 'email'\n",
      " 'test' 'e-mail' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 416\n",
      "-------------------------------------------------------------\n",
      "['version' 'email' 'stats' 'tin' 'e-mail' 'x-newsreader' '1.1' 'test'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 417\n",
      "-------------------------------------------------------------\n",
      "['stats' 'appreciate' 'x-newsreader' 'test' 'email' 'honda' 'e-mail' '1.1'\n",
      " 'version' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 418\n",
      "-------------------------------------------------------------\n",
      "['honda' 'version' 'email' 'stats' 'appreciate' 'x-newsreader' 'tin'\n",
      " 'e-mail' '1.1' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 419\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'test' 'email' 'tin' 'honda' 'e-mail' 'stats' 'version'\n",
      " 'x-newsreader' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 420\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'version' 'appreciate' 'stats' 'test' 'honda' 'x-newsreader'\n",
      " 'email' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 421\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'e-mail' 'tin' 'x-newsreader' 'stats' '1.1' 'honda' 'email'\n",
      " 'version' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 422\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'e-mail' 'appreciate' 'honda' 'test' 'stats' '1.1'\n",
      " 'version' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 423\n",
      "-------------------------------------------------------------\n",
      "['test' 'email' 'honda' 'version' 'x-newsreader' 'e-mail' 'stats'\n",
      " 'appreciate' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 424\n",
      "-------------------------------------------------------------\n",
      "['email' 'appreciate' 'x-newsreader' 'version' 'honda' 'e-mail' 'stats'\n",
      " 'test' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 425\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' 'appreciate' 'honda' 'test' 'email' '1.1'\n",
      " 'e-mail' 'tin' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 426\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'stats' 'version' 'x-newsreader' 'appreciate' 'email' 'honda'\n",
      " '1.1' 'tin' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 427\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'email' 'stats' 'e-mail' 'version' 'x-newsreader' 'honda' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 428\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' '1.1' 'test' 'email' 'e-mail' 'stats' 'version' 'tin'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 429\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' '1.1' 'tin' 'honda' 'e-mail' 'version' 'stats' 'test'\n",
      " 'email' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 430\n",
      "-------------------------------------------------------------\n",
      "['stats' 'x-newsreader' 'tin' 'test' 'version' 'e-mail' 'email' '1.1'\n",
      " 'honda' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 431\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'email' '1.1' 'e-mail' 'version' 'stats' 'x-newsreader'\n",
      " 'tin' 'honda' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 432\n",
      "-------------------------------------------------------------\n",
      "['version' 'e-mail' '1.1' 'email' 'test' 'honda' 'x-newsreader' 'stats'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 433\n",
      "-------------------------------------------------------------\n",
      "['version' 'e-mail' '1.1' 'test' 'email' 'honda' 'x-newsreader'\n",
      " 'appreciate' 'stats' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 434\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'honda' 'appreciate' '1.1' 'x-newsreader' 'email' 'stats'\n",
      " 'version' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 435\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'e-mail' 'email' 'tin' '1.1' 'version' 'stats'\n",
      " 'appreciate' 'honda' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 436\n",
      "-------------------------------------------------------------\n",
      "['test' '1.1' 'stats' 'email' 'appreciate' 'honda' 'x-newsreader'\n",
      " 'version' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 437\n",
      "-------------------------------------------------------------\n",
      "['stats' 'honda' 'version' 'test' 'appreciate' '1.1' 'e-mail' 'email'\n",
      " 'x-newsreader' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 438\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'tin' 'x-newsreader' 'test' '1.1' 'e-mail' 'email' 'stats'\n",
      " 'honda' 'version']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 439\n",
      "-------------------------------------------------------------\n",
      "['version' 'e-mail' 'honda' 'stats' 'test' 'x-newsreader' 'email'\n",
      " 'appreciate' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 440\n",
      "-------------------------------------------------------------\n",
      "['stats' 'honda' 'e-mail' '1.1' 'tin' 'appreciate' 'test' 'version'\n",
      " 'email' 'x-newsreader']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 441\n",
      "-------------------------------------------------------------\n",
      "['test' 'appreciate' 'honda' 'stats' 'x-newsreader' 'version' 'tin'\n",
      " 'email' '1.1' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 442\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'version' 'stats' 'x-newsreader' 'email' 'appreciate' 'test' 'tin'\n",
      " 'e-mail' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 443\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' 'e-mail' 'appreciate' 'honda' 'stats' '1.1'\n",
      " 'test' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 444\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'honda' 'version' 'stats' 'email' 'e-mail' '1.1'\n",
      " 'x-newsreader' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 445\n",
      "-------------------------------------------------------------\n",
      "['honda' 'email' 'stats' '1.1' 'e-mail' 'version' 'x-newsreader' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 446\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'version' '1.1' 'appreciate' 'email' 'stats' 'test'\n",
      " 'honda' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 447\n",
      "-------------------------------------------------------------\n",
      "['stats' 'appreciate' 'e-mail' 'honda' 'version' 'tin' 'test' 'email'\n",
      " 'x-newsreader' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 448\n",
      "-------------------------------------------------------------\n",
      "['version' 'x-newsreader' 'honda' 'test' 'stats' 'email' '1.1'\n",
      " 'appreciate' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 449\n",
      "-------------------------------------------------------------\n",
      "['test' 'x-newsreader' '1.1' 'appreciate' 'version' 'stats' 'honda'\n",
      " 'e-mail' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 450\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'tin' 'version' 'email' 'stats' 'e-mail' 'x-newsreader' 'honda'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 451\n",
      "-------------------------------------------------------------\n",
      "['honda' 'stats' 'e-mail' 'email' 'test' 'version' 'x-newsreader' 'tin'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 452\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'stats' 'test' '1.1' 'e-mail' 'x-newsreader' 'version'\n",
      " 'honda' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 453\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' 'tin' 'x-newsreader' 'stats' 'honda' 'email' '1.1'\n",
      " 'e-mail' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 454\n",
      "-------------------------------------------------------------\n",
      "['version' 'email' 'test' '1.1' 'x-newsreader' 'stats' 'honda' 'tin'\n",
      " 'e-mail' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 455\n",
      "-------------------------------------------------------------\n",
      "['email' '1.1' 'appreciate' 'tin' 'e-mail' 'x-newsreader' 'stats'\n",
      " 'version' 'honda' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 456\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'honda' 'test' 'stats' 'e-mail' 'email' 'x-newsreader'\n",
      " 'version' '1.1' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 457\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' '1.1' 'honda' 'stats' 'test' 'tin' 'appreciate' 'email'\n",
      " 'version' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 458\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'version' 'appreciate' 'honda' 'e-mail' 'x-newsreader' 'test'\n",
      " 'stats' 'tin' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 459\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'email' 'e-mail' '1.1' 'appreciate' 'version' 'stats'\n",
      " 'honda' 'tin' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 460\n",
      "-------------------------------------------------------------\n",
      "['version' '1.1' 'stats' 'x-newsreader' 'e-mail' 'test' 'appreciate'\n",
      " 'honda' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 461\n",
      "-------------------------------------------------------------\n",
      "['email' 'tin' 'version' 'test' 'stats' 'appreciate' 'e-mail' '1.1'\n",
      " 'x-newsreader' 'honda']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 462\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'version' 'tin' '1.1' 'x-newsreader' 'test' 'email' 'honda'\n",
      " 'appreciate' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 463\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'test' 'x-newsreader' 'appreciate' 'e-mail' 'honda' 'version'\n",
      " 'stats' 'email' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 464\n",
      "-------------------------------------------------------------\n",
      "['tin' 'version' 'email' 'e-mail' 'x-newsreader' 'stats' 'honda' '1.1'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 465\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'stats' 'e-mail' 'version' 'email' 'x-newsreader' 'test' 'honda'\n",
      " 'tin' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 466\n",
      "-------------------------------------------------------------\n",
      "['email' 'version' 'stats' 'x-newsreader' '1.1' 'e-mail' 'honda' 'tin'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 467\n",
      "-------------------------------------------------------------\n",
      "['stats' 'x-newsreader' 'email' 'honda' 'e-mail' '1.1' 'test' 'version'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 468\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' 'stats' 'x-newsreader' 'honda' 'test' 'email'\n",
      " 'tin' 'e-mail' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 469\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'test' 'stats' 'x-newsreader' 'honda' 'version' 'email'\n",
      " 'appreciate' 'tin' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 470\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'version' 'e-mail' 'tin' 'test' 'x-newsreader' 'stats' 'honda'\n",
      " 'appreciate' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 471\n",
      "-------------------------------------------------------------\n",
      "['test' 'honda' 'version' 'stats' '1.1' 'x-newsreader' 'email' 'e-mail'\n",
      " 'appreciate' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 472\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' '1.1' 'email' 'honda' 'version' 'appreciate' 'test' 'tin'\n",
      " 'e-mail' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 473\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'test' 'version' 'email' 'x-newsreader' 'e-mail' 'honda' 'tin'\n",
      " 'stats' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 474\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'appreciate' 'stats' 'version' 'x-newsreader' 'honda' 'email' 'tin'\n",
      " 'e-mail' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 475\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'stats' 'e-mail' 'email' 'x-newsreader' 'version' 'honda' 'tin'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 476\n",
      "-------------------------------------------------------------\n",
      "['e-mail' '1.1' 'test' 'x-newsreader' 'version' 'stats' 'email'\n",
      " 'appreciate' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 477\n",
      "-------------------------------------------------------------\n",
      "['test' 'version' 'honda' 'email' 'e-mail' 'tin' 'stats' 'x-newsreader'\n",
      " 'appreciate' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 478\n",
      "-------------------------------------------------------------\n",
      "['tin' 'test' 'version' 'x-newsreader' 'email' 'honda' 'e-mail' 'stats'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 479\n",
      "-------------------------------------------------------------\n",
      "['honda' 'test' '1.1' 'x-newsreader' 'stats' 'email' 'appreciate' 'e-mail'\n",
      " 'version' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 480\n",
      "-------------------------------------------------------------\n",
      "['stats' 'version' 'x-newsreader' 'email' '1.1' 'honda' 'e-mail'\n",
      " 'appreciate' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 481\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'tin' '1.1' 'honda' 'email' 'x-newsreader' 'test' 'appreciate'\n",
      " 'version' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 482\n",
      "-------------------------------------------------------------\n",
      "['email' '1.1' 'test' 'appreciate' 'x-newsreader' 'honda' 'e-mail' 'stats'\n",
      " 'version' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 483\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'x-newsreader' 'e-mail' 'appreciate' 'honda' 'test' 'email' 'tin'\n",
      " 'version' 'stats']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 484\n",
      "-------------------------------------------------------------\n",
      "['test' 'x-newsreader' 'honda' 'version' 'appreciate' 'stats' 'email'\n",
      " 'tin' '1.1' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 485\n",
      "-------------------------------------------------------------\n",
      "['version' 'test' 'stats' 'appreciate' 'e-mail' 'x-newsreader' '1.1'\n",
      " 'email' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 486\n",
      "-------------------------------------------------------------\n",
      "['honda' 'email' 'version' 'appreciate' 'x-newsreader' 'stats' '1.1'\n",
      " 'test' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 487\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' 'stats' 'e-mail' '1.1' 'email' 'x-newsreader'\n",
      " 'honda' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 488\n",
      "-------------------------------------------------------------\n",
      "['appreciate' 'version' 'stats' 'x-newsreader' '1.1' 'honda' 'email'\n",
      " 'e-mail' 'test' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 489\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'tin' 'version' 'email' 'x-newsreader' 'stats' 'honda' 'test'\n",
      " '1.1' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 490\n",
      "-------------------------------------------------------------\n",
      "['honda' 'test' 'version' 'appreciate' 'x-newsreader' 'email' 'stats'\n",
      " 'e-mail' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 491\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'version' 'stats' 'e-mail' 'appreciate' 'x-newsreader' 'test'\n",
      " 'email' 'honda' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 492\n",
      "-------------------------------------------------------------\n",
      "['1.1' 'stats' 'x-newsreader' 'version' 'honda' 'email' 'tin' 'e-mail'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 493\n",
      "-------------------------------------------------------------\n",
      "['x-newsreader' 'appreciate' 'e-mail' 'tin' '1.1' 'stats' 'test' 'honda'\n",
      " 'version' 'email']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 494\n",
      "-------------------------------------------------------------\n",
      "['e-mail' 'email' 'x-newsreader' 'stats' 'version' 'tin' '1.1' 'honda'\n",
      " 'test' 'appreciate']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 495\n",
      "-------------------------------------------------------------\n",
      "['test' 'x-newsreader' 'version' 'stats' 'tin' 'honda' 'email'\n",
      " 'appreciate' 'e-mail' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 496\n",
      "-------------------------------------------------------------\n",
      "['test' 'version' 'appreciate' 'stats' 'email' 'honda' 'x-newsreader'\n",
      " 'e-mail' 'tin' '1.1']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 497\n",
      "-------------------------------------------------------------\n",
      "['appreciate' '1.1' 'x-newsreader' 'version' 'honda' 'stats' 'e-mail'\n",
      " 'email' 'tin' 'test']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 498\n",
      "-------------------------------------------------------------\n",
      "['version' 'appreciate' 'email' 'test' '1.1' 'honda' 'tin' 'stats'\n",
      " 'x-newsreader' 'e-mail']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 499\n",
      "-------------------------------------------------------------\n",
      "['honda' '1.1' 'stats' 'test' 'x-newsreader' 'version' 'email'\n",
      " 'appreciate' 'e-mail' 'tin']\n",
      "\n",
      "\n",
      "10 words with highest probability in factor 500\n",
      "-------------------------------------------------------------\n",
      "['version' 'stats' 'x-newsreader' '1.1' 'honda' 'email' 'tin' 'e-mail'\n",
      " 'appreciate' 'test']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (c) Describe the resulting factors: list the 10 words with highest probability in each factor. \n",
    "for i in range(theta.shape[0]):\n",
    "    print('10 words with highest probability in factor ' + str(i+1))\n",
    "    print('-------------------------------------------------------------')\n",
    "    topweights_indices=numpy.argsort(-1*theta[i,:])\n",
    "    print(remainingvocabulary[highesttotals[topweights_indices[0:10]]])\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting factors are related to the topic of each directory, as the same as exercise 6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Find, for each factor, the document (message) with highest probability of that factor, and print its 100 first words.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document index with highest factor probability: 2937\n",
      "First 100 words of factor 1 of the document with highest probability\n",
      "['buchberger' 'bunt' 'cuyler' 'amazing' 'colonial' 'checker' 'concession'\n",
      " 'bum' 'challenging' 'colored' 'closed-minded' 'camping'\n",
      " 'cms.cc.wayne.edu' \"'57\" 'compulsive' 'bythe' 'compromise' 'beast'\n",
      " 'competitive' 'chess.ncsu.edu' 'anonymous' '16,005' 'c4zcii.ftn'\n",
      " 'cluster' 'breakaway' 'chassis' 'anthony' 'cannucks' 'concern' 'barberie'\n",
      " 'antenna' 'crusade' '185900001' 'basement' 'att.com' 'contractual'\n",
      " 'canadiens' 'ching' 'cam' 'chi-5' '.533' '05-04' '1110' 'competitor'\n",
      " 'ala' 'claude' 'boever' 'collegiate' 'creighton' '12:40' 'alternator'\n",
      " 'conceivable' 'boyle' 'clockwise' 'cmk' 'bogey' '1988' 'csc.albany.edu'\n",
      " 'dagibbs' 'cmuvm.csv.cmich.edu' 'd6s' '15th' 'd.sweeney' 'cgkarras'\n",
      " 'burke' 'business' '19:59' '04-03' 'cream' 'copy' '7:30' 'con' '1138'\n",
      " 'bald' '===' '094' 'appoint' '987' '0.571' 'casey' 'charm' '1.8' 'aug'\n",
      " 'cyt' 'complaint' 'closeup' 'cpsc.ucalgary.ca' 'commute' 'am2x+'\n",
      " 'collie/golden' 'ame' 'alright' 'cvax.psi.ch' 'center' 'comfortable'\n",
      " 'athena.mit.edu' 'adjustable' '.653' '0.421' 'card']\n",
      "\n",
      "\n",
      "Document index with highest factor probability: 449\n",
      "First 100 words of factor 2 of the document with highest probability\n",
      "['0.701' '5-4' '721-7297' 'beenback' 'beep' 'beer' 'beetle' 'beginner'\n",
      " 'beg' 'begin' 'ab-' 'bdi' '04-04' '84.0' 'clipper' 'basemen' 'accuse'\n",
      " '222hp' \"'84-'87\" 'autoweek' '850' '68.6' 'a.k.a' '3rd' 'bowling'\n",
      " 'cunews' '5-0' '_______/' '247' '66758' '3.26' '292' '6.8' '-spike-'\n",
      " 'basingstoke' '67-68' 'acid' '484' 'controversy' '218' 'albelin' '60.1'\n",
      " '7.7' '\\\\_______' '6-5' '524245' '10.1' \"'69\" 'br1' '0.42' 'catcher'\n",
      " '147' '3-6' '.417' 'afterward' '0.887' 'accelerator' '171' '0.44' '4.0l'\n",
      " '80,000' '5.333333333333333' 'cox' '1008' '900ss' '664' 'absolute' '153'\n",
      " '0.02' 'beginning' '106' '741a' '.714' '1981' 'b.c' '3.44' 'anatomy'\n",
      " '4-5' '348/700' 'approve' '6-0' '5:05' '239' 'bearing' '510' '30,000'\n",
      " 'ave.' '3.84' '0.448' '1.21' '-b-i-k-e' 'cafe' '5.28' '28.8' '13:14'\n",
      " '0.303' '7566' '125' '0.316' '1.2']\n",
      "\n",
      "\n",
      "Document index with highest factor probability: 1204\n",
      "First 100 words of factor 3 of the document with highest probability\n",
      "['31.6' 'addiction' '1992/93' '-14' 'condemn' '+44' '.253' '10510'\n",
      " 'antique' '2:10' '\\\\_____' '-ppv' 'berthiaume' '20k' '328' 'blueline'\n",
      " 'attack' 'berth' '0.889' 'adsorbent' '16v' '00072' '6.0' 'conversation'\n",
      " '1qkkodinn5f5' '1071' '2.90' '14~15k' '13.9' '7:00' '.277' '127' '0.38'\n",
      " '0.667' '4/26' '0.348' '60mph' '.812' '11150' '.759' 'adsorption' '400s'\n",
      " '1ur-m' '3.66' \"-guns'n'roses\" '1984-85' '.....' '4-door' '181' '0.61'\n",
      " 'advertisement' '37.6' '317' '0863' \"'89cbr600\" '=========' 'blaise'\n",
      " '1r1d62' '.280' '250' '0.261' '18.6' '16,000' '0330' '0.39' '224'\n",
      " '___________________' '0.7' '1919' '4.2' 'accelerate' '0969' '275-2527'\n",
      " '3-7' '4.9' '-black' '2500' '3.20' '12.10' '414' '1.4' '4.62' '.285'\n",
      " '1250' '583905' '851' '1.3' '0.412' '2min' '1.6' '1985-86' 'blauser'\n",
      " '.354' '103' '2-0' '8000' '1995' '0.360' '2.9' '229']\n",
      "\n",
      "\n",
      "Document index with highest factor probability: 1771\n",
      "First 100 words of factor 4 of the document with highest probability\n",
      "['\\\\stersund' 'camry' 'chapin-carpenter' 'canucks' 'buster' '22.0' \"'89\"\n",
      " '0.32' 'c+d' 'cabletron' '211' '44.0' 'countersteer' '......' '1:30'\n",
      " '34592' 'bozo' '356' '324' '50,000' 'angelo' 'alpo' '0.294' '9th' \"'62\"\n",
      " '1982' '164' '74-75' '85.1' '649' 'bay' 'acscvjh' 'calmly' '1983'\n",
      " 'advtech.uswest.com' '9235' '757' '900rr' '452' '23.0' 'aerostitch'\n",
      " 'cabin' 'adjuster' 'ant' 'blower' '10-year' '\\\\_\\\\_' 'c5pntm.8co'\n",
      " 'bugger' 'accounting' 'bjoern' '3b2' 'calderon' '140' 'cinci'\n",
      " 'congressman' '0.5' '70mph' \"'89-'91\" 'calif.' '3-3' 'c5t759.dsc'\n",
      " '4-speed' '8-6' 'brookbank' '6.7' '.628' '-18' '200,000' '200mpg' '80s'\n",
      " 'admit' '8:51' 'cactus.org' '758-4141' '0.111' 'acceptable' '_so_' '232'\n",
      " 'act' '450' '280' '6.00' '1368' '1006' '3.8' '111' '1r7cr2innvar'\n",
      " 'accord' '8177' '12k' \"'till\" '780' 'campanella' 'adobe.com'\n",
      " 'abbreviation' '763' 'caleb' '269' '20w50']\n",
      "\n",
      "\n",
      "Document index with highest factor probability: 461\n",
      "First 100 words of factor 5 of the document with highest probability\n",
      "['0.872' 'bad-t-the-bone' 'cbr' 'among' '538-3693' '5-speed' 'arrange'\n",
      " 'combine' 'aero-engine' '249' 'bulletin' 'aka' 'break-in' 'assemble'\n",
      " 'bondra' '1967' 'abs' '9500' 'carbs' '302' 'chief.|' 'clayton'\n",
      " 'conclusion' 'aerostich' '\\\\\\\\\\\\' 'a/c' 'bolick' 'claim' '550' 'bargain'\n",
      " 'chi-stl' '10pm' '5.5' 'compuserve' '650' '794-4168' 'buyout' 'critical'\n",
      " 'acs.ucalgary.ca' '0.6' '862' 'approx' '984' 'celebration' 'consumer'\n",
      " 'areans' 'allow' '291' '56.3' '4/15' '275' 'bale' 'corrado' 'backhander'\n",
      " '857' 'alan' 'annoyance' 'alley' '__________' 'abbott' '300,000'\n",
      " 'argument' 'arbour' 'bnr.ca' 'acad.drake.edu' '52.6' 'christopher'\n",
      " 'boulder' 'adder' '750' '760' '259' '3.94' '214' '604-255-9937' 'airbox'\n",
      " '7-1' 'allen' 'cas.org' '686' 'blur' 'conversion' '2:12' 'berryhill'\n",
      " 'christ' '7:45' '0.476' 'cci632.cci.com' 'aerodynamics' '318' '9-1'\n",
      " 'c5t3b2.dg' '6425' 'certain' 'alarm' 'completely' 'bother' 'bound'\n",
      " 'biased' '6th']\n",
      "\n",
      "\n",
      "Document index with highest factor probability: 2959\n",
      "First 100 words of factor 6 of the document with highest probability\n",
      "['build' 'aspect' 'bell' '0.41' '.593' '49.5' 'amusing' \"'91-92\"\n",
      " 'avoidance' 'baltimore' 'bag' '/_/' 'ballyard' 'accumulate' 'cs.cmu.edu'\n",
      " 'convert' '.550' '854-7617' 'buff' 'campus' '54.4' 'canister' 'bone'\n",
      " '.357' 'chief' 'confine' '220' 'co.' '0.900' '858' 'archie.cbusa.att.com'\n",
      " '1067' '405' 'administration' 'archibald' '.742' 'bricklin' 'cdt' '124'\n",
      " 'admire' 'chair' '975' '2656' '0.30' 'avenue' '0.00' 'ashburn' '.656'\n",
      " '0.211' 'computrac-richardson' 'bruno' '918' 'coffey' 'bigboote.wpi.edu'\n",
      " '0.649' '_|\\\\' '982' 'callison' 'astacio' 'atmosphere' '177' 'cart' '0.3'\n",
      " '20.8' 'bigs' '764-5874' 'bradw' 'century' 'balltown.cma.com' '406' '=-='\n",
      " '66.8' '0.902' 'backhand' '714/364-0515' 'bull' '3.60' 'assertion' '74.7'\n",
      " '600cc' 'brief' '1817' 'blomberg' 'atleast' 'chrysler' '____' '76.6'\n",
      " 'charlottetown' 'calm' '.59' '1958' '117' '1193' '6-4' 'administrator'\n",
      " 'cbc' 'company/owner' '-p.' 'bonus' '0.290']\n",
      "\n",
      "\n",
      "Document index with highest factor probability: 1357\n",
      "First 100 words of factor 7 of the document with highest probability\n",
      "['46904' '469' 'accident' '0.875' '.599' 'cdkaupan' '451-0815' '/_____/'\n",
      " 'cutlas' 'boone' 'czar' 'apparent' 'college' '0.267' '1326' 'cute'\n",
      " 'conradie' 'btree.uucp' 'common' 'abo.fi' 'contribution' 'amongst'\n",
      " 'cruncher' 'cavallini' '47.2' '629' 'columnist' 'contend' 'clock'\n",
      " 'correction' 'count' 'combustion' 'csa.bu.edu' 'collide'\n",
      " 'csd4.csd.uwm.edu' 'cheat' 'cuban' 'carb' 'cj360' 'csa' 'clothe'\n",
      " 'cerritos' 'chiasson' 'cassidy' 'coleman' 'czech' '573' 'c4wkfs.bc1'\n",
      " 'cliff' 'correlate' 'abe' 'contender' 'clyde' 'bigot' '3.4' 'complain'\n",
      " 'cory.berkeley.edu' 'cloth' 'commissioner' '-rick' 'connection'\n",
      " 'captaincy' 'cookson' '570' 'albuquerque' \"a's\" 'actuality' 'bloody'\n",
      " '15.8' 'carmel' 'creative' 'cecil' 'canyon' 'comfortably' 'copious'\n",
      " '0.84' 'charlie' 'colin' '0.25' 'bumps/potholes' 'combined' 'chronic'\n",
      " '0.49' 'ccwf.cc.utexas.edu' 'collective' 'continually' 'consideration'\n",
      " 'cheryl' 'bandit' '4173' 'carnegie' '1180' 'cent' 'clara' '1992-93'\n",
      " 'corson' 'connor' 'colleague' 'cbnewsj.cb.att.com' 'consumption']\n",
      "\n",
      "\n",
      "Document index with highest factor probability: 3677\n",
      "First 100 words of factor 8 of the document with highest probability\n",
      "['confirm' 'applicable' 'bar' 'alink' '130' '1564' '7000' '4-6' '10.2'\n",
      " 'buffalo' 'block' '100' '//|' 'arm' 'bust' 'british' 'clobber' 'axel'\n",
      " '187' 'bite' 'clamp' '1053' 'afm' '192' '415' 'acsu.buffalo.edu' 'cincy'\n",
      " '1539' 'am/fm' '1.0b14' 'catastrophe' 'aslin' 'cross' 'beautiful' 'bosio'\n",
      " \"'93-'94\" '500cc' '227-2431' 'airport' 'arnie' 'clarkson' 'arlington'\n",
      " '34.5' 'barely' '.659' 'casbah.acns.nwu.edu' 'coil' '-dr.banzai'\n",
      " 'chrissc587qb.d1b' 'chest' 'bart' 'add' 'caldwell8102' 'cadkey.com'\n",
      " 'arlow' 'bain' 'barry' '12s' '2002' '18th' 'brownlow' 'appearance' 'arpa'\n",
      " '256' 'asshole' '207' 'assembly' 'c23st' '1993apr22.101356.1' 'ambulance'\n",
      " 'bdrc.bd.com' '0.795' '16.7' 'behrens' '-750-3511' 'behunin' '35.4'\n",
      " 'cogsci.ucsd.edu' 'cdw2t' '716' 'acd4.acd.com' '15.1' 'corp' 'bump'\n",
      " 'brittenson' 'better' '1196' 'alphabetical' 'courtesy' 'blanket'\n",
      " '\\\\_____\\\\' 'ave' '0663' '13th' '9000' '325' 'crumble' '966' '85.0' '542']\n",
      "\n",
      "\n",
      "Document index with highest factor probability: 612\n",
      "First 100 words of factor 9 of the document with highest probability\n",
      "['1010' '0.28' 'ago' 'ashamed' 'aik' 'bsu-ucs' 'cgy' 'barasso'\n",
      " '1993apr23.102811.623' '10-12' 'bimmer' 'bandwagon' '1082' 'bangle'\n",
      " '1qgi8einnhs5' '0598' 'bigwpi.wpi.edu' 'afternoon' 'blair' 'bluntly'\n",
      " 'coating' '1-0' 'black' 'ascot' 'borchevsky' 'cruiser-bike' '.634'\n",
      " 'binghmaton' 'azw' 'bumpy' '10-15' 'biology' 'avg' 'casares' '.655'\n",
      " 'black.berkeley.edu' 'arrl' '1212' 'boi.hp.com' 'charging' 'andresen'\n",
      " '1kspt=17.28' '1.01' 'bcr' 'coat' 'beat' 'buffalo-boston' 'arsenal'\n",
      " 'alpine' 'ascertain' 'arbitration' 'attention' 'blumstein' 'bow'\n",
      " 'corporation' '.717' 'apartment' 'bra' 'allegation' '15-day' 'arrow'\n",
      " 'ashkar' 'burnham' '1975' 'carroll' '0.09' '0.190' 'blazer' 'bless' '835'\n",
      " '1.12' 'applause' 'considerable' 'announcer' 'cameron' '0.880' '0w0'\n",
      " 'body' 'ayari' 'brock' 'bobby' '1.11' 'assure' '1720.1' 'cursive'\n",
      " 'atsugi' 'brag' '02-01' 'asphaug' '0.642' 'cs.uiuc.edu' '1575.9'\n",
      " 'audience' '3.75' 'blockhead' '0.56' '1:05pm' 'albeit' 'commit' '228']\n",
      "\n",
      "\n",
      "Document index with highest factor probability: 826\n",
      "First 100 words of factor 10 of the document with highest probability\n",
      "['186' 'akerstrom' 'biberdorf' '182' '.680' '0.81' '0.45' '.616'\n",
      " 'black.clarku.edu' '^^^^^^^^^^^^^^' '97.7' '169' 'bernie' '120399'\n",
      " 'bugatti' 'bat' 'conceive' 'alfredo' '604' 'ai598' 'bloom' 'attach'\n",
      " 'bunch' 'bpita' '703' 'cs.dal.ca' '0.854' 'building' 'bullshit' '750ss'\n",
      " 'binghamton' 'alloy' '161' 'burlington' 'bmwmoa' 'aber.ac.uk' 'belong'\n",
      " 'bates' 'buick' 'batter' 'bash' 'beretta' '31.8' 'along' 'assault'\n",
      " 'americans' '0.03' 'circumstance' 'baron' 'baun' 'bruiser' '4/22' '_any_'\n",
      " 'buffeting' '136' 'b.c.' '141' '351' 'belt' 'badge' 'belcher' 'baseline'\n",
      " '131' '48.0' 'bristol' '18.3' '122' 'chart' '04-02' 'artist' 'ctrlaltdel'\n",
      " 'boring' 'bunis' 'cbx' 'binghampton' 'bson' '.615' 'battery' '0.327'\n",
      " '0-0,1-1,0-2' 'btw' '327/278' '191' '1.4-b1' 'athletics' '145' '998'\n",
      " 'borschevsky' '16:44' 'bench' '\\\\_______/' 'alexander' 'broadcaster'\n",
      " 'coliseum' '5,000rpm' 'antonio' 'amend' 'bure' '0709' '100,000']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10 words with largest absolute weights in each factor\n",
    "for i in range(psi.shape[0]):\n",
    "    topweights_indices = numpy.argsort(-1 * numpy.abs(psi[i, :]))\n",
    "    print('Document index with highest factor probability: ' + str(topweights_indices[0] + 1))\n",
    "    print('First 100 words of factor ' + str(i+1) + ' of the document with highest probability')\n",
    "    print(remainingvocabulary[topweights_indices[0:100]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Do the factors seem related to individual newsgroups? Does their content seem meaningful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, the factors seem not related to individual newsgroups. The content seems not meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Optional: let's see if an AI chatbot can analyze these factors. See exercise 2.4 regarding possible chatbots; report what chatbot you used. \n",
    "\n",
    "Take one of the factors, e.g., the highest probability one, and give its list of top words to an AI chatbot; you can tell it that the factor has been learned from the four newsgroups. Ask it to interpret the factor based on the word list. Ask it also to generate a text that could be drawn from the factor. Does its interpretation seem meaningful and likely correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: \n",
    "\n",
    "Document index with highest factor probability: 2937\n",
    "First 100 words of factor 1 of the document with highest probability\n",
    "['buchberger' 'bunt' 'cuyler' 'amazing' 'colonial' 'checker' 'concession'\n",
    " 'bum' 'challenging' 'colored' 'closed-minded' 'camping'\n",
    " 'cms.cc.wayne.edu' \"'57\" 'compulsive' 'bythe' 'compromise' 'beast'\n",
    " 'competitive' 'chess.ncsu.edu' 'anonymous' '16,005' 'c4zcii.ftn'\n",
    " 'cluster' 'breakaway' 'chassis' 'anthony' 'cannucks' 'concern' 'barberie'\n",
    " 'antenna' 'crusade' '185900001' 'basement' 'att.com' 'contractual'\n",
    " 'canadiens' 'ching' 'cam' 'chi-5' '.533' '05-04' '1110' 'competitor'\n",
    " 'ala' 'claude' 'boever' 'collegiate' 'creighton' '12:40' 'alternator'\n",
    " 'conceivable' 'boyle' 'clockwise' 'cmk' 'bogey' '1988' 'csc.albany.edu'\n",
    " 'dagibbs' 'cmuvm.csv.cmich.edu' 'd6s' '15th' 'd.sweeney' 'cgkarras'\n",
    " 'burke' 'business' '19:59' '04-03' 'cream' 'copy' '7:30' 'con' '1138'\n",
    " 'bald' '===' '094' 'appoint' '987' '0.571' 'casey' 'charm' '1.8' 'aug'\n",
    " 'cyt' 'complaint' 'closeup' 'cpsc.ucalgary.ca' 'commute' 'am2x+'\n",
    " 'collie/golden' 'ame' 'alright' 'cvax.psi.ch' 'center' 'comfortable'\n",
    " 'athena.mit.edu' 'adjustable' '.653' '0.421' 'card']\n",
    "\n",
    "Can you tell the factor has  been learned from ec.autos, rec.motorcycles,\n",
    "rec.sport.baseball, and rec.sport.hockey? \n",
    "\n",
    "interpret the factor based on the word list\n",
    "\n",
    "generate a text that could be\n",
    "drawn from the factor\n",
    "\n",
    "CHAT GPT RESPONSE:\n",
    "\n",
    "Based on the provided information, it seems like the document index with the highest factor probability is 2937, and the first 100 words of factor 1 of this document include a list of words. Unfortunately, without more context or specific details about the factor analysis, it's challenging to precisely interpret the factor and its connection to ec.autos, rec.motorcycles, rec.sport.baseball, and rec.sport.hockey.\n",
    "\n",
    "However, by examining the word list, it appears to contain a diverse range of terms that might be associated with different topics. Some words, such as \"chess,\" \"camping,\" \"canadiens,\" and \"competitor,\" suggest a connection to sports or recreational activities. Other words like \"colonial,\" \"concession,\" and \"contractual\" seem more general and could be related to various discussions.\n",
    "\n",
    "To generate a text that could be drawn from this factor, we can create a hypothetical paragraph:\n",
    "\n",
    "\"In the exciting world of competitive sports, where amazing feats and challenging competitions unfold, teams and players strive for victory. The chess matches on chess.ncsu.edu showcase the strategic prowess of competitors, while camping enthusiasts gather at the colonial campground for a breakaway adventure. Amid contractual negotiations and concession agreements, the Canadiens make strategic moves on the chessboard of rec.sport.hockey. The atmosphere is electric, with each participant bringing their competitive spirit to the forefront. Whether it's the adrenaline of rec.sport.baseball or the precision of chess.ncsu.edu, the diverse community engages in thrilling competitions that captivate audiences worldwide.\"\n",
    "\n",
    "This paragraph attempts to incorporate some of the words from the provided list into a coherent narrative that could be related to factors learned from ec.autos, rec.motorcycles, rec.sport.baseball, and rec.sport.hockey.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation seem meaning ful, since it is related to the topic of the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 6.3: Latent Dirichlet allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Using the same data as in Exercise 6.1 (four newsgroups), create a term frequency matrix of\n",
    "raw term counts for the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Apply Latent Dirichlet Allocation to the term frequency matrix to find 10 underlying topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "# Create a dictionary from the documents\n",
    "# startdoc=9000     # We will use the baseball n.g.\n",
    "# enddoc=10000      # again, but all features\n",
    "# gensim_docs=mycrawled_prunedtexts[startdoc:enddoc]\n",
    "gensim_docs=mycrawled_prunedtexts\n",
    "gensim_dictionary=gensim.corpora.Dictionary(gensim_docs)\n",
    "# Create the document-term vectors\n",
    "gensim_docvectors=[]\n",
    "for k in range(len(gensim_docs)):     \n",
    "    docvector=gensim_dictionary.doc2bow(gensim_docs[k])\n",
    "    gensim_docvectors.append(docvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LDA optimization\n",
    "numtopics=10\n",
    "randomseed=124574527\n",
    "numiters=10000\n",
    "ninits=10\n",
    "gensim_ldamodel=gensim.models.ldamodel.LdaModel( \\\n",
    "    gensim_docvectors, \\\n",
    "    id2word=gensim_dictionary,num_topics=numtopics, \\\n",
    "    iterations=numiters,random_state=randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Describe the resulting factors: list the 10 words with highest probability in each topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 words with highest probability in topic 1\n",
      "-------------------------------------------------------------\n",
      "0.011*\"edmonton\" + 0.010*\"buffalo\" + 0.008*\"giant\" + 0.006*\"fame\" + 0.006*\"draft\" + 0.006*\"scoring\" + 0.005*\"czech\" + 0.004*\"milwaukee\" + 0.004*\"ted\" + 0.004*\"murphy\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 2\n",
      "-------------------------------------------------------------\n",
      "0.009*\"brave\" + 0.007*\"captain\" + 0.006*\"stadium\" + 0.006*\"cal\" + 0.005*\"runner\" + 0.004*\"cleveland\" + 0.004*\"bos\" + 0.004*\"finish\" + 0.004*\"predict\" + 0.004*\"suck\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 3\n",
      "-------------------------------------------------------------\n",
      "0.007*\"pen\" + 0.006*\"jay\" + 0.005*\"york\" + 0.005*\"draft\" + 0.004*\"murray\" + 0.004*\"williams\" + 0.003*\"acquire\" + 0.003*\"frank\" + 0.003*\"era\" + 0.003*\"morris\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 4\n",
      "-------------------------------------------------------------\n",
      "0.011*\"pit\" + 0.010*\"mario\" + 0.008*\"bat\" + 0.008*\"bos\" + 0.007*\"maynard\" + 0.006*\"morris\" + 0.005*\"ron\" + 0.004*\"defense\" + 0.004*\"=-=\" + 0.004*\"minor\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 5\n",
      "-------------------------------------------------------------\n",
      "0.004*\"philadelphia\" + 0.004*\"ottawa\" + 0.004*\"capital\" + 0.004*\"greg\" + 0.004*\"final\" + 0.004*\"champ\" + 0.004*\"cap\" + 0.003*\"defense\" + 0.003*\"minnesota\" + 0.003*\"field\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 6\n",
      "-------------------------------------------------------------\n",
      "0.016*\"stanley\" + 0.016*\"islander\" + 0.010*\"defensive\" + 0.006*\"offense\" + 0.006*\"giant\" + 0.005*\"murray\" + 0.005*\"face\" + 0.005*\"broadcast\" + 0.004*\"smith\" + 0.003*\"pinch\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 7\n",
      "-------------------------------------------------------------\n",
      "0.015*\"det\" + 0.010*\"baltimore\" + 0.008*\"tie\" + 0.007*\"ice\" + 0.004*\"skate\" + 0.004*\"smythe\" + 0.004*\"joseph\" + 0.004*\"bos\" + 0.004*\"calgary\" + 0.004*\"contact\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 8\n",
      "-------------------------------------------------------------\n",
      "0.013*\"shark\" + 0.007*\"hartford\" + 0.005*\"bobby\" + 0.005*\"cincinnati\" + 0.005*\"montreal\" + 0.005*\"pit\" + 0.004*\"jose\" + 0.004*\"vancouver\" + 0.004*\"st.\" + 0.003*\"netcom.com\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 9\n",
      "-------------------------------------------------------------\n",
      "0.006*\"cal\" + 0.005*\"los\" + 0.005*\"stats\" + 0.004*\"angeles\" + 0.004*\"calgary\" + 0.004*\"bond\" + 0.004*\"van\" + 0.004*\"jet\" + 0.004*\"expansion\" + 0.003*\"montreal\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 10\n",
      "-------------------------------------------------------------\n",
      "0.012*\"penalty\" + 0.005*\"quebec\" + 0.005*\"ott\" + 0.004*\"devil\" + 0.004*\"montreal\" + 0.004*\"maynard\" + 0.003*\"lopez\" + 0.003*\"arena\" + 0.003*\"finland\" + 0.003*\"brave\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (c) Describe the resulting factors: list the 10 words with highest probability in each topic. \n",
    "for i in range(numtopics):\n",
    "    print('10 words with highest probability in topic ' + str(i+1))\n",
    "    print('-------------------------------------------------------------')\n",
    "    print(gensim_ldamodel.print_topic(i,topn=10))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Find, for each topic, the document (message) with highest probability of that topic, and print its 100 first words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic content: term-topic probabilities\n",
    "gensim_termtopicprobabilities=gensim_ldamodel.get_topics()\n",
    "# Get topic prevalences per document, and overall topic prevalences\n",
    "# (expected amount of documents per topic)\n",
    "overallstrengths=numpy.zeros((numtopics,1))\n",
    "documentstrengths=numpy.zeros((len(gensim_docvectors),numtopics))\n",
    "for k in range(len(gensim_docvectors)):\n",
    "    topicstrengths=gensim_ldamodel.get_document_topics(\\\n",
    "        gensim_docvectors[k],minimum_probability=0)\n",
    "    for m in range(len(topicstrengths)):\n",
    "        documentstrengths[k][topicstrengths[m][0]]=topicstrengths[m][1]\n",
    "        overallstrengths[topicstrengths[m][0]]=\\\n",
    "        overallstrengths[topicstrengths[m][0]]+topicstrengths[m][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('stanley', 0.01637378), ('islander', 0.015583312), ('defensive', 0.0099151675), ('offense', 0.005795607), ('giant', 0.0056868396), ('murray', 0.0051159374), ('face', 0.0046372013), ('broadcast', 0.0045163757), ('smith', 0.004167805), ('pinch', 0.0031735469)]\n"
     ]
    }
   ],
   "source": [
    "# Show top-10 words of the top topic (number 5 here)\n",
    "print(gensim_ldamodel.show_topic(5,topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document index with highest topic probability: 1144\n",
      "First 100 words of topic 1 of the document with highest probability\n",
      "['engr.latech.edu', 'speedy', 'engr.latech.edu', 'speedy', 'mercer', 'attack', 'rabid', 'hubcap', 'yamaha', '750', 'twin', 'a.k.a', 'tank', 'wierd', 'noise', 'catch', 'glimpse', 'silver', 'left', 'foot', 'jerk', 'foot', 'peg', 'pull', 'near', 'parking', 'discover', 'type', 'hubcap', 'large', 'cage', 'hubcap', 'weigh', '4-5', 'pound', 'impact', 'bend', 'left', 'peg', 'flat', 'frame', 'shifter', 'process', 'heard', 'approach', 'cap', 'sans', 'portion', 'left', 'foot', 'sort', 'experience', 'cap', 'yard', 'delivery', 'truck', 'life', 'interest', 'several', 'sheet', 'dozen', 'gallon', 'mph', 'interesting', 'wood', 'dry', 'helmet', 'tail', 'truck', 'path', 'burst', 'impact', 'lane', '360', 'nail', 'bridge', 'half', '360', 'messy', 'diego', 'apartment', 'beach', 'sportster', 'shake', 'burger', 'fry', 'jack', 'box', 'foul', 'weather', 'jacket', 'milk', 'shake', 'open', 'blvd', 'mph', 'smell', 'vanilla', 'milk', 'shake']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1164\n",
      "First 100 words of topic 2 of the document with highest probability\n",
      "['southern', 'california', '4/14/93', 'update', 'street', 'open', 'bikers', 'inc.', 'phone', 'info', 'e-mail', 'address', 'mailed', 'copy', 'suggest', 'info', 'current', 'info', 'accuracy', 'responsible', 'error', 'e-mail', 'address', 'paulb', 'harley.tti.com', 'coffee', 'donut', 'live', 'music', 'food', 'drink', 'available', 'posting', 'address', 'posting', 'apr', '11th', 'annual', 'river', 'concert', 'poker', 'party', 'etc.', 'sponsor', 'southern', 'calif.', 'harley', 'welcome', 'harley', 'river', 'discount', 'room', 'concert', 'tix', 'apr', '2nd', 'annual', 'race', 'sale', 'art', 'print', 'photo', 'model', 'book', 'apr', 'scma', 'route', 'tour', 'apr', 'tour', 'santa', 'monica', 'lane', 'apr', 'tax', 'abate', '200', 'pin', 'prize', 'raffle', 'free', 'join', 's/in', 'v-twin', 'city', 'canyon', 'manny', 'apr', '3rd', 'annual', 'linda', 'child', 'hospital', 'benefit', 'free', 'hot', 'finish', 's/in', 'skip', 'motor']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1992\n",
      "First 100 words of topic 3 of the document with highest probability\n",
      "['x-disclaimer', 'message', 'user', 'convex', 'computer', 'corp', 'express', 'user', 'necessarily', 'convex', 'quick', 'advantage', 'versus', 'stock', 'exhaust', 'versus', 'aftermarket', 'exhaust', 'heavily', 'advertise', 'half', 'expensive', 'cost', 'oem', 'replacement', 'weigh', 'instance', 'carburetor', 'performance', 'replace', 'oem', 'canister', 'ontario', 'slip', 'performance', 'notice', 'slight', 'rpm', 'developer', 'manufacturer', 'slip', 'large', 'pilot', 'idle', 'jet', 'suppose', 'live', 'difference', 'pressure', 'anyway', 'besides', 'minor', 'slip', 'performance', 'loud', 'stock', 'loud', 'annoy', 'folk', 'ontario', 'slip', 'sort', 'technique', 'reduce', 'full', 'throttle', 'tuned', 'intake', 'exhaust', 'characteristic', 'beyond', 'delta', 'manufacturer', 'compensate', 'complete', 'exhaust', 'header', 'muffler', 'exhaust', 'characteristic', 'require', 'compensate', 'profile', 'folk', 'slip', 'intend', 'particular', 'slip', 'data', 'rider', 'issue', 'review', 'group', 'header', 'exhaust', 'cbr600f2', 'bar', 'ontario', 'slip', 'dyno']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1443\n",
      "First 100 words of topic 4 of the document with highest probability\n",
      "['greeting', 'fellow', 'roadracing', 'enthusiast', 'background', 'racing', 'boogie.ebay.sun.com', 'contain', 'discussion', 'devote', 'race', 'topic', 'broad', 'interest', 'group', 'individual', 'variety', 'background', 'roadracing', 'perspective', 'pit', 'crew', 'racer', 'engineering', 'enthusiast', 'size', 'grow', 'weekly', 'currently', 'hundred', 'member', 'contributor', 'zealand', 'australia', 'germany', 'france', 'england', 'finland', 'switzerland', 'united', 'form', 'october', '1991', 'response', 'perceive', 'provide', 'technical', 'discussion', 'edge', 'performance', 'roadracing', 'improve', 'ratio', 'rec.motorcycles', 'free', 'join', 'discussion', 'necessarily', 'limit', 'rule', 'issue', 'relate', 'race', 'daily', 'distribution', 'welcome', 'subscribe', 'subscribe', 'request', 'boogie.ebay.sun.com', 'traffic', 'currently', 'five', 'message', 'per', 'depend', 'topic', '_not_', 'subscription', 'request', 'directly', 'contact', 'administrator', 'receive', 'request', 'respond', 'request', 'manner', 'add', 'request', 'generate', 'order', 'insure', 'valid', 'site', 'upon', 'add', 'daily', 'digest', 'distribution']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1964\n",
      "First 100 words of topic 5 of the document with highest probability\n",
      "['asphaug', 'lpl.arizona.edu', 'erik', 'asphaug', 'x2773', 'hello', 'folk', 'happy', 'r80gs', 'range', '238', '4.8', 'gallon', 'mpg', 'surprisingly', 'cruiser', 'rough', 'sweet', 'backroad', 'honey', 'mountain', 'shaft', 'effect', 'torque', 'effect', 'crankshaft', 'rev', 'sit', 'twist', 'bit', 'large', 'chunk', 'mass', 'rotate', 'hence', 'rev', 'twist', 'shaft', 'effect', 'rear', 'rise', 'throttle', 'snap', 'shut', 'corner', 'shaft', 'almost', 'shaft', 'effect', 'fast', 'shaft', 'effect', 'buffeting', 'wind', 'consequence', 'okay', 'recommendation', 'fairing', 'wind', 'chest', 'perhaps', 'helmet', 'comfort', 'highway', 'mph', 'yet', 'screw', 'stability', 'block', 'vision', 'trail', 'riding', 'anybody', 'luck', 'two-piece', 'fairings', 'standard', 'headlamp', 'plus', 'sidelamp', 'mount', 'crash', 'bar', 'illumination', 'excellent', 'full', 'beam', 'level', 'motor', 'left', 'lamp', 'beam', 'linear', 'bright', 'streak', 'illumination', 'deer', 'lurking', 'combine', 'headlamp']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 144\n",
      "First 100 words of topic 6 of the document with highest probability\n",
      "['newsgroup', 'tap', 'knowledge', 'expertise', 'available', 'subject', 'after-market', 'cruise', 'control', 'background', 'recently', 'break', 'ankle', 'accident', 'five', 'screw', 'return', 'texas', 'school', 'utah', 'imagine', 'nearly', '1300', 'broken', 'ankle', 'cruise', 'control', 'ankle', 'general', 'after-market', 'cruise', 'control', 'unit', 'realize', 'cheap', 'cruise', 'control', 'pep', 'boy', 'factory', 'professionally', 'installed', 'unit', 'accuracy', 'sort', 'ankle', '1984', 'jeep', 'cherokee', 'standard', 'ignition', \"y'know\", 'distributor', 'cap', 'rotor', 'set-up', 'electronic', \"'84\", 'information', 'unit', 'buck', 'vehicle', 'vacuum', 'instead', 'electric', 'vacuum', 'hose', 'tap', 'sensor', 'signal', 'negative', 'distributor', 'kinda', 'tach', 'pick-up', 'understand', 'manual', 'store', 'today', 'set-up', 'accurate', 'install', 'difference', 'sensor', 'pedal', 'sensor', 'pedal', 'attention', 'push', 'cruise', 'wind', 'kinda', 'wit', 'coordinate', 'bother', 'girlfriend', 'bother', 'installation', 'attachment', 'signal']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 624\n",
      "First 100 words of topic 7 of the document with highest probability\n",
      "['horace', 'dediu', 'shantanu', 'shantanu', 'comment', 'performance', 'mid', 'obtain', 'adjust', 'gear', 'final', 'ratio', 'contrary', 'popular', 'japanese', 'performance', '70+', 'gear', 'perform', 'consistently', 'condition', 'wind', 'curve', 'hour', 'driver', 'white', 'knuckle', 'experience', 'touring', 'easily', 'distinguish', 'poise', 'stay', 'cruise', 'control', '155', 'hour', \"i've\", 'typical', 'boy', 'racer', 'fiat', 'century', 'wind', 'blow', 'lane', 'overpass', 'fly', 'guardrail', 'buffeting', '125', 'severe', 'hood', 'bend', '155', 'melt', 'pothole', 'kill', 'german', 'design', 'environment', \"can't\", 'mercedes', 'mind', 'particular', 'design', 'fuel', 'economy', 'german', 'gear', 'efficiency', 'typical', '1500', 'almost', 'stall', 'idea', 'hondas', 'handle', '100+', 'mph', 'reach', '155', 'mph', 'several', 'trip', 'civic', 'whatsoever', 'trip', 'york', 'texas', 'typically', 'mph', 'comfortable', 'benz', 'white', 'knuckle', 'wind', 'curve', 'trip', 'orleans']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 245\n",
      "First 100 words of topic 8 of the document with highest probability\n",
      "['news-software', 'vax/vms', 'vnews', '1.41', 'research.nj.nec.com', 'behanna', 'syl.nj.nec.com', 'chris', 'behanna', 'newsgate.sps.mot.com', 'rapw20', 'email.sps.mot.com', 'research.nj.nec.com', 'behanna', 'syl.nj.nec.com', 'chris', 'behanna', 'several', 'chemist', 'already', 'several', 'substitute', 'r12', 'mobile', 'air', 'condition', 'society', 'mac', 'stand', 'rake', '300', '1000', 'per', 'retrofit', 'per', 'automobile', 'mount', 'organize', 'campaign', 'squash', 'r12', 'substitute', 'existence', 'ban', 'altogether', 'shaky', 'technical', 'ground', 'outright', 'lie', 'r-12', 'substitute', 'exist', '200mpg', 'carbs', 'company', 'crazy', 'r-12', 'currently', 'commercial', 'product', 'unfortunately', 'sae', 'committee', 'mobile', 'air', 'conditioning', 'comprise', 'almost', 'exclusively', 'member', 'paper', 'alternative', 'accept', 'provide', 'detail', 'repost', 'repost', 'later', 'chris', 'behanna', '114', '1983', 'h-d', 'fxwg', 'wide', 'glide', 'jubilee', 'lady', 'behanna', 'syl.nj.nec.com', '1975', 'cb360t', 'baby', 'disclaimer', 'nec', '1991', 'zx-11', 'anyway', 'raise']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 800\n",
      "First 100 words of topic 9 of the document with highest probability\n",
      "['review', 'today', 'visit', 'friend', 'whose', 'love', 'audis', 'live', 'delay', 'audi', 'servotronic', 'steering', 'familiar', 'servotronic', 'variable', 'steer', 'manufacture', 'audis', 'bmws', 'servotronic', 'past', 'month', 'magazine', 'review', 'audi', 'quattro', 'audi', 'fwd', 'happy', 'report', 'servotronic', 'suppose', 'due', 'fat', 'servotronic', 'load', 'perfect', 'mind', 'happy', 'option', 'refuse', 'longer', 'entire', 'ruin', 'steering', 'tad', 'accurate', 'suppose', 'spring', 'chassis', 'information', 'driver', 'accuracy', 'steering', 'room', 'improvement', 'steering', 'japanese', 'competition', 'primarily', 'japanese', 'engineer', 'completely', 'pressure', '110', 'clock', 'produce', 'anywhere', 'later', 'pack', 'terrific', 'punch', 'turbocharged', 'machine', 'unusual', 'encourage', 'lazy', 'driving', 'i.e', 'rev', 'gear', 'flexible', 'hardly', '2.2', 'liter', 'displacement', 'pound', 'fashion', 'maximum', 'torque', 'available', '1950', 'rpm', 'rpm', 'redline', 'translate', 'range', 'mph', 'normally', 'associate']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1634\n",
      "First 100 words of topic 10 of the document with highest probability\n",
      "['dsd.es.com', 'bgardner', 'pebbles.es.com', 'blaine', 'gardner', 'earth.cs.utexas.edu', 'mcguire', 'cs.utexas.edu', 'tommy', 'marcus', 'mcguire', 'hey', 'hell', 'suck', 'god-given', 'express', 'carry', 'gun', 'wear', 'helmet', 'goddamn', 'everything', 'stand', 'stupid', '0.5', 'scale', 'mention', 'hitler', 'koresh', 'favor', 'neglect', 'mention', '105', 'mph', 'tennis', 'girl', 'countersteering', 'mexican', 'food', 'folk', 'mistake', 'heat', 'quality', 'subtle', 'reference', 'various', 'personal', 'generally', 'earn', 'four', 'letter', 'word', 'cap', 'lock', 'key', 'introduce', 'polysyllabic', 'word', 'strabismic', 'example', 'likely', 'insure', 'become', 'immortal', 'blaine', 'gardner', 'evans', 'sutherland', 'bgardner', 'dsd.es.com', \"c'mon\", 'serious', 'overreaction', 'ought', 'worth', 'mention', 'bit', 'condemn', 'non', 'gun', 'helmet', 'proper', 'flourish', 'personally', 'type', 'quality', 'sense', 'mention', 'heat', 'certain', 'surprise', 'value', 'correctly', 'contend', 'reasonably', 'entertaining', 'mention', 'velocity', 'friend', 'dinner']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (d) Find, for each topic, the document (message) with highest probability of that topic, and print\n",
    "# its 100 first words.\n",
    "for i in range(numtopics):\n",
    "    print('Document index with highest topic probability: ' + str(numpy.argmax(documentstrengths[:,i]) + 1))\n",
    "    print('First 100 words of topic ' + str(i+1) + ' of the document with highest probability')\n",
    "    print(gensim_docs[numpy.argmax(documentstrengths[:,i])][0:100])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Do the topics seem related to individual newsgroups? Does their content seem meaningful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the topics seem related to individual newsgroups, but some of them are not. The content seems meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Carry out (b)-(d) with 15 topics instead. Are some of the topics the same as before? What are the differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LDA optimization\n",
    "numtopics=15\n",
    "randomseed=124574527\n",
    "numiters=10000\n",
    "ninits=10\n",
    "gensim_ldamodel=gensim.models.ldamodel.LdaModel( \\\n",
    "    gensim_docvectors, \\\n",
    "    id2word=gensim_dictionary,num_topics=numtopics, \\\n",
    "    iterations=numiters,random_state=randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 words with highest probability in topic 1\n",
      "-------------------------------------------------------------\n",
      "0.017*\"buffalo\" + 0.014*\"giant\" + 0.011*\"montreal\" + 0.008*\"scoring\" + 0.007*\"lineup\" + 0.007*\"jersey\" + 0.006*\"jet\" + 0.006*\"stats\" + 0.006*\"ted\" + 0.005*\"rockies\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 2\n",
      "-------------------------------------------------------------\n",
      "0.019*\"brave\" + 0.009*\"captain\" + 0.008*\"cal\" + 0.008*\"stadium\" + 0.008*\"atlanta\" + 0.008*\"runner\" + 0.007*\"bos\" + 0.006*\"3rd\" + 0.006*\"eric\" + 0.005*\"cleveland\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 3\n",
      "-------------------------------------------------------------\n",
      "0.008*\"jay\" + 0.007*\"murray\" + 0.006*\"williams\" + 0.005*\"draft\" + 0.005*\"roy\" + 0.004*\"acquire\" + 0.004*\"individual\" + 0.004*\"isle\" + 0.004*\"steal\" + 0.004*\"statistic\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 4\n",
      "-------------------------------------------------------------\n",
      "0.014*\"mario\" + 0.010*\"maynard\" + 0.008*\"morris\" + 0.005*\"=-=\" + 0.005*\"bat\" + 0.005*\"european\" + 0.004*\"ron\" + 0.004*\"pit\" + 0.003*\"central\" + 0.003*\"sfu.ca\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 5\n",
      "-------------------------------------------------------------\n",
      "0.010*\"philadelphia\" + 0.006*\"cap\" + 0.005*\"ottawa\" + 0.004*\"hunter\" + 0.004*\"102\" + 0.004*\"nichols\" + 0.004*\"defense\" + 0.004*\"dale\" + 0.004*\"stevens\" + 0.003*\"star\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 6\n",
      "-------------------------------------------------------------\n",
      "0.024*\"stanley\" + 0.023*\"islander\" + 0.009*\"defensive\" + 0.006*\"broadcast\" + 0.006*\"giant\" + 0.005*\"offensive\" + 0.004*\"face\" + 0.003*\"winner\" + 0.003*\"kevin\" + 0.003*\"champion\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 7\n",
      "-------------------------------------------------------------\n",
      "0.022*\"det\" + 0.009*\"bos\" + 0.007*\"ice\" + 0.007*\"calgary\" + 0.007*\"bond\" + 0.007*\"skate\" + 0.006*\"tie\" + 0.005*\"contact\" + 0.004*\"request\" + 0.004*\"final\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 8\n",
      "-------------------------------------------------------------\n",
      "0.017*\"shark\" + 0.014*\"pit\" + 0.009*\"hartford\" + 0.008*\"jose\" + 0.007*\"vancouver\" + 0.007*\"bobby\" + 0.007*\"cincinnati\" + 0.007*\"smythe\" + 0.006*\"montreal\" + 0.006*\"har\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 9\n",
      "-------------------------------------------------------------\n",
      "0.006*\"expansion\" + 0.006*\"calgary\" + 0.006*\"stats\" + 0.005*\"hall\" + 0.004*\"hitting\" + 0.004*\"wilson\" + 0.004*\"winner\" + 0.003*\"draft\" + 0.003*\"murray\" + 0.003*\"singer\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 10\n",
      "-------------------------------------------------------------\n",
      "0.019*\"penalty\" + 0.008*\"ott\" + 0.007*\"min\" + 0.006*\"maynard\" + 0.005*\"arena\" + 0.004*\"devil\" + 0.003*\"forward\" + 0.003*\"netcom.com\" + 0.003*\"gary\" + 0.003*\"ryan\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 11\n",
      "-------------------------------------------------------------\n",
      "0.013*\"los\" + 0.008*\"champ\" + 0.008*\"lopez\" + 0.007*\"tie\" + 0.007*\"finland\" + 0.006*\"pool\" + 0.006*\"czech\" + 0.006*\"capital\" + 0.005*\"angeles\" + 0.005*\"victory\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 12\n",
      "-------------------------------------------------------------\n",
      "0.009*\"cal\" + 0.007*\"van\" + 0.005*\"angeles\" + 0.004*\"strike\" + 0.004*\"sunday\" + 0.004*\"baltimore\" + 0.004*\"stat\" + 0.004*\"walk\" + 0.004*\"field\" + 0.004*\"draft\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 13\n",
      "-------------------------------------------------------------\n",
      "0.008*\"era\" + 0.008*\"quebec\" + 0.008*\"baltimore\" + 0.006*\"pen\" + 0.006*\"sweden\" + 0.006*\"fame\" + 0.006*\"contract\" + 0.005*\"montreal\" + 0.005*\"mon\" + 0.005*\"rochester\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 14\n",
      "-------------------------------------------------------------\n",
      "0.013*\"edmonton\" + 0.012*\"offense\" + 0.007*\"football\" + 0.006*\"senator\" + 0.005*\"frank\" + 0.005*\"george\" + 0.004*\"maine\" + 0.004*\"stats\" + 0.004*\"felix\" + 0.004*\"hawk\"\n",
      "\n",
      "\n",
      "10 words with highest probability in topic 15\n",
      "-------------------------------------------------------------\n",
      "0.006*\"philly\" + 0.006*\"halifax\" + 0.006*\"suck\" + 0.006*\"canadian\" + 0.006*\"final\" + 0.005*\"jack\" + 0.005*\"2nd\" + 0.005*\"pen\" + 0.005*\"bowman\" + 0.005*\"buffalo\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (c) Describe the resulting factors: list the 10 words with highest probability in each topic. \n",
    "for i in range(numtopics):\n",
    "    print('10 words with highest probability in topic ' + str(i+1))\n",
    "    print('-------------------------------------------------------------')\n",
    "    print(gensim_ldamodel.print_topic(i,topn=10))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic content: term-topic probabilities\n",
    "gensim_termtopicprobabilities=gensim_ldamodel.get_topics()\n",
    "# Get topic prevalences per document, and overall topic prevalences\n",
    "# (expected amount of documents per topic)\n",
    "overallstrengths=numpy.zeros((numtopics,1))\n",
    "documentstrengths=numpy.zeros((len(gensim_docvectors),numtopics))\n",
    "for k in range(len(gensim_docvectors)):\n",
    "    topicstrengths=gensim_ldamodel.get_document_topics(\\\n",
    "        gensim_docvectors[k],minimum_probability=0)\n",
    "    for m in range(len(topicstrengths)):\n",
    "        documentstrengths[k][topicstrengths[m][0]]=topicstrengths[m][1]\n",
    "        overallstrengths[topicstrengths[m][0]]=\\\n",
    "        overallstrengths[topicstrengths[m][0]]+topicstrengths[m][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('stanley', 0.024050219), ('islander', 0.022864446), ('defensive', 0.009085701), ('broadcast', 0.0062354463), ('giant', 0.0057611787), ('offensive', 0.005448156), ('face', 0.004192777), ('winner', 0.0033398676), ('kevin', 0.0033038915), ('champion', 0.0032330477)]\n"
     ]
    }
   ],
   "source": [
    "# Show top-10 words of the top topic (number 5 here)\n",
    "print(gensim_ldamodel.show_topic(5,topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document index with highest topic probability: 607\n",
      "First 100 words of topic 1 of the document with highest probability\n",
      "['drutx.att.com', 'callison', 'james', 'callison', 'normally', 'unloaded', 'colt', 'delta', 'glove', 'box', 'loaded', 'magazine', 'handy', 'perfectly', 'legal', 'oklahoma', 'travel', 'inter-state', 'unloaded', 'magnum', 'revolver', 'glove', 'box', 'pocket', 'legal', 'everywhere', 'federal', 'law', 'illinois', 'police', 'hang', 'carry', 'pistol', 'load', 'unloaded', 'glove', 'compartment', 'carry', 'concealed', 'weapon', 'colorado', 'illegal', 'concealed', 'weapon', 'permit', 'unless', 'law', 'recently', 'carry', 'weapon', 'legal', 'colorado', 'conceal', 'illegal', 'newspaper', 'account', 'police', 'traffic', 'infraction', 'observe', '.357', 'magnum', 'revolver', 'sit', 'seat', 'driver', 'cite', 'carry', 'weapon', 'conceal', 'gun', 'discover', 'glove', 'box', 'crime', 'carry', 'glove', 'box', '_is_', 'legal', 'oklahoma', 'inter-state', 'travel', 'legal', 'destination', 'gun', 'carry', 'locked', 'glove', 'box', 'specifically', 'exclude', 'separate', 'ammo', 'legal', 'title', 'chapter', 'section', 'forget', 'copy']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1164\n",
      "First 100 words of topic 2 of the document with highest probability\n",
      "['southern', 'california', '4/14/93', 'update', 'street', 'open', 'bikers', 'inc.', 'phone', 'info', 'e-mail', 'address', 'mailed', 'copy', 'suggest', 'info', 'current', 'info', 'accuracy', 'responsible', 'error', 'e-mail', 'address', 'paulb', 'harley.tti.com', 'coffee', 'donut', 'live', 'music', 'food', 'drink', 'available', 'posting', 'address', 'posting', 'apr', '11th', 'annual', 'river', 'concert', 'poker', 'party', 'etc.', 'sponsor', 'southern', 'calif.', 'harley', 'welcome', 'harley', 'river', 'discount', 'room', 'concert', 'tix', 'apr', '2nd', 'annual', 'race', 'sale', 'art', 'print', 'photo', 'model', 'book', 'apr', 'scma', 'route', 'tour', 'apr', 'tour', 'santa', 'monica', 'lane', 'apr', 'tax', 'abate', '200', 'pin', 'prize', 'raffle', 'free', 'join', 's/in', 'v-twin', 'city', 'canyon', 'manny', 'apr', '3rd', 'annual', 'linda', 'child', 'hospital', 'benefit', 'free', 'hot', 'finish', 's/in', 'skip', 'motor']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1992\n",
      "First 100 words of topic 3 of the document with highest probability\n",
      "['x-disclaimer', 'message', 'user', 'convex', 'computer', 'corp', 'express', 'user', 'necessarily', 'convex', 'quick', 'advantage', 'versus', 'stock', 'exhaust', 'versus', 'aftermarket', 'exhaust', 'heavily', 'advertise', 'half', 'expensive', 'cost', 'oem', 'replacement', 'weigh', 'instance', 'carburetor', 'performance', 'replace', 'oem', 'canister', 'ontario', 'slip', 'performance', 'notice', 'slight', 'rpm', 'developer', 'manufacturer', 'slip', 'large', 'pilot', 'idle', 'jet', 'suppose', 'live', 'difference', 'pressure', 'anyway', 'besides', 'minor', 'slip', 'performance', 'loud', 'stock', 'loud', 'annoy', 'folk', 'ontario', 'slip', 'sort', 'technique', 'reduce', 'full', 'throttle', 'tuned', 'intake', 'exhaust', 'characteristic', 'beyond', 'delta', 'manufacturer', 'compensate', 'complete', 'exhaust', 'header', 'muffler', 'exhaust', 'characteristic', 'require', 'compensate', 'profile', 'folk', 'slip', 'intend', 'particular', 'slip', 'data', 'rider', 'issue', 'review', 'group', 'header', 'exhaust', 'cbr600f2', 'bar', 'ontario', 'slip', 'dyno']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 834\n",
      "First 100 words of topic 4 of the document with highest probability\n",
      "['gibbonsa', 'fraser.sfu.ca', 'darren', 'gibbon', 'information', 'opel', 'model', 'sad', 'truth', 'entirely', 'two-seater', 'roll-over', 'headlight', 'sporty', 'friend', 'sitting', 'yard', 'condition', 'body-wise', 'transmission', 'seize', 'info', 'compartment', 'tight', 'fine', 'shape', 'interested', 'opel', 'country', \"'69\", \"'73\", 'originally', '1100', 'later', 'replace', '1900', 'kadett', 'train', 'suspension', 'spring', 'rear', 'single', 'spring', 'limit', 'performer', 'discussion', 'thread', 'manta', 'model', '1971', 'opel', 'introduce', 'model', '1900', 'model', 'newer', 'available', 'coupe', 'station', 'wagon', 'coupe', 'europe', 'manta', '1900', 'kadett', 'suspension', 'coupe', 'model', 'available', 'black', 'hood', 'tach', 'fog', 'mechanically', 'except', 'rear', 'ratio', '1973', 'coupe', 'manta', '1973', 'country', 'bumper', 'height', 'regulation', 'fiat', 'exercise', 'option', 'factory', 'opel', 'lease', 'build', 'gts', '1900', 'continue', '1974', 'minor', 'body', 'difference', '1975']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1003\n",
      "First 100 words of topic 5 of the document with highest probability\n",
      "['x-newsreader', 'tin', 'version', '1.1', 'pl9', 'ranck', 'ranck', 'joesbar.cc.vt.edu', 'hate', 'admit', 'mentally', 'kick', 'brand', 'friday', '100', 'rain', 'darkness', 'center', 'stand', 'push', 'center', 'stand', 'preparation', 'friend', 'house', 'pose', 'land', 'scratch', 'fairing', 'crack', 'mirror', 'crack', 'upper', 'fairing', 'damn', 'stupid', 'cost', '200', 'local', 'body', 'shop', 'fix', 'fairing', 'cheap', 'mirror', 'alone', 'replacement', 'cheap', 'sister', 'pain', 'jose', 'finally', 'fall', 'k100rs', 'perfect', 'condition', 'everyone', 'shop', 'norton', 'war', 'story', 'fifteen', 'ago', 'sign', 'liability', 'waiver', 'walk', 'pizza', 'shop', 'street', 'sister', 'boyfriend', 'happy', 'horrendous', 'crash', 'saw', 'towards', 'obvious', 'source', 'disturbance', 'jeff', 'lay', 'rear', 'wheel', 'spin', 'kill', 'switch', 'star', 'slice', 'hang', 'mouth', 'matty', 'shop', 'manager', 'slide', 'beside', 'friend', 'shit', 'matty', 'jeff']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1434\n",
      "First 100 words of topic 6 of the document with highest probability\n",
      "['research.nj.nec.com', 'behanna', 'syl.nj.nec.com', 'chris', 'behanna', 'kryptonite', 'cable', 'lock', 'anywhere', '1/2', 'thick', 'steel', 'cable', 'steel', 'rope', 'shield', 'flexible', 'protect', 'finish', 'lock', 'mechanism', 'adjustable', 'source', 'difficult', 'lock', 'cable', 'tend', 'squish', 'flat', 'jaw', 'shear', 'model', 'fyi', 'krypto', 'cable', 'paycheck', 'word', 'warning', 'kryptonite', 'almost', 'useless', 'cable', 'lock', 'kryptonite', 'obtain', 'kryptonite', 'bicycle', 'shopping', 'lock', 'bicycle', 'choice', 'kryptonite', 'cable', 'lock', 'advantage', 'lock', 'wheel', 'bicycle', 'kryptonite', 'cheesy', 'u-lock', 'advantage', 'steel', 'choose', 'kryptonite', 'cable', 'disgust', 'exchange', 'cheesy', 'u-lock', 'krypto', 'cable', 'kryptonite', 'cover', 'kryptonite', 'guarantee', 'approach', 'kryptonite', 'standard', 'quality', 'quality', 'generic', 'cable', 'lock', 'kryptonite', 'secondly', 'engagement', 'mechanism', 'joke', 'mine', 'particularly', 'poor', 'example', 'often', 'frustrate', 'positively', 'engage', 'sometimes', 'engage', 'fall']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 168\n",
      "First 100 words of topic 7 of the document with highest probability\n",
      "['archive-name', 'automotive', 'mailing', 'electronic', 'updated', 'lotus', 'exotic', 'subscription', 'info', 'add', 'portland', 'triumph', 'rpw', 'electronic', 'mailing', 'network', 'devote', 'various', 'special', 'automotive', 'topic', 'knowledge', 'appear', 'open', 'membership', 'policy', 'policy', 'closed', 'mailing', 'mailing', 'provide', 'separate', 'address', 'administrative', 'query', 'general', 'separate', 'administrative', 'address', 'exist', 'general', 'address', 'appropriate', 'inquiry', 'request', 'audi', 'request', 'request', 'request', 'balltown.cma.com', 'regular', 'digest', 'form', 'available', 'british', 'request', 'buick', 'grand', 'request', 'camaro/firebird', 'request', 'boogie.ebay.sun.com', 'request', 'bryan', 'competition', 'orient', 'general', 'nature', 'competition', 'request', 'general', 'request', 'roadster', 'request', 'dodge', '3000gt', 'request', 'request', 'electric', 'vehicle', 'request', 'request', 'race', 'request', 'international', 'discussion', 'scout', 'pickup', 'request', 'balltown.cma.com', 'italian', 'request', 'balltown.cma.com', 'regular', 'digest', 'form', 'available', 'hondas', 'listserv', 'standard']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 410\n",
      "First 100 words of topic 8 of the document with highest probability\n",
      "['cybernet.cse.fau.edu', 'vlasis', 'cybernet.cse.fau.edu', 'vlasis', 'theodore', 'tobias', 'convex.com', 'allen', 'tobias', 'virginia.edu', 'ejv2j', 'virginia.edu', 'erik', 'vel', 'ago', 'washington', 'beltway', 'snot', 'nose', 'drunken', 'kid', 'decide', 'cool', 'huge', 'rock', 'overpass', 'four', 'five', 'several', 'serious', 'injury', 'sadly', 'girl', 'sit', 'seat', 'strike', 'large', 'rock', 'recall', 'comatose', 'month', 'doctor', 'hold', 'hope', 'live', 'hell', 'country', 'boyhood', 'prank', 'pee', 'bridge', 'pound', 'rock', 'society', 'stoop', 'erik', 'velapold', 'society', 'apart', 'seam', 'basic', 'human', 'life', 'devalue', 'kill', 'kid', 'hundred', 'murderous', 'act', 'abort', 'child', 'demand', 'kill', 'sick', 'surprise', 'kid', 'drop', 'rock', 'kill', 'care', 'message', 'life', 'cheap', 'unfortunatly', 'experience', 'human', 'life', 'among', 'develop', 'nation', 'american', 'raise', 'europe', 'somebody', 'broken', 'pocket', 'slave', 'russian', 'thats', 'extremely']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 800\n",
      "First 100 words of topic 9 of the document with highest probability\n",
      "['review', 'today', 'visit', 'friend', 'whose', 'love', 'audis', 'live', 'delay', 'audi', 'servotronic', 'steering', 'familiar', 'servotronic', 'variable', 'steer', 'manufacture', 'audis', 'bmws', 'servotronic', 'past', 'month', 'magazine', 'review', 'audi', 'quattro', 'audi', 'fwd', 'happy', 'report', 'servotronic', 'suppose', 'due', 'fat', 'servotronic', 'load', 'perfect', 'mind', 'happy', 'option', 'refuse', 'longer', 'entire', 'ruin', 'steering', 'tad', 'accurate', 'suppose', 'spring', 'chassis', 'information', 'driver', 'accuracy', 'steering', 'room', 'improvement', 'steering', 'japanese', 'competition', 'primarily', 'japanese', 'engineer', 'completely', 'pressure', '110', 'clock', 'produce', 'anywhere', 'later', 'pack', 'terrific', 'punch', 'turbocharged', 'machine', 'unusual', 'encourage', 'lazy', 'driving', 'i.e', 'rev', 'gear', 'flexible', 'hardly', '2.2', 'liter', 'displacement', 'pound', 'fashion', 'maximum', 'torque', 'available', '1950', 'rpm', 'rpm', 'redline', 'translate', 'range', 'mph', 'normally', 'associate']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1634\n",
      "First 100 words of topic 10 of the document with highest probability\n",
      "['dsd.es.com', 'bgardner', 'pebbles.es.com', 'blaine', 'gardner', 'earth.cs.utexas.edu', 'mcguire', 'cs.utexas.edu', 'tommy', 'marcus', 'mcguire', 'hey', 'hell', 'suck', 'god-given', 'express', 'carry', 'gun', 'wear', 'helmet', 'goddamn', 'everything', 'stand', 'stupid', '0.5', 'scale', 'mention', 'hitler', 'koresh', 'favor', 'neglect', 'mention', '105', 'mph', 'tennis', 'girl', 'countersteering', 'mexican', 'food', 'folk', 'mistake', 'heat', 'quality', 'subtle', 'reference', 'various', 'personal', 'generally', 'earn', 'four', 'letter', 'word', 'cap', 'lock', 'key', 'introduce', 'polysyllabic', 'word', 'strabismic', 'example', 'likely', 'insure', 'become', 'immortal', 'blaine', 'gardner', 'evans', 'sutherland', 'bgardner', 'dsd.es.com', \"c'mon\", 'serious', 'overreaction', 'ought', 'worth', 'mention', 'bit', 'condemn', 'non', 'gun', 'helmet', 'proper', 'flourish', 'personally', 'type', 'quality', 'sense', 'mention', 'heat', 'certain', 'surprise', 'value', 'correctly', 'contend', 'reasonably', 'entertaining', 'mention', 'velocity', 'friend', 'dinner']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1328\n",
      "First 100 words of topic 11 of the document with highest probability\n",
      "['leavitt', 'cs.umd.edu', 'mr.', 'bill', 'mjs', 'sys.uea.ac.uk', 'sixsmith', 'mjs', 'imho', 'newbie', 'countersteering', 'mjs', 'confuse', 'happily', 'mjs', 'countersteering', 'differently', 'mjs', 'interpret', 'representative', 'motorcyclist', 'imho', 'leavitt', 'cs.umd.edu', 'mr.', 'bill', 'leavitt', 'learn', 'countersteering', 'technique', 'leavitt', 'learn', 'develop', 'habit', 'rode', 'leavitt', 'five', 'msf', 'learn', 'leavitt', 'countersteer', 'eight', 'later', 'leavitt', 'steer', 'countersteer', 'leavitt', 'habit', 'die', 'habit', 'mjs', 'sorry', 'bill', 'complete', 'learn', 'countersteer', 'mjs', 'natural', 'sorry', 'kick', '_not_', 'countersteer', 'stone', 'kick', 'sake', 'argument', 'concede', 'countersteering', 'sake', 'argument', 'mjs', 'msf', 'teach', 'countersteer', 'mjs', 'already', 'value', 'value', 'confusing', 'newbie', 'difference', 'especially', 'extreme', 'emergency', 'swerve', 'whatever', 'precisely', 'command', 'emergency', 'avoidance', 'improve', 'mention', 'improvement', 'normal', 'corner', 'ability', 'countersteer', 'steer', 'command', 'corner']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 163\n",
      "First 100 words of topic 12 of the document with highest probability\n",
      "['archive-name', 'recent', 'march', 'addition', 'rpw', '===', 'welcome', 'rec.autos', '===', 'automatically', 'month', 'contain', 'general', 'description', 'purpose', 'automotive', 'newsgroups', 'suggest', 'guideline', 'discussion', 'keywords', 'monthly', 'appear', 'kill', 'easy', 'user', 'kill', 'facility', 'auto', 'group', 'followup', 'direct', 'rec.autos', 'understand', 'administrator', 'copy', 'fail', 'subscribe', 'newsgroup', 'provide', 'introduction', 'rec.autos', 'newsgroup', 'hierarchy', 'rec.autos.tech', 'intend', 'technical', 'discussion', 'automobile', 'design', 'construction', 'service', 'discussion', 'largely', 'inappropriate', 'especially', 'sale', 'intend', 'discussion', 'legal', 'organize', 'competition', 'involve', 'automobile', 'technical', 'discussion', 'appropriate', 'apply', 'competition', 'vehicle', 'discussion', 'viewpoint', 'spectator', 'participant', 'encourage', 'argument', 'largely', 'inappropriate', 'discussion', 'sale', 'inappropriate', 'unless', 'competition', 'vehicle', 'and/or', 'equipment', 'discussion', 'illegal', 'event', 'marginal', 'avoid', 'advocate', 'break', 'law', 'fbi', 'usenet', 'intend', 'discussion', 'relate', 'driving']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 127\n",
      "First 100 words of topic 13 of the document with highest probability\n",
      "['previous', 'andrew.cmu.edu', 'daniel', 'twenty', 'mostly', 'trail', 'wagon', 'rut', 'fairly', 'placement', 'steer', 'wheel', 'arbitrary', 'company', '.....', 'active', 'movement', 'origin', 'bicycle', 'steam', 'teen', 'witness', 'highway', 'association', 'highway', 'support', 'act', 'federal', 'county', 'build', 'decent', 'experience', 'widespread', 'truck', 'domestic', 'convince', 'government', 'crucial', 'national', 'defense', 'anyway', '20s', 'plenty', 'urban', 'rapidly', 'expand', 'era', 'auto', 'tour', 'motel', 'auto', 'camp', 'ground', 'book', 'subject', 'spring', 'mind', 'warren', 'america', 'title', 'exact', 'author', 'devil', 'wagon', 'god', 'country', 'author', 'forget', 'bell', 'auto', 'history', 'sorry', 'important', 'classroom', 'movie', 'huh', 'recall', 'thinking', 'asphalt', 'til', 'interstate', 'act', 'whatever', 'wood', 'fairly', 'rare', 'except', 'england', 'city', 'obviously', 'placement', 'steer', 'wheel', 'arbitrary', 'teen', 'virtually', 'american', 'wheel', 'left', 'wheel']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 1617\n",
      "First 100 words of topic 14 of the document with highest probability\n",
      "['pet', 'peeve', 'definitely', 'peeve', 'bill', 'lock', 'easy', 'break', 'person', '|the', 'proper', 'supply', 'and/or', 'motivation', 'minute', 'glad', 'explain', 'dont', 'contribute', 'alarm', 'offense', 'bill', 'straight', 'secret', 'method', 'break', 'lock', 'word', 'unlikely', 'successful', 'business', 'rec.motorcycles', \"can't\", 'protect', 'assault', 'discuss', 'method', 'pipe', 'liquid', 'nitrogen', 'tool', 'bunch', 'method', 'thief', 'certain', 'rod', 'wheel', 'four', 'lift', 'truck', 'lock', 'method', 'easy', 'figure', 'visible', 'chain', 'cable', 'lock', 'likely', 'lazy', 'thief', 'hey', 'finally', 'advantage', 'weight', 'concours', 'hate', 'rip', 'tactic', 'warn', 'lock', 'alone', 'safe', 'deterent', 'theft', '|the', 'thief', 'doesnt', 'walk', 'personally', 'motion', 'alarm', 'combination', 'lock', 'type', 'concerned', 'tactic', 'refer', 'guard', 'literally', 'rely', 'combination', 'alarm', 'questionable', 'insurance', 'park', 'obvious', 'visible', 'intention', 'steal']\n",
      "\n",
      "\n",
      "Document index with highest topic probability: 30\n",
      "First 100 words of topic 15 of the document with highest probability\n",
      "['bottom', 'technique', 'callison', 'james', 'callison', 'michael.apple.com', 'michael.apple.com', 'michael', 'smith', 'peculiar', 'tool', 'remove', 'rear', 'spring', 'ford', 'truck', '4x4', 'spring', 'rear', 'socket', 'air', 'wrench', 'floor', 'jack', 'bottle', 'jack', 'socket', 'undo', 'shock', 'wd40', 'socket', 'metric', 'exact', 'fit', 'able', 'sae', 'socket', 'fun', 'canadian', 'ford', 'picture', 'undo', 'bolt', 'bottle', 'jack', 'axle', 'raise', 'stress', 'spring', 'undo', 'drop', 'spring', 'bottom', 'spring', 'bolt', 'undo', 'bolt', 'shock', 'jack', 'frame', 'spare', 'garage', 'floor', 'wooden', 'platform', 'jack', 'raise', 'frame', 'truck', 'lift', 'spring', 'free', 'axel', 'block', 'room', 'undo', 'pin', 'hold', 'spring', 'pack', 'together', 'spring', 'pack', 'hold', 'together', 'nut', 'round', 'wrench', 'vice', 'grip', 'fine', 'soak', 'nut', 'wd40', 'flip', 'bottom', 'spring', 'wait', 'easy', 'physically']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (d) Find, for each topic, the document (message) with highest probability of that topic, and print\n",
    "# its 100 first words.\n",
    "for i in range(numtopics):\n",
    "    print('Document index with highest topic probability: ' + str(numpy.argmax(documentstrengths[:,i]) + 1))\n",
    "    print('First 100 words of topic ' + str(i+1) + ' of the document with highest probability')\n",
    "    print(gensim_docs[numpy.argmax(documentstrengths[:,i])][0:100])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the topics are the same as before, but some of them are different. The differences are that the topics are more specific and the words having higher probability are more related to the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Optional: let's see if an AI chatbot can analyze these topics. See exercise 2.4 regarding possible chatbots; report what chatbot you used. \n",
    "Take one of the topics, e.g., the highest probability one, and provide its list of top words to an AI chatbot; you can tell it that the topic has been learned from the four newsgroups. Ask it to interpret the topic based on the list of words. Ask it also to generate a text that could be drawn from the topic. Does its interpretation of the topic seem meaningful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question for CHATGPT:\n",
    "Document index with highest topic probability: 607\n",
    "First 100 words of topic 1 of the document with highest probability\n",
    "['drutx.att.com', 'callison', 'james', 'callison', 'normally', 'unloaded', 'colt', 'delta', 'glove', 'box', 'loaded', 'magazine', 'handy', 'perfectly', 'legal', 'oklahoma', 'travel', 'inter-state', 'unloaded', 'magnum', 'revolver', 'glove', 'box', 'pocket', 'legal', 'everywhere', 'federal', 'law', 'illinois', 'police', 'hang', 'carry', 'pistol', 'load', 'unloaded', 'glove', 'compartment', 'carry', 'concealed', 'weapon', 'colorado', 'illegal', 'concealed', 'weapon', 'permit', 'unless', 'law', 'recently', 'carry', 'weapon', 'legal', 'colorado', 'conceal', 'illegal', 'newspaper', 'account', 'police', 'traffic', 'infraction', 'observe', '.357', 'magnum', 'revolver', 'sit', 'seat', 'driver', 'cite', 'carry', 'weapon', 'conceal', 'gun', 'discover', 'glove', 'box', 'crime', 'carry', 'glove', 'box', '_is_', 'legal', 'oklahoma', 'inter-state', 'travel', 'legal', 'destination', 'gun', 'carry', 'locked', 'glove', 'box', 'specifically', 'exclude', 'separate', 'ammo', 'legal', 'title', 'chapter', 'section', 'forget', 'copy']\n",
    "\n",
    "tell it that the topic has been learned from the four newsgroups\n",
    "\n",
    "interpret the topic based on the list of words.\n",
    "\n",
    "generate a text that could be drawn from the topic\n",
    "\n",
    "\n",
    "CHAT GPT RESPONSE:\n",
    "It appears that the text you provided is related to discussions about the legality and regulations surrounding the transportation and carrying of firearms in different states, particularly focusing on Oklahoma, Illinois, and Colorado. The mention of terms like \"unloaded,\" \"glove box,\" \"concealed weapon,\" and references to specific laws suggests a discussion on the legal nuances of carrying firearms in various locations.\n",
    "\n",
    "Given the context and the mention of \"four newsgroups,\" it seems like this topic has been discussed or learned from online forums or news groups where individuals share information and experiences related to firearms laws and regulations.\n",
    "\n",
    "Here's a generated text that could be drawn from the topic:\n",
    "\n",
    "In the realm of firearm regulations, discussions among online communities have illuminated the legal intricacies of carrying weapons across state lines. Users share insights on the permissible practices, highlighting the legality of transporting unloaded firearms in specific compartments, such as glove boxes. The discourse touches upon variations in state laws, with particular attention to the contrasting perspectives in states like Oklahoma, where carrying an unloaded firearm in a glove box is deemed legal for interstate travel, and Illinois, where law enforcement may scrutinize concealed weapons, even if unloaded.\n",
    "\n",
    "The narrative delves into recent legal developments, shedding light on changes in Colorado's concealed carry landscape. While carrying a concealed weapon was once illegal without a permit, recent legislative shifts have rendered it permissible under certain circumstances. Anecdotes recount incidents where individuals, initially cited for traffic infractions, found themselves entangled in legal debates due to the discovery of firearms in glove boxes. The conversation underscores the importance of staying abreast of evolving laws and adhering to specific regulations governing the transportation of firearms, emphasizing the need for responsible gun ownership.\n",
    "\n",
    "This generated text attempts to capture the essence of the topic, combining elements of legal discussions, regional variations, and the practical implications of firearm transportation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the interpretation of the topic seems meaningful since it can recognize the reason of the topic and the generated text is related to the topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
