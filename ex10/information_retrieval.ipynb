{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 10.1: Retrieval using TF-IDF and unigram language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = sum(a.get(word, 0) * b.get(word, 0) for word in set(a) & set(b))\n",
    "\n",
    "    magnitude = math.sqrt(sum(value**2 for value in a.values())) * math.sqrt(\n",
    "        sum(value**2 for value in b.values())\n",
    "    )\n",
    "    return dot_product / magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the documents and the query\n",
    "documents = {\n",
    "    'd1': \"the robot is insightful but you are strong and i may answer and the wise fox is insightful and you are insightful and i am insightful but i will explain the insightful bird\",\n",
    "    'd2': \"the bird is insightful\",\n",
    "    'd3': \"when will they explain the friendly insightful strong insightful bird and is the bird strong and is a strong robot insightful\",\n",
    "    'd4': \"a cat is strong but you are cautious and i may help but a fox is insightful but are they strong and when may you answer\"\n",
    "}\n",
    "query = \"insightful bird\"\n",
    "\n",
    "# Split the documents and the query into words\n",
    "documents = {doc: text.split() for doc, text in documents.items()}\n",
    "query = query.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the term frequencies\n",
    "tfs = {doc: Counter(words) for doc, words in documents.items()}\n",
    "query_tf = Counter(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the document frequencies\n",
    "dfs = Counter(word for words in documents.values() for word in set(words))\n",
    "\n",
    "# Compute the inverse document frequencies\n",
    "idfs = {word: math.log(len(documents) / df) for word, df in dfs.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the TF-IDF vectors for the documents and the query\n",
    "tfidfs = {\n",
    "    doc: {word: tf * idfs[word] for word, tf in tfs[doc].items()} for doc in documents\n",
    "}\n",
    "query_tfidf = {word: tf * idfs.get(word, 0) for word, tf in query_tf.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarities between the query and the documents:\n",
      "d1: 0.06591142916966435\n",
      "d2: 0.7071067811865475\n",
      "d3: 0.2249420126105055\n",
      "d4: 0.0\n",
      "\n",
      "Unigram probabilities for the query given by each document:\n",
      "d1: 0.004591368227731864\n",
      "d2: 0.0625\n",
      "d3: 0.013605442176870746\n",
      "d4: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "cosine_similarities = {\n",
    "    doc: cosine_similarity(tfidf, query_tfidf) for doc, tfidf in tfidfs.items()\n",
    "}\n",
    "\n",
    "print(\"Cosine similarities between the query and the documents:\")\n",
    "for doc, cosine_similarity in cosine_similarities.items():\n",
    "    print(f\"{doc}: {cosine_similarity}\")\n",
    "\n",
    "# Compute the unigram probabilities for the query given by each document\n",
    "unigram_probabilities = {\n",
    "    doc: math.prod(tfs[doc].get(word, 0) / len(words) for word in query)\n",
    "    for doc, words in documents.items()\n",
    "}\n",
    "\n",
    "print(\"\\nUnigram probabilities for the query given by each document:\")\n",
    "for doc, unigram_probability in unigram_probabilities.items():\n",
    "    print(f\"{doc}: {unigram_probability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 10.2: Pagerank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d1': 1, 'd2': 1, 'd3': 1, 'd4': 1}\n",
      "d1: 0\n",
      "d2: 0.80078125\n",
      "d3: 1.599609375\n",
      "d4: 1.599609375\n"
     ]
    }
   ],
   "source": [
    "links = {\n",
    "    'd1': ['d2', 'd3'],\n",
    "    'd2': ['d4'],\n",
    "    'd3': ['d2', 'd4'],\n",
    "    'd4': ['d3']\n",
    "}\n",
    "pageranks = {doc: 1 for doc in links}\n",
    "print(pageranks)\n",
    "while True:\n",
    "    new_pageranks = {}\n",
    "    \n",
    "    for doc in links:\n",
    "        new_pageranks[doc] = sum(pageranks[incoming_doc] / len(links[incoming_doc]) for incoming_doc in links if doc in links[incoming_doc])\n",
    "    if all(abs(new_pageranks[doc] - pageranks[doc]) < 0.001 for doc in links):\n",
    "        break\n",
    "    pageranks = new_pageranks\n",
    "\n",
    "for doc, pagerank in pageranks.items():\n",
    "    print(f\"{doc}: {pagerank}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 10.3: Limitations and improvements of Pagerank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query:\n",
    "1. what the limitations of the Pagerank algorithm are, \n",
    "2. in what ways the algorithm can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHATGPT RESPONSE:\n",
    "\n",
    "# 1. Limitations of the PageRank Algorithm\n",
    "The PageRank algorithm, despite its effectiveness in ranking web pages, has some limitations:\n",
    "\n",
    "Static Nature: PageRank was initially designed for static web pages, and its effectiveness decreases when applied to dynamic or rapidly changing content on the internet.\n",
    "\n",
    "*-> This is because PageRank scores are not calculated at the time of search but are determined at the time of indexing. [1]* \n",
    "\n",
    "Link Spamming: It is susceptible to manipulation by link spammers who create numerous links to artificially inflate the ranking of a page.\n",
    "\n",
    "Topic Ignorance: PageRank doesn't consider the topical relevance of content, leading to potential inaccuracies in ranking when content is diverse. \n",
    "*-> It also struggles with queries containing natural language and information outside of keywords [1]*\n",
    "\n",
    "# 2. Ways to Improve the PageRank Algorithm\n",
    "\n",
    "To enhance the PageRank algorithm, several improvements have been proposed:\n",
    "\n",
    "BlockRank Algorithm: An improved approach involves the BlockRank algorithm, which reduces the dimension of the linear system, making calculations more efficient for general nodes.\n",
    "\n",
    "Adaptation to Evolving Networks: Recognizing the limitations in growing networks, modifications like considering the decay of relevance can address the failure of PageRank in ranking nodes effectively.\n",
    "\n",
    "*-> The ideas above are correct, maybe nothing to add or support more. Some information I can find more:*\n",
    "\n",
    "*Another method: [2]* \n",
    "\n",
    "*Eliminate dangling pages: Dangling pages are pages that have no out links. They are not considered in the PageRank algorithm.*\n",
    "\n",
    "*Aggregate out links on pages with many site links*\n",
    "\n",
    "*Split long pages into several pages: This is a good idea to improve the PageRank algorithm. Because the PageRank algorithm is based on the number of links, the more links, the higher the PageRank score. Therefore, splitting long pages into several pages will increase the number of links, thereby increasing the PageRank score.\n",
    "*\n",
    "\n",
    "[1]: https://blogs.cornell.edu/info2040/2015/10/28/limitations-of-pagerank/\n",
    "[2]: https://www.zdnet.com/article/3-simple-ways-to-optimize-for-google-pagerank/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: https://blogs.cornell.edu/info2040/2015/10/28/limitations-of-pagerank/\n",
    "\n",
    "2: https://www.zdnet.com/article/3-simple-ways-to-optimize-for-google-pagerank/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
